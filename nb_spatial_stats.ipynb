{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial statistics on hsdm hiprfish images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import aicspylibczi as aplc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "from collections import defaultdict\n",
    "# from scipy.cluster import hierarchy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sklearn.cluster as clst\n",
    "import hdbscan\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from skimage.feature import peak_local_max\n",
    "# from matplotlib_scalebar.scalebar import ScaleBar\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from scipy.spatial.distance import squareform, pdist\n",
    "# from skimage.segmentation import watershed, relabel_sequential\n",
    "# from skimage.measure import label, regionprops_table, regionprops\n",
    "\n",
    "import cv2\n",
    "import libpysal as ps\n",
    "from esda.moran import Moran, Moran_BV\n",
    "from libpysal.weights import W\n",
    "import pointpats.quadrat_statistics as qs\n",
    "from pointpats import PointPattern, RectangleM\n",
    "from pointpats import distance_statistics as dst\n",
    "from pointpats import PoissonPointProcess as csr\n",
    "from pointpats.window import Window, poly_from_bbox, as_window, to_ccf\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "from time import sleep\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = \"\"\n",
    "workdir = \"\"\n",
    "os.chdir(cluster + workdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "functions_path = 'functions'\n",
    "\n",
    "sys.path.append(cluster + functions_path)\n",
    "\n",
    "import fn_general_use as fgu\n",
    "import image_plots as ip\n",
    "# import segmentation_func as sf\n",
    "import fn_hiprfish_classifier as fhc\n",
    "import fn_spectral_images as fsi\n",
    "import fn_analysis_plots as apl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get czi filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_table_fn = \"input_table_all.csv\"\n",
    "input_table = pd.read_csv(input_table_fn)\n",
    "filenames = input_table[\"filenames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_date_sn_fns = defaultdict(lambda: defaultdict(list))\n",
    "for fn in filenames:\n",
    "    bn = os.path.split(fn)[1]\n",
    "    date, bn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "    sn, ext = re.split(\"(?<=fov_\\d{2})\", bn)\n",
    "    dict_date_sn_fns[date][sn].append(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get processed filename formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../outputs/{date}/{date}_{sn}\"\n",
    "out_fmt_classif = out_dir + \"/classif\"\n",
    "centroid_sciname_fmt = out_fmt_classif + \"/{date}_{sn}_centroid_sciname.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get color dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sciname_list = [\n",
    "#     \"Corynebacterium\",\n",
    "#     \"Actinomyces\",\n",
    "#     \"Rothia\",\n",
    "#     \"Capnocytophaga\",\n",
    "#     \"Prevotella\",\n",
    "#     \"Porphyromonas\",\n",
    "#     \"Streptococcus\",\n",
    "#     \"Gemella\",\n",
    "#     \"Veillonella\",\n",
    "#     \"Selenomonas\",\n",
    "#     \"Lautropia\",\n",
    "#     \"Neisseriaceae\",\n",
    "#     \"Pasteurellaceae\",\n",
    "#     \"Campylobacter\",\n",
    "#     \"Fusobacterium\",\n",
    "#     \"Leptotrichia\",\n",
    "#     \"Treponema\",\n",
    "#     \"TM7\",\n",
    "# ]\n",
    "# colors = plt.get_cmap(\"tab20\").colors\n",
    "# # colors = [c + (1,) for c in colors]\n",
    "# dict_sciname_color = dict(zip(sciname_list, colors))\n",
    "# dict_sciname_color[\"Neisseria\"] = dict_sciname_color[\"Neisseriaceae\"]\n",
    "# dict_sciname_color[\"Saccharibacteria\"] = dict_sciname_color[\"TM7\"]\n",
    "# dict_sciname_color[\"TM\"] = dict_sciname_color[\"TM7\"]\n",
    "\n",
    "# get coords\n",
    "sciname_list = [\n",
    "    'Pasteurellaceae',\n",
    "    'Corynebacterium',\n",
    "    'Veillonella',\n",
    "    'Actinomyces',\n",
    "    'Selenomonas',\n",
    "    'Rothia',\n",
    "    'Porphyromonas',\n",
    "    'Capnocytophaga',\n",
    "    'Prevotella',\n",
    "    'Streptococcus',\n",
    "    'Gemella',\n",
    "    'Campylobacter',\n",
    "    'Lautropia',\n",
    "    'Leptotrichia',\n",
    "    'Neisseriaceae',\n",
    "    'Treponema',\n",
    "    'Fusobacterium',\n",
    "    'TM7'\n",
    "]\n",
    "cmap = plt.get_cmap('gist_rainbow')\n",
    "colors = [cmap(i)[:3] for i in np.linspace(0,1,len(sciname_list))]\n",
    "colors[13] = [0.75,0.75,0.75]\n",
    "colors[1] = np.array([176,2,104])/255\n",
    "colors[8] = np.array([184,155,69])/255\n",
    "colors[6] = np.array([245,164,159])/255\n",
    "colors[5] = np.array([221,159,239])/255\n",
    "colors[14] = np.array([54,148,161])/255\n",
    "colors.insert(17, colors.pop(1))\n",
    "colors.insert(4, colors.pop(6))\n",
    "colors.insert(9, colors.pop(12))\n",
    "colors.insert(5, colors.pop(8))\n",
    "# colors = [c + (1,) for c in colors]\n",
    "dict_sciname_color = dict(zip(sciname_list, colors))\n",
    "dict_sciname_color['Neisseria'] = dict_sciname_color['Neisseriaceae']\n",
    "dict_sciname_color['Saccharibacteria'] = dict_sciname_color['TM7']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.taxon_legend(list(dict_sciname_color.keys()), list(dict_sciname_color.values()))\n",
    "out_fn = \"../outputs/taxon_legend.png\"\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick an image to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2023_02_08\"\n",
    "sn = \"hsdm_group_1_sample_12_fov_01\"\n",
    "czi_fns = dict_date_sn_fns[date][sn]\n",
    "czi_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get coordinates and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_sciname_fn = centroid_sciname_fmt.format(date=date, sn=sn)\n",
    "centroid_sciname = pd.read_csv(centroid_sciname_fn)\n",
    "coords = np.array([eval(c) for c in centroid_sciname[\"coord\"].values])\n",
    "scinames = centroid_sciname[\"sciname\"].values\n",
    "scn_unq = np.unique(scinames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Spatial autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get adjacency  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_um = 3\n",
    "\n",
    "res_mpix = fsi.get_resolution(czi_fns[0])\n",
    "res_umpix = res_mpix * 1e6\n",
    "radius_pix = radius_um / res_umpix\n",
    "neigh = NearestNeighbors(radius=radius_pix)\n",
    "nbrs = neigh.fit(coords)\n",
    "nn_dists, nn_inds = nbrs.radius_neighbors(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pixel radius', radius_pix)\n",
    "_ = plt.hist([len(ni) for ni in nn_inds])\n",
    "_ = plt.xlabel('Number of cells within ' + str(radius_um) + 'Î¼m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build weights matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_inds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = {}\n",
    "for i, (nn_i) in enumerate(nn_inds):\n",
    "    neighbors[i] = [ni for ni in nn_i if ni != i]\n",
    "neighbors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = W(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get join counts stat for each taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 1\n",
    "ft = 7\n",
    "dims = (2, 1)\n",
    "l_col = 'k'\n",
    "colors = apl.get_cmap_listed(\"tab10\")\n",
    "line_colors = [colors[0], colors[1]]\n",
    "xlabel = \"\"\n",
    "xticks = (1, 1.7)\n",
    "xlims = (0.65, 2.05)\n",
    "ylabel = \"\"\n",
    "yticks = []\n",
    "pad = 0.2\n",
    "h = 100\n",
    "dpi=500\n",
    "\n",
    "spot_size = 3\n",
    "dims_im = (4,4)\n",
    "\n",
    "xlim = (0, np.max(coords[:, 1]))\n",
    "ylim = (0, np.max(coords[:, 0]))\n",
    "\n",
    "moran_dir = out_dir + '/spatial_stats/morans_i'\n",
    "moran_plot_fmt = moran_dir + \"/{date}_{sn}_sciname_{scn}_moran_plot.png\"\n",
    "scatter_plot_fmt = moran_dir + \"/{date}_{sn}_sciname_{scn}_scatter_plot.png\"\n",
    "moran_table_fmt = moran_dir + \"/{date}_{sn}_moran_values.csv\"\n",
    "\n",
    "moran_table = defaultdict(list)\n",
    "for scn in scn_unq:\n",
    "    # calculate morans i\n",
    "    col = dict_sciname_color[scn]\n",
    "    bool_scn = scinames == scn\n",
    "    y = bool_scn * 1\n",
    "    mi = Moran(y, w)\n",
    "    print(scn, mi.I, mi.p_sim)\n",
    "    moran_table[\"sciname\"].append(scn)\n",
    "    moran_table[\"I_expected\"].append(mi.EI)\n",
    "    moran_table[\"I_measured\"].append(mi.I)\n",
    "    moran_table[\"p_simulation\"].append(mi.p_sim)\n",
    "    # PLot the simluation vs observed\n",
    "    fig, ax = apl.general_plot(col=l_col, dims=dims, lw=lw, ft=ft, pad=pad)\n",
    "    apl.plot_morans_i_sim_obj(ax, mi, lw=lw, ft=ft, col=col, l_col=l_col)\n",
    "    moran_fn = moran_plot_fmt.format(date=date, sn=sn, scn=scn)\n",
    "    ip.check_dir(moran_fn)\n",
    "    ip.save_fig(moran_fn)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # Plot the scatter locations\n",
    "    coord_scn = coords[bool_scn]\n",
    "    fig, ax = ip.general_plot(col='w', dims=dims_im, lw=lw, ft=ft)\n",
    "    ax.scatter(coord_scn[:,1], coord_scn[:,0], s=spot_size, color=col)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    scatter_fn = scatter_plot_fmt.format(date=date, sn=sn, scn=scn)\n",
    "    ip.check_dir(scatter_fn)\n",
    "    ip.save_fig(scatter_fn, dpi=dpi)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "moran_table_fn = moran_table_fmt.format(date=date, sn=sn)\n",
    "ip.check_dir(moran_table_fn)\n",
    "pd.DataFrame(moran_table).to_csv(moran_table_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate global correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 1\n",
    "ft = 7\n",
    "dims = (2, 1)\n",
    "l_col = 'k'\n",
    "colors = apl.get_cmap_listed(\"tab10\")\n",
    "line_colors = [colors[0], colors[1]]\n",
    "xlabel = \"\"\n",
    "xticks = (1, 1.7)\n",
    "xlims = (0.65, 2.05)\n",
    "ylabel = \"\"\n",
    "yticks = []\n",
    "pad = 0.2\n",
    "h = 100\n",
    "dpi=500\n",
    "\n",
    "spot_size = 1\n",
    "dims_im = (4,4)\n",
    "\n",
    "xlim = (0, np.max(coords[:, 1]))\n",
    "ylim = (0, np.max(coords[:, 0]))\n",
    "\n",
    "moran_bv_dir = out_dir + '/spatial_stats/moran_bv'\n",
    "moran_bv_plot_fmt = moran_bv_dir + \"/{date}_{sn}_sciname_{scn}_moran_plot.png\"\n",
    "scatter_plot_fmt = moran_bv_dir + \"/{date}_{sn}_scinames_{scn0}_{scn1}_scatter_plot.png\"\n",
    "moran_table_fmt = moran_bv_dir + \"/{date}_{sn}_moran_bv_values.csv\"\n",
    "\n",
    "moran_bv_table = defaultdict(list)\n",
    "for i, scn0 in enumerate(scn_unq):\n",
    "    for j, scn1 in enumerate(scn_unq):\n",
    "        if i < j:\n",
    "            # calculate morans i\n",
    "            col0 = dict_sciname_color[scn0]\n",
    "            col1 = dict_sciname_color[scn1]\n",
    "            bool_scn0 = scinames == scn0\n",
    "            bool_scn1 = scinames == scn1\n",
    "            y0 = bool_scn0 * 1\n",
    "            y1 = bool_scn1 * 1\n",
    "            mbv = Moran_BV(y0, y1, w)\n",
    "            print(scn0, scn1, mbv.EI_sim, mbv.I, mbv.p_sim)\n",
    "            moran_bv_table[\"sciname0\"].append(scn0)\n",
    "            moran_bv_table[\"sciname1\"].append(scn0)\n",
    "            moran_bv_table[\"I_expected\"].append(mbv.EI_sim)\n",
    "            moran_bv_table[\"I_measured\"].append(mbv.I)\n",
    "            moran_bv_table[\"p_simulation\"].append(mbv.p_sim)\n",
    "            # PLot the simluation vs observed\n",
    "            fig, ax = apl.general_plot(col=l_col, dims=dims, lw=lw, ft=ft, pad=pad)\n",
    "            apl.plot_morans_i_sim_obj(ax, mbv, lw=lw, ft=ft, col=col0, l_col=l_col)\n",
    "            # moran_fn = moran_plot_fmt.format(date=date, sn=sn, , scn0=scn1, scn0=scn1)\n",
    "            # ip.check_dir(moran_fn)\n",
    "            # ip.save_fig(moran_fn)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            # Plot the scatter locations\n",
    "            coord_scn0 = coords[bool_scn0]\n",
    "            coord_scn1 = coords[bool_scn1]\n",
    "            fig, ax = ip.general_plot(col='w', dims=dims_im, lw=lw, ft=ft)\n",
    "            ax.scatter(coord_scn0[:,1], coord_scn0[:,0], s=spot_size, color=col0)\n",
    "            ax.scatter(coord_scn1[:,1], coord_scn1[:,0], s=spot_size, color=col1)\n",
    "            ax.set_xlim(xlim[0], xlim[1])\n",
    "            ax.set_ylim(ylim[0], ylim[1])\n",
    "            ax.invert_yaxis()\n",
    "            ax.set_aspect('equal')\n",
    "            # scatter_fn = scatter_plot_fmt.format(date=date, sn=sn, scn0=scn1, scn0=scn1)\n",
    "            # ip.check_dir(scatter_fn)\n",
    "            # ip.save_fig(scatter_fn, dpi=dpi)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "# moran_bv_table_fn = moran_bv_table_fmt.format(date=date, sn=sn)\n",
    "# ip.check_dir(moran_bv_table_fn)\n",
    "# pd.DataFrame(moran_bv_table).to_csv(moran_bv_table_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmax = 205\n",
    "stepsize=5\n",
    "\n",
    "dims=(10,5)\n",
    "ft=12\n",
    "lw=2\n",
    "\n",
    "def deriv(K, h):\n",
    "    return np.diff(K) / np.diff(h)\n",
    "\n",
    "\n",
    "# Define distance range\n",
    "res_mpix = fsi.get_resolution(czi_fns[0])\n",
    "res_umpix = res_mpix * 1e6\n",
    "d = np.arange(0, dmax, stepsize)\n",
    "dpix = d / res_umpix\n",
    "# Get cells window\n",
    "convex_hull = ps.cg.convex_hull(coords.tolist())\n",
    "ch_arr = np.array(to_ccf(convex_hull))\n",
    "plt.plot(ch_arr[:,1], ch_arr[:,0])\n",
    "plt.gca().invert_yaxis()\n",
    "window = Window([convex_hull])\n",
    "\n",
    "for scn in scn_unq[3:5]:\n",
    "    print(scn)\n",
    "    # Get point pattern\n",
    "    col_obs = dict_sciname_color[scn]\n",
    "    bool_scn = scinames == scn\n",
    "    coord_scn = coords[bool_scn]\n",
    "    pp = PointPattern(coord_scn, window=window)\n",
    "    # Measure L values\n",
    "    lenv = dst.L(pp, d=dpix)\n",
    "    # Plot L values\n",
    "    fig, ax = ip.general_plot(dims=dims, ft=ft, col='k', lw=lw)\n",
    "    x = lenv.d\n",
    "    ax.plot(x, lenv.l, lw=lw, color=col_obs)\n",
    "    xlab = np.arange(0, dmax, 10)\n",
    "    xticks = xlab / res_umpix\n",
    "    _ = ax.set_xticks(xticks, labels=xlab)\n",
    "    ax.plot([xticks[0], xticks[-1]],[0,0], 'k')\n",
    "    ax.set_xlim([xticks[0], xticks[-1]])\n",
    "    # PLot derivative of L\n",
    "    h = lenv.d\n",
    "    Lpobs = deriv(lenv.l, h)\n",
    "    fig, ax = ip.general_plot(dims=dims, ft=ft, col='k', lw=lw)\n",
    "    x = h[:-1]\n",
    "    ax.plot(x, Lpobs, lw=lw, color=col_obs)\n",
    "    xlab = np.arange(0, dmax, 10)\n",
    "    xticks = xlab / res_umpix\n",
    "    _ = ax.set_xticks(xticks, labels=xlab)\n",
    "    ax.plot([xticks[0], xticks[-1]],[0,0], 'k')\n",
    "    ax.set_xlim([xticks[0], xticks[-1]])\n",
    "    # PLot second derivative of L\n",
    "    h = x\n",
    "    Lppobs = deriv(Lpobs, h)\n",
    "    fig, ax = ip.general_plot(dims=dims, ft=ft, col='k', lw=lw)\n",
    "    x = h[:-1]\n",
    "    ax.plot(x, Lppobs, lw=lw, color=col_obs)\n",
    "    xlab = np.arange(0, dmax, 10)\n",
    "    xticks = xlab / res_umpix\n",
    "    _ = ax.set_xticks(xticks, labels=xlab)\n",
    "    ax.plot([xticks[0], xticks[-1]],[0,0], 'k')\n",
    "    ax.set_xlim([xticks[0], xticks[-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up simulation envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bbox=[0,0,crf_shp[0],crf_shp[1]]\n",
    "# poly = poly_from_bbox(bbox)\n",
    "# window = as_window(poly)\n",
    "\n",
    "convex_hull = ps.cg.convex_hull(coords.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_arr = np.array(to_ccf(convex_hull))\n",
    "plt.plot(ch_arr[:,1], ch_arr[:,0])\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window([convex_hull])\n",
    "window.bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up point pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn = 'Gemella'\n",
    "scn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_scn = scinames == scn\n",
    "coord_scn = coords[bool_scn]\n",
    "pp = PointPattern(coord_scn, window=window)\n",
    "# mge_pp = PointPattern(mge_coords_adj_order, window=window)\n",
    "pp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmax = 205\n",
    "stepsize=5\n",
    "\n",
    "res_mpix = fsi.get_resolution(czi_fns[0])\n",
    "res_umpix = res_mpix * 1e6\n",
    "d = np.arange(0, dmax, stepsize)\n",
    "dpix = d / res_umpix\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenv = dst.L(pp, d=dpix)\n",
    "lenv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_sim = '-.'\n",
    "env_col = 'k'\n",
    "xt_max = 100\n",
    "dims=(10,5)\n",
    "ft=12\n",
    "lw=2\n",
    "col_obs = dict_sciname_color[scn]\n",
    "\n",
    "\n",
    "fig, ax = ip.general_plot(dims=dims, ft=ft, col='k', lw=lw)\n",
    "x = lenv.d\n",
    "ax.plot(x, lenv.l, lw=lw, color=col_obs)\n",
    "# ax.plot(x, Lpmean, lw=lw, color='k', ls=ls_sim)\n",
    "# ax.plot(x, Lplow, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "# ax.plot(x, Lphigh, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "# xt_max = int(xlim[1] * mge_umpix)\n",
    "xlab = np.arange(0, dmax, 10)\n",
    "xticks = xlab / res_umpix\n",
    "_ = ax.set_xticks(xticks, labels=xlab)\n",
    "\n",
    "ax.plot(xlim,[0,0], 'k')\n",
    "# ax.set_ylim(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(K, h):\n",
    "    return np.diff(K) / np.diff(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = lenv.d\n",
    "Lpobs = deriv(lenv.l, h)\n",
    "# Lpmean = pcf(lenv.mean, h)\n",
    "# Lplow = pcf(lenv.low, h)\n",
    "# Lphigh = pcf(lenv.high, h)\n",
    "\n",
    "\n",
    "ls_sim = '-.'\n",
    "env_col = 'k'\n",
    "xt_max = 100\n",
    "dims=(10,5)\n",
    "ft=12\n",
    "lw=2\n",
    "col_obs = dict_sciname_color[scn]\n",
    "\n",
    "\n",
    "fig, ax = ip.general_plot(dims=dims, ft=ft, col='k', lw=lw)\n",
    "x = h[:-1]\n",
    "ax.plot(x, Lpobs, lw=lw, color=col_obs)\n",
    "# ax.plot(x, Lpmean, lw=lw, color='k', ls=ls_sim)\n",
    "# ax.plot(x, Lplow, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "# ax.plot(x, Lphigh, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "# xt_max = int(xlim[1] * mge_umpix)\n",
    "xlab = np.arange(0, dmax, 10)\n",
    "xticks = xlab / res_umpix\n",
    "_ = ax.set_xticks(xticks, labels=xlab)\n",
    "\n",
    "ax.plot(xlim,[0,0], 'k')\n",
    "# ax.set_ylim(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L second derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = lenv.d[:-1]\n",
    "Lppobs = deriv(Lpobs, h)\n",
    "# Lpmean = pcf(lenv.mean, h)\n",
    "# Lplow = pcf(lenv.low, h)\n",
    "# Lphigh = pcf(lenv.high, h)\n",
    "\n",
    "\n",
    "ls_sim = '-.'\n",
    "env_col = 'k'\n",
    "xt_max = 100\n",
    "dims=(10,5)\n",
    "ft=12\n",
    "lw=2\n",
    "\n",
    "fig, ax = ip.general_plot(dims=dims, ft=ft, col='k', lw=lw)\n",
    "x = h[:-1]\n",
    "ax.plot(x, Lppobs, lw=lw, color=col_obs)\n",
    "# ax.plot(x, Lpmean, lw=lw, color='k', ls=ls_sim)\n",
    "# ax.plot(x, Lplow, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "# ax.plot(x, Lphigh, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "# xt_max = int(xlim[1] * mge_umpix)\n",
    "xlab = np.arange(0, dmax, 10)\n",
    "xticks = xlab / res_umpix\n",
    "_ = ax.set_xticks(xticks, labels=xlab)\n",
    "ax.plot(xlim,[0,0], 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizations = csr(pp.window, pp.n, 100, asPP=True) # simulate CSR \n",
    "# reals = realizations.realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dists = pp.nnd.squeeze()\n",
    "nn_dists_um = nn_dists * res_umpix\n",
    "n_ints_1um = int(np.max(nn_dists_um))\n",
    "\n",
    "n_ints_1um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kenv = dst.K(pp, d=dpix)\n",
    "Kenv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_sim = '-.'\n",
    "env_col = 'k'\n",
    "xt_max = 100\n",
    "dims=(10,5)\n",
    "ft=12\n",
    "lw=2\n",
    "col_obs = dict_sciname_color[scn]\n",
    "\n",
    "\n",
    "fig, ax = ip.general_plot(dims=dims, ft=ft, col='k', lw=lw)\n",
    "x = d\n",
    "ax.plot(x, Kenv.k, lw=lw, color=col_obs)\n",
    "# ax.plot(x, Lpmean, lw=lw, color='k', ls=ls_sim)\n",
    "# ax.plot(x, Lplow, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "# ax.plot(x, Lphigh, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "\n",
    "lndist = np.log(d[1:])\n",
    "lnk = np.log(Kenv.k[1:])\n",
    "model = LinearRegression().fit(lndist[:, None], lnk)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(lndist, lnk)\n",
    "print('slope: ', model.coef_, 'intercept: ', model.intercept_)\n",
    "print(stats.pearsonr(lndist, lnk))\n",
    "print(stats.linregress(lndist, lnk))\n",
    "\n",
    "y = x**(model.coef_[0]) * math.exp(model.intercept_)\n",
    "ax.plot(x, y, 'k')\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel('log10(distance (Î¼m))')\n",
    "ax.set_ylabel(\"log10(Ripley's K)\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcf(K, h):\n",
    "    dKdh = np.diff(K) / np.diff(h)\n",
    "    return dKdh / (2 * h[1:] * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_obs = dict_sciname_color[scn]\n",
    "\n",
    "Robs = pcf(Kenv.k, Kenv.d)\n",
    "# Rmean = pcf(Kenv.mean, Kenv.d)\n",
    "# Rlow = pcf(Kenv.low, Kenv.d)\n",
    "# Rhigh = pcf(Kenv.high, Kenv.d)\n",
    "\n",
    "\n",
    "ls_sim = '-.'\n",
    "env_col = 'k'\n",
    "xt_max = 100\n",
    "dims=(10,5)\n",
    "ft=12\n",
    "lw=2\n",
    "\n",
    "fig, ax = ip.general_plot(dims=dims, ft=ft, col='k', lw=lw)\n",
    "x = Kenv.d[:-1]\n",
    "ax.plot(x, Robs, lw=lw, color=col_obs)\n",
    "# ax.plot(x, Rmean, lw=lw, color='k', ls=ls_sim)\n",
    "# ax.plot(x, Rlow, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "# ax.plot(x, Rhigh, lw=lw, color=(0.5,0.5,0.5), ls=ls_sim)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "# xt_max = int(xlim[1] * mge_umpix)\n",
    "xlab = np.arange(0, xt_max, 5)\n",
    "xticks = xlab / res_umpix\n",
    "_ = ax.set_xticks(xticks, labels=xlab)\n",
    "\n",
    "# ax.set_ylim(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lena pair correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01_centroid_sciname.csv\", index_col=0)\n",
    "spatial_temp = data['coord']\n",
    "spatial = [tuple(map(float, line.replace('[', '').replace(']', '').replace(',', '').split())) for line in spatial_temp]\n",
    "x_min = np.min(np.array(spatial).T[0]); x_max = np.max(np.array(spatial).T[0])\n",
    "y_min = np.min(np.array(spatial).T[1]); y_max = np.max(np.array(spatial).T[1])\n",
    "area = (x_max - x_min)*(y_max - y_min)\n",
    "rmax = min(x_max - x_min, y_max - y_min) / 2 # np.sqrt(area)/2\n",
    "radii = np.linspace(0,rmax,50).reshape(50,1)\n",
    "def ripley_K(spatial, radii):\n",
    "    ## Ripley's K with edge correction\n",
    "    npts = np.shape(spatial)[0]                                 # Number of events in A\n",
    "    diff = np.zeros(shape = (npts*(npts-1)//2,2))               # Decomposed distances matrix\n",
    "    k = 0\n",
    "    for i in range(npts - 1):\n",
    "        size = npts - i - 1\n",
    "        diff[k:k + size] = abs(np.array(spatial[i]) - np.array(spatial[i+1:])) # distance\n",
    "        k += size\n",
    "    n_ripley = np.zeros(len(radii))\n",
    "    distances = np.hypot(diff[:,0], diff[:,1])                      # Pythagorean Theorem (a^2+b^2=c^2)\n",
    "    for r in range(len(radii)):\n",
    "        n_ripley[r] = (distances<radii[r]).sum()                    # Indicator function and summation term\n",
    "    n_ripley = area * 2. * n_ripley / (npts * (npts - 1))           # Expectation vector element-wise divided by scalar intensity\n",
    "    return n_ripley\n",
    "def ripley_K_boundary(spatial, radii=radii):\n",
    "    ## Ripley's K with edge correction\n",
    "    ripley = np.zeros(len(radii))\n",
    "    #npts = len(spatial)\n",
    "    npts = np.shape(spatial)[0]                                 # Number of events in A\n",
    "    diff = np.zeros(shape = (npts*(npts-1)//2,2))               # Decomposed distances matrix\n",
    "    k = 0\n",
    "    for i in range(npts - 1):\n",
    "        size = npts - i - 1\n",
    "        diff[k:k + size] = abs(np.array(spatial[i]) - np.array(spatial[i+1:])) # distance\n",
    "        k += size\n",
    "    x_min = np.min(np.array(spatial).T[0]); x_max = np.max(np.array(spatial).T[0])\n",
    "    y_min = np.min(np.array(spatial).T[1]); y_max = np.max(np.array(spatial).T[1])\n",
    "    hor_dist = np.zeros(shape=(npts * (npts - 1)) // 2, dtype=np.double)\n",
    "    ver_dist = np.zeros(shape=(npts * (npts - 1)) // 2, dtype=np.double)\n",
    "    for k in range(npts - 1):                           # Finds horizontal and vertical distances from every event to nearest egde\n",
    "        min_hor_dist = min(x_max - spatial[k][0], spatial[k][0] - x_min)\n",
    "        min_ver_dist = min(y_max - spatial[k][1], spatial[k][1] - y_min)\n",
    "        start = (k * (2 * (npts - 1) - (k - 1))) // 2\n",
    "        end = ((k + 1) * (2 * (npts - 1) - k)) // 2\n",
    "        hor_dist[start: end] = min_hor_dist * np.ones(npts - 1 - k)\n",
    "        ver_dist[start: end] = min_ver_dist * np.ones(npts - 1 - k)\n",
    "    dist = np.hypot(diff[:, 0], diff[:, 1])\n",
    "    dist_ind = dist <= np.hypot(hor_dist, ver_dist)     # True if distance between events is less than or equal to distance to edge\n",
    "    w1 = (1 - (np.arccos(np.minimum(ver_dist, dist) / dist) + np.arccos(np.minimum(hor_dist, dist) / dist)) / np.pi)\n",
    "    w2 = (3 / 4 - 0.5 * (np.arccos(ver_dist / dist * ~dist_ind) + np.arccos(hor_dist / dist * ~dist_ind)) / np.pi)\n",
    "    weight = dist_ind * w1 + ~dist_ind * w2              # Weighting term\n",
    "    for r in range(len(radii)):\n",
    "        ripley[r] = ((dist < radii[r]) / weight).sum()   # Indicator function with weighting term\n",
    "    ripley = area * 2. * ripley / (npts * (npts - 1))\n",
    "    return ripley\n",
    "ripley_K =  ripley_K(spatial, radii)\n",
    "ripley_K_edge =  ripley_K_boundary(spatial, radii)\n",
    "ax, fig1 = plt.subplots()\n",
    "fig1.plot(radii,ripley_K_edge,color='red',linewidth=2,label='K_edgeCorrect')\n",
    "fig1.plot(radii,ripley_K,color='black',linewidth=2,label='K')\n",
    "fig1.set_title('K Function without edge adjustment',size=20)\n",
    "fig1.set_xlabel('Radii (m)',size=15); fig1.set_ylabel('K',size=15)\n",
    "fig1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hdbscan\n",
    "import libpysal as ps\n",
    "from pointpats.window import Window\n",
    "\n",
    "xlim = (0, np.max(coords[:, 1]))\n",
    "ylim = (0, np.max(coords[:, 0]))\n",
    "\n",
    "dims_im = (20,20)\n",
    "spot_size = 10\n",
    "lw=2\n",
    "ft=20\n",
    "\n",
    "dict_df = defaultdict(list)\n",
    "for scn in scn_unq:\n",
    "    # cluster coords\n",
    "    col = dict_sciname_color[scn]\n",
    "    bool_scn = scinames == scn\n",
    "    coord_scn = coords[bool_scn]\n",
    "    hdb = hdbscan.HDBSCAN(min_cluster_size=10).fit(coord_scn).labels_\n",
    "\n",
    "    # Plot clusters\n",
    "    fig, ax = ip.general_plot(col='w', dims=dims_im, lw=lw, ft=ft)\n",
    "    coord_scn_cl = coord_scn[hdb != -1]\n",
    "    hdb_cl = hdb[hdb != -1]\n",
    "    ax.scatter(coord_scn_cl[:,1], coord_scn_cl[:,0], s=spot_size, c=hdb_cl, cmap='gist_rainbow')\n",
    "    coord_scn_non = coord_scn[hdb == -1]\n",
    "    ax.scatter(coord_scn_non[:,1], coord_scn_non[:,0], s=spot_size, color=[0.75]*3)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    # print(np.unique(hdb))\n",
    "\n",
    "    # count spots in clusters and plot convex hull on clusters\n",
    "    # areas = []\n",
    "    counts = []\n",
    "    for cl in np.unique(hdb_cl):\n",
    "        coords_cl = coord_scn[hdb == cl]\n",
    "        ch_cl = ps.cg.convex_hull(coords_cl.tolist())\n",
    "        ch_arr = np.array(to_ccf(ch_cl))\n",
    "        ax.plot(ch_arr[:,1], ch_arr[:,0],'w', lw=lw)\n",
    "        # w = Window([ch_cl])\n",
    "        # areas.append(w.area)\n",
    "        counts.append(coords_cl.shape[0])\n",
    "        # cent = w.centroid\n",
    "        # ax.text(cent[1], cent[0], int(w.area), color='w', fontsize=ft)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Plot power law stuff? Mori, Smith, Hsu, 2020\n",
    "    counts_sort = sorted(counts)\n",
    "    nclust = len(counts_sort)\n",
    "    Pr = [r/nclust for r in range(nclust,0,-1)]\n",
    "    fig, ax = ip.general_plot()\n",
    "    lnpr = np.log(Pr) - 0.5  # improve alpha estimate Gabaix and ibragimov 2011\n",
    "    lncs = np.log(counts_sort)\n",
    "    ax.plot(lnpr, lncs)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    rval, pval = stats.pearsonr(lnpr, lncs)\n",
    "    dict_df['rval'].append(rval)\n",
    "    dict_df['pval'].append(pval)\n",
    "    model = LinearRegression().fit(lncs[:, None], lnpr)\n",
    "    dict_df['alpha'].append(1 / model.coef_[0])\n",
    "    dict_df['coef'].append(model.coef_[0])\n",
    "    dict_df['intercept'].append(model.intercept_)\n",
    "    dict_df['score'].append(model.score(lncs[:, None], lnpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([[0,1],[2,3]]), columns=['a','b'], index=['1','2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_compare_dir =  '../outputs/compare_samples'\n",
    "feature_matrix_fn = sample_compare_dir + '/samples_feature_matrix.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = pd.read_csv(feature_matrix_fn, index_col=0)\n",
    "feature_matrix = feature_matrix.fillna(0)\n",
    "X = feature_matrix.values\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_neighbors=2, min_dist=1\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(10,10), col='w')\n",
    "fit = umap.UMAP(n_neighbors=2, min_dist=1).fit(X)\n",
    "u = fit.embedding_\n",
    "ax.scatter(u[:,0], u[:,1], s=10)\n",
    "ax.set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = clst.KMeans(n_clusters=9).fit(u)\n",
    "cl_kmeans = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ip.general_plot(dims=(10, 10), col=\"w\")\n",
    "\n",
    "ax.scatter(u[:, 0], u[:, 1], s=10, c=cl_kmeans, cmap='tab10')\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in np.unique(cl_kmeans):\n",
    "    print(cl)\n",
    "    bool_cl = cl_kmeans == cl\n",
    "    print(feature_matrix.index.values[bool_cl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=10).fit(X)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = feature_matrix.columns.values\n",
    "\n",
    "for i, c in enumerate(pca.components_):\n",
    "    if i < 4:\n",
    "        print(i)\n",
    "        vlow = np.sort(c)[:3]\n",
    "        vhigh = np.sort(c)[-3:]\n",
    "        for v in [vlow, vhigh]:\n",
    "            for v_ in v:\n",
    "                bool_v = c == v_\n",
    "                print(v_)\n",
    "                print(cols[bool_v])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "pca_fit = pca.fit(Xs)\n",
    "Xt = pca_fit.transform(X)\n",
    "plot = plt.scatter(Xt[:, 0], Xt[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(pca_fit.components_):\n",
    "    if i < 4:\n",
    "        print(i)\n",
    "        vlow = np.sort(c)[:3]\n",
    "        vhigh = np.sort(c)[-3:]\n",
    "        for v in [vlow, vhigh]:\n",
    "            for v_ in v:\n",
    "                bool_v = c == v_\n",
    "                print(v_)\n",
    "                print(cols[bool_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pca = clst.KMeans(n_clusters=3).fit(Xt[:,:2])\n",
    "cl_kmeans_pca = kmeans_pca.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ip.general_plot(dims=(10, 10), col=\"w\")\n",
    "\n",
    "ax.scatter(Xt[:, 0], Xt[:, 1], s=20, c=cl_kmeans_pca, cmap=\"tab10\")\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in np.unique(cl_kmeans_pca):\n",
    "    print(cl)\n",
    "    bool_cl = cl_kmeans_pca == cl\n",
    "    print(feature_matrix.index.values[bool_cl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_sn = {\n",
    "    \"healthy_tooth\": [\n",
    "        \"2023_02_18_hsdm_group_batch1_patient_1_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_batch1_patient_1_fov_02\",\n",
    "        \"2023_02_18_hsdm_group_batch2_patient_10_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_batch2_patient_9_fov_01\",\n",
    "        \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01\",\n",
    "        \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_02\",\n",
    "        \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_03\",\n",
    "        \"2022_12_16_harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_01\",\n",
    "        \"2022_12_16_harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_02\",\n",
    "        \"2022_12_16_harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_03\",\n",
    "        \"2022_12_16_harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_01\",\n",
    "        \"2022_12_16_harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_02\",\n",
    "        \"2022_12_16_harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_03\",\n",
    "        \"2022_12_16_harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_01\",\n",
    "        \"2022_12_16_harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_02\",\n",
    "        \"2022_12_16_harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_03\",\n",
    "    ],\n",
    "    \"periodontitis_tooth\": [\n",
    "        \"2023_02_18_hsdm_group_batch2_patient_11_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_batch1_patient_2_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_batch1_patient_3_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_batch1_patient_4_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_batch1_patient_7_fov_01\",\n",
    "    ],\n",
    "    \"healthy_implant\": [\n",
    "        \"2023_02_18_hsdm_group_I_patient_11_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_I_patient_11_fov_02\",\n",
    "        \"2023_02_18_hsdm_group_I_patient_13_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_I_patient_6_fov_01\",\n",
    "        \"2023_10_16_hsdm_slide_IB_fov_01\",\n",
    "        \"2023_10_16_hsdm_slide_IB_fov_03\",\n",
    "        \"2023_02_08_hsdm_group_1_sample_06_fov_01\",\n",
    "        \"2023_02_08_hsdm_group_1_sample_11_fov_01\",\n",
    "        \"2023_02_08_hsdm_group_1_sample_12_fov_01\",\n",
    "        \"2023_10_16_hsdm_slide_IB_fov_02\",\n",
    "        \"2023_10_16_hsdm_slide_IL_fov_01\",\n",
    "        \"2023_10_16_hsdm_slide_IL_fov_02\",\n",
    "        \"2023_10_16_hsdm_slide_IL_fov_03\",\n",
    "        \"2024_04_24_hsdm_group_I_patient_16_aspect_MB_fov_01\",\n",
    "        \"2024_04_24_hsdm_group_I_patient_16_aspect_MB_fov_02\",\n",
    "        \"2024_04_24_hsdm_group_I_patient_16_aspect_MB_fov_03\",\n",
    "    ],\n",
    "    \"severe_peri_implantitis\": [\n",
    "        \"2023_02_18_hsdm_group_IV_patient_1_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_IV_patient_1_fov_02\",\n",
    "        \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_01\",\n",
    "        \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_02\",\n",
    "        \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_03\",\n",
    "        \"2022_12_16_harvardwelch_patient_18_tooth_2_aspect_MB_depth__fov_01\",\n",
    "        \"2022_12_16_harvardwelch_patient_19_tooth_15_aspect_MF_depth_sub_fov_01\",\n",
    "        \"2022_12_16_harvardwelch_patient_19_tooth_30_aspect_MB_depth_sub_fov_01\",\n",
    "        \"2023_02_08_hsdm_group_4_sample_01_fov_01\",\n",
    "        \"2023_02_08_hsdm_group_4_sample_01_fov_02\",\n",
    "        \"2024_04_16_hsdmgel_group_IV_pat_4_asp_MB_fov_02\",\n",
    "        \"2024_05_03_hsdm_group_IV_patient_4_aspect_ML_fov_01\",\n",
    "        \"2024_05_03_hsdm_group_IV_patient_4_aspect_ML_fov_02\",\n",
    "        \"2024_05_03_hsdm_group_IV_patient_3_aspect_DL_fov_02\",\n",
    "        \"2024_05_03_hsdm_group_IV_patient_3_aspect_DL_fov_03\",\n",
    "    ],\n",
    "    \"moderate_peri_implantitis\": [\n",
    "        \"2023_10_18_hsdm_slide_IIIB_fov_01\",\n",
    "        \"2023_10_18_hsdm_slide_IIIL_fov_01\",\n",
    "        \"2024_04_16_hsdmgel_group_III_pat_6_asp_ML_fov_03\",\n",
    "        \"2024_04_19_hsdm_group_III_patient_7_aspect_ML_fov_02\",\n",
    "        \"2024_04_19_hsdm_group_III_patient_7_aspect_ML_fov_03\",\n",
    "        \"2024_04_19_hsdm_group_III_patient_7_aspect_ML_fov_04\",\n",
    "        \"2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_01\",\n",
    "        \"2024_04_24_hsdm_group_III_patient_8_aspect_DB_fov_03\",\n",
    "        \"2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01\",\n",
    "        \"2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_02\",\n",
    "        \"2024_05_03_hsdm_group_III_patient_3_aspect_DL_fov_02\",\n",
    "        \"2024_05_03_hsdm_group_III_patient_3_aspect_DL_fov_03\",\n",
    "    ],\n",
    "    \"mucositis_implant\": [\n",
    "        \"2023_02_18_hsdm_group_II_patient_6_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_II_patient_7_fov_01\",\n",
    "        \"2023_02_18_hsdm_group_II_patient_7_fov_02\",\n",
    "        \"2023_02_08_hsdm_group_2_sample_06_fov_01\",\n",
    "        \"2023_02_08_hsdm_group_2_sample_06_fov_02\",\n",
    "        \"2023_10_18_hsdm_slide_IIL_fov_01\",\n",
    "        \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_04\",\n",
    "        \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_05\",\n",
    "        \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_06\",\n",
    "        \"2024_04_19_hsdm_group_II_patient_14_aspect_MB_fov_01\",\n",
    "        \"2024_04_19_hsdm_group_II_patient_14_aspect_MB_fov_02\",\n",
    "        \"2024_04_19_hsdm_group_II_patient_15_aspect_MB_fov_01\",\n",
    "        \"2024_04_19_hsdm_group_II_patient_15_aspect_MB_fov_02\",\n",
    "        \"2024_04_27_hsdm_group_II_patient_11_aspect_DL_fov_02\",\n",
    "        \"2024_04_27_hsdm_group_II_patient_11_aspect_DL_fov_03\",\n",
    "        \"2024_04_27_hsdm_group_II_patient_11_aspect_DL_fov_04\",\n",
    "    ],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_pat_sn = {\n",
    "    \"healthy_implant\": {\n",
    "        \"patient_11\": [\n",
    "            \"2023_02_18_hsdm_group_I_patient_11_fov_01\",\n",
    "            \"2023_02_18_hsdm_group_I_patient_11_fov_02\",\n",
    "            \"2023_02_08_hsdm_group_1_sample_11_fov_01\",\n",
    "        ],\n",
    "        \"patient_16\": [\n",
    "            \"2024_04_24_hsdm_group_I_patient_16_aspect_MB_fov_01\",\n",
    "            \"2024_04_24_hsdm_group_I_patient_16_aspect_MB_fov_02\",\n",
    "            \"2024_04_24_hsdm_group_I_patient_16_aspect_MB_fov_03\",\n",
    "            \"2024_04_24_hsdm_group_I_patient_16_aspect_MB_fov_04\",\n",
    "        ],\n",
    "        \"patient_13\": [\n",
    "            \"2023_02_18_hsdm_group_I_patient_13_fov_01\",\n",
    "        ],\n",
    "        \"patient_6\": [\n",
    "            \"2023_02_18_hsdm_group_I_patient_6_fov_01\",\n",
    "            \"2023_02_08_hsdm_group_1_sample_06_fov_01\",\n",
    "        ],\n",
    "        \"patient_12\": [\n",
    "            \"2023_02_08_hsdm_group_1_sample_12_fov_01\",\n",
    "        ],\n",
    "        \"patient_4\": [\n",
    "            \"2023_10_16_hsdm_slide_IB_fov_01\",\n",
    "            \"2023_10_16_hsdm_slide_IB_fov_02\",\n",
    "            \"2023_10_16_hsdm_slide_IB_fov_03\",\n",
    "            \"2023_10_16_hsdm_slide_IB_fov_02\",\n",
    "            \"2023_10_16_hsdm_slide_IL_fov_01\",\n",
    "            \"2023_10_16_hsdm_slide_IL_fov_02\",\n",
    "            \"2023_10_16_hsdm_slide_IL_fov_03\",\n",
    "        ],\n",
    "        \"patient_10\": [\n",
    "            \"2024_04_16_hsdmgel_group_I_pat_10_asp_DL_fov_01\",\n",
    "            \"2024_04_16_hsdmgel_group_I_pat_10_asp_DL_fov_02\",\n",
    "        ]\n",
    "    },\n",
    "    \"mucositis_implant\": {\n",
    "        \"patient_6\":[\n",
    "            \"2023_02_18_hsdm_group_II_patient_6_fov_01\",\n",
    "            \"2023_02_08_hsdm_group_2_sample_06_fov_01\",\n",
    "            \"2023_02_08_hsdm_group_2_sample_06_fov_02\",\n",
    "        ],\n",
    "        \"patient_7\":[\n",
    "            \"2023_02_18_hsdm_group_II_patient_7_fov_01\",\n",
    "            \"2023_02_18_hsdm_group_II_patient_7_fov_02\",\n",
    "        ],\n",
    "        \"patient_9\":[\n",
    "            \"2023_10_18_hsdm_slide_IIL_fov_01\",\n",
    "            \"2023_10_16_hsdm_slide_IIB_fov_01\",\n",
    "        ],\n",
    "        \"patient_13\":[\n",
    "            \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_01\",\n",
    "            \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_02\",\n",
    "            \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_03\",\n",
    "            \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_04\",\n",
    "            \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_05\",\n",
    "            \"2024_04_19_hsdm_group_II_patient_13_aspect_MB_fov_06\",\n",
    "        ],\n",
    "        \"patient_14\":[\n",
    "            \"2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_01\",\n",
    "            \"2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_02\",\n",
    "            \"2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_03\",\n",
    "            \"2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_04\",\n",
    "            \"2024_04_19_hsdm_group_II_patient_14_aspect_MB_fov_01\",\n",
    "            \"2024_04_19_hsdm_group_II_patient_14_aspect_MB_fov_02\",\n",
    "        ],\n",
    "        \"patient_15\":[\n",
    "            \"2024_04_19_hsdm_group_II_patient_15_aspect_MB_fov_01\",\n",
    "            \"2024_04_19_hsdm_group_II_patient_15_aspect_MB_fov_02\",\n",
    "        ],\n",
    "        \"patient_11\":[\n",
    "            \"2024_04_27_hsdm_group_II_patient_11_aspect_DL_fov_01\",\n",
    "            \"2024_04_27_hsdm_group_II_patient_11_aspect_DL_fov_02\",\n",
    "            \"2024_04_27_hsdm_group_II_patient_11_aspect_DL_fov_03\",\n",
    "            \"2024_04_27_hsdm_group_II_patient_11_aspect_DL_fov_04\",\n",
    "        ],\n",
    "        \"patient_12\":[\n",
    "            \"2024_04_27_hsdm_group_II_patient_12_aspect_ML_fov_01\",\n",
    "            \"2024_04_27_hsdm_group_II_patient_12_aspect_ML_fov_02\",\n",
    "            \"2024_04_27_hsdm_group_II_patient_12_aspect_ML_fov_03\",\n",
    "            \"2024_04_27_hsdm_group_II_patient_12_aspect_ML_fov_04\",\n",
    "        ],\n",
    "        \"patient_8\":[\n",
    "            \"2024_04_27_hsdm_group_II_patient_8_aspect_DL_fov_01\",\n",
    "            \"2024_04_27_hsdm_group_II_patient_8_aspect_DL_fov_02\",\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"mild_peri_implantitis\": {\n",
    "        \"patient_2\":[\n",
    "            \"2023_10_18_hsdm_slide_IIIB_fov_01\",\n",
    "            \"2023_10_18_hsdm_slide_IIIL_fov_01\",\n",
    "        ],\n",
    "        \"patient_6\":[\n",
    "            \"2024_04_16_hsdmgel_group_III_pat_6_asp_ML_fov_01\",\n",
    "            \"2024_04_16_hsdmgel_group_III_pat_6_asp_ML_fov_02\",\n",
    "            \"2024_04_16_hsdmgel_group_III_pat_6_asp_ML_fov_03\",\n",
    "        ],\n",
    "        \"patient_7\":[\n",
    "            \"2024_04_19_hsdm_group_III_patient_7_aspect_ML_fov_01\",\n",
    "            \"2024_04_19_hsdm_group_III_patient_7_aspect_ML_fov_02\",\n",
    "            \"2024_04_19_hsdm_group_III_patient_7_aspect_ML_fov_03\",\n",
    "            \"2024_04_19_hsdm_group_III_patient_7_aspect_ML_fov_04\",\n",
    "        ],\n",
    "        \"patient_5\":[\n",
    "            \"2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_01\",\n",
    "            \"2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_02\",\n",
    "            \"2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_03\",\n",
    "            \"2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_04\",\n",
    "        ],\n",
    "        \"patient_8\":[\n",
    "            \"2024_04_24_hsdm_group_III_patient_8_aspect_DB_fov_01\",\n",
    "            \"2024_04_24_hsdm_group_III_patient_8_aspect_DB_fov_02\",\n",
    "            \"2024_04_24_hsdm_group_III_patient_8_aspect_DB_fov_03\",\n",
    "        ],\n",
    "        \"patient_11\":[\n",
    "            \"2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01\",\n",
    "            \"2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_02\",\n",
    "        ],\n",
    "        \"patient_3\":[\n",
    "            \"2024_05_03_hsdm_group_III_patient_3_aspect_DL_fov_01\",\n",
    "            \"2024_05_03_hsdm_group_III_patient_3_aspect_DL_fov_02\",\n",
    "            \"2024_05_03_hsdm_group_III_patient_3_aspect_DL_fov_03\",\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    \"moderate_severe_peri_implantitis\": {\n",
    "        \"patient_1\":[\n",
    "            \"2023_02_18_hsdm_group_IV_patient_1_fov_01\",\n",
    "            \"2023_02_18_hsdm_group_IV_patient_1_fov_02\",\n",
    "            \"2023_02_08_hsdm_group_4_sample_01_fov_01\",\n",
    "            \"2023_02_08_hsdm_group_4_sample_01_fov_02\",\n",
    "        ],\n",
    "        \"patient_14\":[\n",
    "            \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_01\",\n",
    "            \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_02\",\n",
    "            \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_03\",\n",
    "        ],\n",
    "        \"patient_18\":[\n",
    "            \"2022_12_16_harvardwelch_patient_18_tooth_2_aspect_MB_depth__fov_01\",\n",
    "        ],\n",
    "        \"patient_19\":[\n",
    "            \"2022_12_16_harvardwelch_patient_19_tooth_30_aspect_MB_depth_sub_fov_01\",\n",
    "        ],\n",
    "        \"patient_4\":[\n",
    "            \"2024_04_16_hsdmgel_group_IV_pat_4_asp_MB_fov_01\",\n",
    "            \"2024_04_16_hsdmgel_group_IV_pat_4_asp_MB_fov_02\",\n",
    "            \"2024_05_03_hsdm_group_IV_patient_4_aspect_ML_fov_01\",\n",
    "            \"2024_05_03_hsdm_group_IV_patient_4_aspect_ML_fov_02\",\n",
    "            \"2024_05_03_hsdm_group_IV_patient_4_aspect_ML_fov_03\",\n",
    "        ],\n",
    "        \"patient_3\":[\n",
    "            \"2024_05_03_hsdm_group_IV_patient_3_aspect_DL_fov_01\",\n",
    "            \"2024_05_03_hsdm_group_IV_patient_3_aspect_DL_fov_02\",\n",
    "            \"2024_05_03_hsdm_group_IV_patient_3_aspect_DL_fov_03\",\n",
    "        ],\n",
    "        \"patient_2\":[\n",
    "            \"2023_10_18_hsdm_slide_IVL_fov_01\",\n",
    "            \"2023_10_18_hsdm_slide_IVB_fov_01\",\n",
    "        ]\n",
    "    },\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_sns = [\n",
    "    '2023_10_16_hsdm_slide_IB_fov_01', \n",
    "    '2023_10_16_hsdm_slide_IB_fov_03', \n",
    "    '2023_10_16_hsdm_slide_IB_fov_02', \n",
    "    '2022_12_16_harvardwelch_patient_18_tooth_2_aspect_MB_depth__fov_01',\n",
    "    '2022_12_16_harvardwelch_patient_19_tooth_30_aspect_MB_depth_sub_fov_01',\n",
    "    '2023_02_18_hsdm_group_II_patient_7_fov_02',\n",
    "    '2023_02_18_hsdm_group_II_patient_7_fov_01',\n",
    "    '2024_04_16_hsdmgel_group_I_pat_10_asp_DL_fov_01',\n",
    "    '2024_04_16_hsdmgel_group_I_pat_10_asp_DL_fov_02',\n",
    "    '2024_04_27_hsdm_group_II_patient_12_aspect_ML_fov_01',\n",
    "    '2024_04_27_hsdm_group_II_patient_12_aspect_ML_fov_02',\n",
    "    '2024_04_27_hsdm_group_II_patient_12_aspect_ML_fov_03',\n",
    "    '2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_01',\n",
    "    '2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_02',\n",
    "    '2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_03',\n",
    "    '2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_04',\n",
    "    '2024_04_27_hsdm_group_II_patient_8_aspect_DL_fov_01',\n",
    "    '2024_04_27_hsdm_group_II_patient_8_aspect_DL_fov_02',\n",
    "    '2023_10_18_hsdm_slide_IIIB_fov_01',\n",
    "    '2024_04_16_hsdmgel_group_III_pat_6_asp_ML_fov_01',\n",
    "    '2024_05_03_hsdm_group_III_patient_3_aspect_DL_fov_01',\n",
    "    '2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_01',\n",
    "    '2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_03',\n",
    "    '2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_04',\n",
    "    '2024_04_24_hsdm_group_III_patient_8_aspect_DB_fov_01',\n",
    "    '2024_04_24_hsdm_group_III_patient_8_aspect_DB_fov_02',    \n",
    "    '2024_05_03_hsdm_group_IV_patient_3_aspect_DL_fov_01',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dict_group_sn = {\n",
    "#     \"healthy_tooth\": [\n",
    "#         \"2023_02_18_hsdm_group_batch1_patient_1_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_batch1_patient_1_fov_02\",\n",
    "#         \"2023_02_18_hsdm_group_batch2_patient_10_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_batch2_patient_9_fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_02\",\n",
    "#         \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_03\",\n",
    "#         \"2022_12_16_harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_02\",\n",
    "#         \"2022_12_16_harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_03\",\n",
    "#         \"2022_12_16_harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_02\",\n",
    "#         \"2022_12_16_harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_03\",\n",
    "#         \"2022_12_16_harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_02\",\n",
    "#         \"2022_12_16_harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_03\",\n",
    "#     ],\n",
    "#     \"periodontitis_tooth\": [\n",
    "#         \"2023_02_18_hsdm_group_batch2_patient_11_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_batch1_patient_2_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_batch1_patient_3_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_batch1_patient_4_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_batch1_patient_7_fov_01\",\n",
    "#     ],\n",
    "#     \"healthy_implant\": [\n",
    "#         \"2023_02_18_hsdm_group_I_patient_11_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_I_patient_11_fov_02\",\n",
    "#         \"2023_02_18_hsdm_group_I_patient_13_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_I_patient_6_fov_01\",\n",
    "#         \"2023_10_16_hsdm_slide_IB_fov_01\",\n",
    "#         \"2023_10_16_hsdm_slide_IB_fov_03\",\n",
    "#         \"2023_02_08_hsdm_group_1_sample_06_fov_01\",\n",
    "#         \"2023_02_08_hsdm_group_1_sample_11_fov_01\",\n",
    "#         \"2023_02_08_hsdm_group_1_sample_12_fov_01\",\n",
    "#         \"2023_10_16_hsdm_slide_IB_fov_02\",\n",
    "#         \"2023_10_16_hsdm_slide_IL_fov_01\",\n",
    "#         \"2023_10_16_hsdm_slide_IL_fov_02\",\n",
    "#         \"2023_10_16_hsdm_slide_IL_fov_03\",\n",
    "#     ],\n",
    "#     \"severe_implant\": [\n",
    "#         \"2023_02_18_hsdm_group_IV_patient_1_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_IV_patient_1_fov_02\",\n",
    "#         \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_02\",\n",
    "#         \"2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_03\",\n",
    "#         \"2022_12_16_harvardwelch_patient_18_tooth_2_aspect_MB_depth__fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_19_tooth_15_aspect_MF_depth_sub_fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_19_tooth_30_aspect_MB_depth_sub_fov_01\",\n",
    "#         \"2023_02_08_hsdm_group_4_sample_01_fov_01\",\n",
    "#         \"2023_02_08_hsdm_group_4_sample_01_fov_02\",\n",
    "#     ],\n",
    "#     \"mucositis_implant\": [\n",
    "#         \"2023_02_18_hsdm_group_II_patient_6_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_II_patient_7_fov_01\",\n",
    "#         \"2023_02_18_hsdm_group_II_patient_7_fov_02\",\n",
    "#         \"2023_02_08_hsdm_group_2_sample_06_fov_01\",\n",
    "#         \"2023_02_08_hsdm_group_2_sample_06_fov_02\",\n",
    "#         \"2023_10_18_hsdm_slide_IIL_fov_01\",\n",
    "#     ],\n",
    "#     \"moderate_implant\": [\n",
    "#         \"2023_10_18_hsdm_slide_IIIB_fov_01\",\n",
    "#         \"2023_10_18_hsdm_slide_IIIL_fov_01\",\n",
    "#     ],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_sn_group = {}\n",
    "# for k, vs in dict_group_sn.items():\n",
    "#     for v in vs:\n",
    "#         dict_sn_group[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sn_group = {}\n",
    "for k, dps in dict_group_pat_sn.items():\n",
    "    for p, sns in dps.items():\n",
    "        for v in sns:\n",
    "            dict_sn_group[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,1,1,2,2,3,3,3,3])\n",
    "_, counts = np.unique(a, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"/{date}_{sn}_sciname_{scn}_cluster_size.npy\".format(date=1, sn=2, scn='Veillonella')\n",
    "\n",
    "re.search('(?<=sciname_)[A-Za-z]+', a)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_group_sn = {\n",
    "#     \"healthy_tooth\": [\n",
    "#         \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01\",\n",
    "#         \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_02\",\n",
    "#         \"2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_03\",\n",
    "#         \"hsdm_group_batch2_patient_10_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_batch2_patient_9_fov_01_2023_02_18\",\n",
    "#         \"harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_01_2022_12_16\",\n",
    "#         \"harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_02_2022_12_16\",\n",
    "#         \"harvardwelch_patient_9_tooth_15_aspect_MB_depth_supra_fov_03_2022_12_16\",\n",
    "#         \"harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_01_2022_12_16\",\n",
    "#         \"harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_02_2022_12_16\",\n",
    "#         \"harvardwelch_patient_9_tooth_3_aspect_D_depth_supra_fov_03_2022_12_16\",\n",
    "#         \"harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_01_2022_12_16\",\n",
    "#         \"harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_02_2022_12_16\",\n",
    "#         \"harvardwelch_patient_1_tooth_31_aspect_ML_depth_supra_fov_03_2022_12_16\",\n",
    "#         \"hsdm_group_batch1_patient_1_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_batch1_patient_1_fov_02_2023_02_18\",\n",
    "#     ],\n",
    "#     \"disease_tooth\": [\n",
    "#         \"hsdm_group_batch1_patient_2_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_batch1_patient_3_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_batch1_patient_4_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_batch1c_patient_7_fov_01_2023_02_18\",\n",
    "#         \"2023_02_18_hsdm_group_batch2_patient_11_fov_01\",\n",
    "#     ],\n",
    "#     \"healthy_implant\": [\n",
    "#         \"hsdm_group_I_patient_11_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_I_patient_11_fov_02_2023_02_18\",\n",
    "#         \"hsdm_group_I_patient_13_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_I_patient_6_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_1_sample_06_fov_01_2023_02_08\",\n",
    "#         \"hsdm_group_1_sample_11_fov_01_2023_02_08\",\n",
    "#         \"hsdm_group_1_sample_12_fov_01_2023_02_08\",\n",
    "#     ],\n",
    "#     \"moderate_severe_implant\": [\n",
    "#         \"harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_01_2022_12_16\",\n",
    "#         \"harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_03_2022_12_16\",\n",
    "#         \"harvardwelch_patient_18_tooth_2_aspect_MB_depth__fov_01_2022_12_16\",\n",
    "#         \"harvardwelch_patient_19_tooth_15_aspect_MF_depth_sub_fov_01_2022_12_16\",\n",
    "#         \"harvardwelch_patient_19_tooth_30_aspect_MB_depth_sub_fov_01_2022_12_16\",\n",
    "#         \"hsdm_group_4_sample_01_fov_01_2023_02_08\",\n",
    "#         \"hsdm_group_4_sample_01_fov_02_2023_02_08\",\n",
    "#         \"hsdm_group_IV_patient_1_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_IV_patient_1_fov_02_2023_02_18\",\n",
    "#         \"harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_02_2022_12_16\",\n",
    "#     ],\n",
    "#     \"mucositis_implant\": [\n",
    "#         \"hsdm_group_2_sample_06_fov_01_2023_02_08\",\n",
    "#         \"hsdm_group_2_sample_06_fov_02_2023_02_08\",\n",
    "#         \"hsdm_group_II_patient_7_fov_01_2023_02_18\",\n",
    "#         \"hsdm_group_II_patient_7_fov_02_2023_02_18\",\n",
    "#         \"hsdm_group_II_patient_6_fov_01_2023_02_18\",\n",
    "#     ],\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cluster size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_size_dict_fn = sample_compare_dir + \"/dict_sample_sciname_clustersize.yaml\"\n",
    "os.path.exists(cluster_size_dict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_size_dir = sample_compare_dir + '/cluster_size_distribution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cluster_size_dict_fn, 'r') as f:\n",
    "    dict_sn_scn_clsize = yaml.unsafe_load(f)\n",
    "len(dict_sn_scn_clsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pool all clusters and plot distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_all = []\n",
    "for sn, dict_scn_clsize in dict_sn_scn_clsize.items():\n",
    "    for scn, clsizes in dict_scn_clsize.items():\n",
    "        sizes_all += clsizes.tolist()\n",
    "\n",
    "len(sizes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_sort = np.sort(sizes_all)\n",
    "nclust = len(counts_sort)\n",
    "Pr = np.array([r/nclust for r in range(nclust,0,-1)])\n",
    "\n",
    "bool_l = counts_sort > 20\n",
    "bool_u = counts_sort < 1e4\n",
    "lnc = np.log(counts_sort[bool_l * bool_u])\n",
    "lnp = np.log(Pr[bool_l * bool_u])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(lnc, lnp)\n",
    "\n",
    "fig, ax = ip.general_plot()\n",
    "ax.scatter(counts_sort, Pr, color='k')\n",
    "\n",
    "x = [2e1, 3e4]\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.plot(x, y, 'r')\n",
    "x = 3e2\n",
    "y = math.exp(intercept) * x**slope + 0.1\n",
    "ax.text(x, y, 'Slope = ' + str(round(slope,2)), color='r')\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_title('All clusters (n=8117)')\n",
    "ax.set_xlabel(\"log(number of cells)\")\n",
    "ax.set_ylabel(\"log(Pr(ncells > x))\")\n",
    "out_fn = cluster_size_dir + '/all_clusters_size_distribution.png'\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sn_clsizes = defaultdict(list)\n",
    "for sn, dict_scn_clsize in dict_sn_scn_clsize.items():\n",
    "    for scn, clsizes in dict_scn_clsize.items():\n",
    "        dict_sn_clsizes[sn] += clsizes.tolist()\n",
    "\n",
    "len(dict_sn_clsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smin = 1e10\n",
    "smax = -1e10\n",
    "\n",
    "colors = plt.get_cmap('tab10').colors\n",
    "dict_group_color = dict(zip(list(dict_group_sn.keys()), colors))\n",
    "\n",
    "for group, sns in dict_group_sn.items():\n",
    "    color = dict_group_color[group]\n",
    "    fig, ax = ip.general_plot()\n",
    "    slopes = []\n",
    "    intercepts = []\n",
    "    for sn in sns:\n",
    "        clsizes = dict_sn_clsizes[sn]\n",
    "        counts_sort = np.sort(clsizes)\n",
    "        nclust = len(counts_sort)\n",
    "        Pr = np.array([r / nclust for r in range(nclust, 0, -1)])\n",
    "\n",
    "        bool_l = counts_sort > 20\n",
    "        bool_u = counts_sort < 1e4\n",
    "        lnc = np.log(counts_sort[bool_l * bool_u])\n",
    "        lnp = np.log(Pr[bool_l * bool_u])\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(lnc, lnp)\n",
    "        if slope < smin: \n",
    "            smin = slope\n",
    "            imin = intercept\n",
    "        if slope > smax:\n",
    "            smax = slope\n",
    "            imax = intercept\n",
    "        ax.scatter(counts_sort, Pr, s=2, color=color)\n",
    "\n",
    "        slopes.append(slope)\n",
    "        intercepts.append(intercept)\n",
    "\n",
    "    slopes = np.array(slopes)\n",
    "    slopes = slopes[~np.isnan(slopes)]\n",
    "    intercepts = np.array(intercepts)\n",
    "    intercepts = intercepts[~np.isnan(intercepts)]\n",
    "    smean = np.median(slopes)\n",
    "    imean = np.median(intercepts)\n",
    "    x = [2e1, 1e4]\n",
    "    y = math.exp(imean) * x**smean\n",
    "    ax.plot(x, y, \"r\")\n",
    "    x = 3e2\n",
    "    y = (math.exp(imean) * x**smean) \n",
    "    print(imean, smean)\n",
    "    print(x, y)\n",
    "    ax.text(x, y, \"Slope median = \" + str(round(smean, 2)), color=\"r\", ha=\"left\", va=\"bottom\")\n",
    "\n",
    "    # x = [2e1, 1e4]\n",
    "    # y = math.exp(imin) * x**smin\n",
    "    # ax.plot(x, y, \"r\")\n",
    "    # x = 3e2\n",
    "    # y = (math.exp(imin) * x**smin) - 0.01\n",
    "    # print(x, y)\n",
    "    # ax.text(x, y, \"Slope min = \" + str(round(smin, 2)), color=\"r\", ha='right', va='top')\n",
    "\n",
    "    # x = [2e1, 1e4]\n",
    "    # y = math.exp(imax) * x**smax\n",
    "    # ax.plot(x, y, \"r\")\n",
    "    # x = 3e2\n",
    "    # y = math.exp(imax) * x**smax + 0.1\n",
    "    # ax.text(x, y, \"Slope max = \" + str(round(smax, 2)), color=\"r\", ha='left', va='bottom')\n",
    "    # print(x,y)\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_title(group)\n",
    "    ax.set_xlabel(\"log(number of cells)\")\n",
    "    ax.set_ylabel(\"log(Pr(ncells > x))\")\n",
    "\n",
    "    out_fn = cluster_size_dir + '/size_distribution_by_sample_group_{}.png'.format(group)\n",
    "    ip.check_dir(out_fn)\n",
    "    ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot implants together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smin = 1e10\n",
    "smax = -1e10\n",
    "\n",
    "colors = plt.get_cmap(\"tab10\").colors\n",
    "dict_group_color = dict(zip(list(dict_group_sn.keys()), colors))\n",
    "fig, ax = ip.general_plot()\n",
    "\n",
    "for group, sns in dict_group_sn.items():\n",
    "    if 'implant' in group:\n",
    "        color = dict_group_color[group]\n",
    "        clsizes = []\n",
    "        for sn in sns:\n",
    "            clsizes += dict_sn_clsizes[sn]\n",
    "\n",
    "        counts_sort = np.sort(np.array(clsizes))\n",
    "        nclust = len(counts_sort)\n",
    "        Pr = np.array([r / nclust for r in range(nclust, 0, -1)])\n",
    "\n",
    "        bool_l = counts_sort > 20\n",
    "        bool_u = counts_sort < 1e4\n",
    "        lnc = np.log(counts_sort[bool_l * bool_u])\n",
    "        lnp = np.log(Pr[bool_l * bool_u])\n",
    "\n",
    "\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(lnc, lnp)\n",
    "        if slope < smin:\n",
    "            smin = slope\n",
    "            imin = intercept\n",
    "        if slope > smax:\n",
    "            smax = slope\n",
    "            imax = intercept\n",
    "        ax.scatter(counts_sort, Pr, s=2, color=color, label=group)\n",
    "\n",
    "        # x = [2e1, 1e4]\n",
    "        # y = math.exp(intercept) * x**slope\n",
    "        # ax.plot(x, y, \"r\")\n",
    "        # x = 3e2\n",
    "        # y = math.exp(intercept) * x**slope\n",
    "        # ax.text(\n",
    "        #     x,\n",
    "        #     y,\n",
    "        #     \"Slope = \" + str(round(slope, 2)) + \", R^2 = \" + str(round(r_value**2, 3)),\n",
    "        #     color=\"r\",\n",
    "        #     ha=\"left\",\n",
    "        #     va=\"bottom\",\n",
    "        # )\n",
    "\n",
    "        # x = [2e1, 1e4]\n",
    "        # y = math.exp(imin) * x**smin\n",
    "        # ax.plot(x, y, \"r\")\n",
    "        # x = 3e2\n",
    "        # y = (math.exp(imin) * x**smin) - 0.01\n",
    "        # print(x, y)\n",
    "        # ax.text(x, y, \"Slope min = \" + str(round(smin, 2)), color=\"r\", ha='right', va='top')\n",
    "\n",
    "        # x = [2e1, 1e4]\n",
    "        # y = math.exp(imax) * x**smax\n",
    "        # ax.plot(x, y, \"r\")\n",
    "        # x = 3e2\n",
    "        # y = math.exp(imax) * x**smax + 0.1\n",
    "        # ax.text(x, y, \"Slope max = \" + str(round(smax, 2)), color=\"r\", ha='left', va='bottom')\n",
    "        # print(x,y)\n",
    "\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_title(group)\n",
    "        ax.set_xlabel(\"log(ncells in cluster)\")\n",
    "        ax.set_ylabel(\"log(Pr(ncells > x))\")\n",
    "ax.legend()\n",
    "    # out_fn = cluster_size_dir + \"/size_distribution_by_sample_group_{}.png\".format(\n",
    "    #     group\n",
    "    # )\n",
    "    # ip.check_dir(out_fn)\n",
    "    # ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot each taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scn_clsizes = defaultdict(list)\n",
    "for sn, dict_scn_clsize in dict_sn_scn_clsize.items():\n",
    "    for scn, clsizes in dict_scn_clsize.items():\n",
    "        dict_scn_clsizes[scn] += clsizes.tolist()\n",
    "\n",
    "len(dict_scn_clsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smin = 1e10\n",
    "smax = -1e10\n",
    "\n",
    "colors = plt.get_cmap('tab20').colors\n",
    "\n",
    "plots = []\n",
    "slopes = []\n",
    "intercepts = []\n",
    "fig, ax = ip.general_plot()\n",
    "for i, (sn, clsizes) in enumerate(dict_scn_clsizes.items()):\n",
    "    counts_sort = np.sort(clsizes)\n",
    "    nclust = len(counts_sort)\n",
    "    Pr = np.array([r / nclust for r in range(nclust, 0, -1)])\n",
    "\n",
    "    bool_l = counts_sort > 20\n",
    "    bool_u = counts_sort < 1e4\n",
    "    lnc = np.log(counts_sort[bool_l * bool_u])\n",
    "    lnp = np.log(Pr[bool_l * bool_u])\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lnc, lnp)\n",
    "    if slope < smin:\n",
    "        smin = slope\n",
    "        imin = intercept\n",
    "    if slope > smax:\n",
    "        smax = slope\n",
    "        imax = intercept\n",
    "    slopes.append(slope)\n",
    "    intercepts.append(intercept)\n",
    "    ax.scatter(counts_sort, Pr, s=2, label=sn, color=colors[i])\n",
    "\n",
    "# x = [2e1, 1e4]\n",
    "# y = math.exp(imin) * x**smin\n",
    "# ax.plot(x, y, \"r\")\n",
    "# x = 3e2\n",
    "# y = (math.exp(imin) * x**smin) - 0.001\n",
    "# print(x, y)\n",
    "# ax.text(x, y, \"Slope min = \" + str(round(smin, 2)), color=\"r\", ha=\"right\", va=\"top\")\n",
    "\n",
    "# x = [2e1, 1e4]\n",
    "# y = math.exp(imax) * x**smax\n",
    "# ax.plot(x, y, \"r\")\n",
    "# x = 3e2\n",
    "# y = math.exp(imax) * x**smax + 0.1\n",
    "# ax.text(x, y, \"Slope max = \" + str(round(smax, 2)), color=\"r\", ha=\"left\", va=\"bottom\")\n",
    "# print(x, y)\n",
    "\n",
    "smean = np.median(slopes)\n",
    "imean = np.median(intercepts)\n",
    "x = [2e1, 1e4]\n",
    "y = math.exp(imean) * x**smean\n",
    "ax.plot(x, y, \"r\")\n",
    "x = 3e2\n",
    "y = (math.exp(imean) * x**smean) + 0.1\n",
    "print(x, y)\n",
    "ax.text(x, y, \"Slope median = \" + str(round(smean, 2)), color=\"r\", ha=\"left\", va=\"bottom\")\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_title(\"All clusters from each taxon\")\n",
    "ax.set_xlabel(\"log(number of cells)\")\n",
    "ax.set_ylabel(\"log(Pr(ncells > x))\")\n",
    "\n",
    "plt.figure(fig)\n",
    "out_fn = cluster_size_dir + '/all_taxa_clusters_size_distribution.png'\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)\n",
    "\n",
    "legendFig = plt.figure(\"Legend plot\")\n",
    "label_params = ax.get_legend_handles_labels()\n",
    "figl, axl = plt.subplots()\n",
    "axl.axis(False)\n",
    "lgnd = axl.legend(*label_params, loc=\"center\", bbox_to_anchor=(0.5, 0.5))\n",
    "for l in lgnd.legendHandles:\n",
    "    l._sizes = [20]\n",
    "\n",
    "plt.figure(legendFig)\n",
    "out_fn = cluster_size_dir + '/all_taxa_clusters_size_distribution_legend.png'\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot slope for each taxon in each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smin = 1e10\n",
    "smax = -1e10\n",
    "\n",
    "dict_group_sgroup = {\n",
    "    \"healthy_implant\": \"healthy\",\n",
    "    \"severe_implant\": \"disease\",\n",
    "    \"moderate_implant\": \"disease\",\n",
    "    \"mucositis_implant\": \"disease\",\n",
    "    \"periodontitis_tooth\": \"disease\",\n",
    "    \"healthy_tooth\": \"healthy\",\n",
    "}\n",
    "\n",
    "dict_scn_slopes = defaultdict(list)\n",
    "dict_scn_groups = defaultdict(list)\n",
    "for sn, dict_scn_clsize in dict_sn_scn_clsize.items():\n",
    "    group = dict_sn_group[sn]\n",
    "    if 'implant' in group:\n",
    "        for scn, clsizes in dict_scn_clsize.items():\n",
    "            if len(clsizes) > 3:\n",
    "                if scn == \"Neisseria\":\n",
    "                    scn = \"Neisseriaceae\"\n",
    "                elif scn == \"TM7\":\n",
    "                    scn = \"Saccharibacteria\"\n",
    "                elif scn == \"TM\":\n",
    "                    scn = \"Saccharibacteria\"\n",
    "\n",
    "                # color = dict_sciname_color[scn]\n",
    "                counts_sort = np.sort(np.array(clsizes))\n",
    "                nclust = len(counts_sort)\n",
    "                Pr = np.array([r / nclust for r in range(nclust, 0, -1)])\n",
    "\n",
    "                bool_l = counts_sort > 20\n",
    "                bool_u = counts_sort < 1e4\n",
    "                lnc = np.log(counts_sort[bool_l * bool_u])\n",
    "                lnp = np.log(Pr[bool_l * bool_u])\n",
    "\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(lnc, lnp)\n",
    "                if not np.isnan(slope):\n",
    "                    dict_scn_slopes[scn].append(slope)\n",
    "                    dict_scn_groups[scn].append(group)\n",
    "\n",
    "\n",
    "means = [np.median(s) for s in dict_scn_slopes.values()]\n",
    "scns = [s for s in dict_scn_slopes.keys()]\n",
    "scns_sort = [x for _, x in sorted(zip(means, scns))]\n",
    "\n",
    "\n",
    "xticks = np.arange(len(scns_sort)) + 1\n",
    "dict_sciname_ind = dict(zip(scns_sort, xticks))\n",
    "# dict_sciname_ind[\"Neisseria\"] = dict_sciname_ind[\"Neisseriaceae\"]\n",
    "# dict_sciname_ind[\"Saccharibacteria\"] = dict_sciname_ind[\"TM7\"]\n",
    "# dict_sciname_ind[\"TM\"] = dict_sciname_ind[\"TM7\"]\n",
    "\n",
    "s=100\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(20,10), ft=20)\n",
    "x = 1\n",
    "# scn_list = []\n",
    "# xticks = []\n",
    "for scn in scns_sort:\n",
    "    x = dict_sciname_ind[scn]\n",
    "    slopes = dict_scn_slopes[scn]\n",
    "    slopes = -np.array(slopes) \n",
    "    xs = [x] * len(slopes) + np.random.rand(len(slopes)) * 0.2 - 0.1\n",
    "    color = dict_sciname_color[scn]\n",
    "    # box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5)\n",
    "    box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5, patch_artist=True)\n",
    "    for k, vs in box.items():\n",
    "        for v in vs:\n",
    "            v.set_color('k')\n",
    "            v.set_alpha(0.25)\n",
    "            # if k == 'boxes':\n",
    "            # v.set_facecolor(\"k\")\n",
    "\n",
    "    groups = np.array(dict_scn_groups[scn])\n",
    "\n",
    "    ax.scatter(xs[groups == \"healthy_implant\"], slopes[groups == \"healthy_implant\"], color=\"tab:blue\", s=s)\n",
    "    ax.scatter(xs[groups == \"mucositis_implant\"], slopes[groups == \"mucositis_implant\"], color=\"tab:green\", s=s)\n",
    "    ax.scatter(xs[groups == \"peri_implantitis\"], slopes[groups == \"peri_implantitis\"], color=\"tab:red\", s=s)\n",
    "\n",
    "\n",
    "    \n",
    "    x += 1\n",
    "\n",
    "_ = ax.set_xticks(\n",
    "    xticks, scns_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    ")\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylabel(\"Power law eponent for each tilescan\")\n",
    "\n",
    "\n",
    "# out_fn = cluster_size_dir + \"/size_distribution_by_sample_group_{}.png\".format(\n",
    "#     group\n",
    "# )\n",
    "# ip.check_dir(out_fn)\n",
    "# ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toplot = ['Streptococcus','Lautropia', 'Porphyromonas','Selenomonas','Neisseriaceeae','Veillonella', 'Pasteurellaceae','Prevotella']\n",
    "\n",
    "s=5\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(2,2), ft=7)\n",
    "x = 1\n",
    "scn_list = []\n",
    "xticks = []\n",
    "for scn in scns_sort:\n",
    "    if scn in toplot:\n",
    "        # x = dict_sciname_ind[scn]\n",
    "        slopes = dict_scn_slopes[scn]\n",
    "        slopes = -np.array(slopes) \n",
    "        xs = [x] * len(slopes) + np.random.rand(len(slopes)) * 0.2 - 0.1\n",
    "        color = dict_sciname_color[scn]\n",
    "        # box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5)\n",
    "        box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5, patch_artist=True)\n",
    "        for k, vs in box.items():\n",
    "            for v in vs:\n",
    "                v.set_color('k')\n",
    "                v.set_alpha(0.25)\n",
    "                # if k == 'boxes':\n",
    "                # v.set_facecolor(\"k\")\n",
    "\n",
    "        groups = np.array(dict_scn_groups[scn])\n",
    "\n",
    "        ax.scatter(xs[groups == \"healthy_implant\"], slopes[groups == \"healthy_implant\"], color=\"tab:blue\", s=s)\n",
    "        ax.scatter(xs[groups == \"mucositis_implant\"], slopes[groups == \"mucositis_implant\"], color=\"tab:green\", s=s)\n",
    "        ax.scatter(xs[groups == \"peri_implantitis\"], slopes[groups == \"peri_implantitis\"], color=\"tab:red\", s=s)\n",
    "\n",
    "        scn_list.append(scn)\n",
    "        xticks.append(x)\n",
    "        \n",
    "        x += 1\n",
    "\n",
    "_ = ax.set_xticks(\n",
    "    xticks, scn_list, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    ")\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylim(0,2)\n",
    "# ax.set_ylabel(\"Power law eponent for each tilescan\")\n",
    "\n",
    "\n",
    "out_fn = cluster_size_dir + \"/size_distribution_boxplot_select.pdf\"\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLot specific curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scns = ['Pasteurellaceae','Selenomonas']\n",
    "date = \"2023_02_08\"\n",
    "sn = \"hsdm_group_1_sample_12_fov_01\"\n",
    "key = date + \"_\" + sn\n",
    "\n",
    "dims = (2,1.5)\n",
    "ft=6\n",
    "lw=1\n",
    "\n",
    "fig, ax = ip.general_plot(dims=dims, ft=ft, lw=lw)\n",
    "for i, scn in enumerate(scns):\n",
    "    color = dict_sciname_color[scn]\n",
    "    clsizes = dict_sn_scn_clsize[key][scn]\n",
    "    counts_sort = np.sort(clsizes)\n",
    "    nclust = len(counts_sort)\n",
    "    Pr = np.array([r / nclust for r in range(nclust, 0, -1)])\n",
    "    ax.scatter(counts_sort, Pr, s=2, label=sn, color=color)\n",
    "    # Get slope\n",
    "    bool_l = counts_sort > 10\n",
    "    bool_u = counts_sort < 1e4\n",
    "    lnc = np.log(counts_sort[bool_l * bool_u])\n",
    "    lnp = np.log(Pr[bool_l * bool_u])\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lnc, lnp)\n",
    "    # PLot slope\n",
    "    x = [2e1, 1e4]\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.plot(x, y, color=color)\n",
    "    x = 3e2\n",
    "    y = (math.exp(intercept) * x**slope)\n",
    "    print(scn)\n",
    "    print('Slope: ',slope)\n",
    "    print('rsqure: ',r_value**2)\n",
    "    # if i == 1:\n",
    "    #     ax.text(x, y, scn + \":\\nSlope = \" + str(round(slope, 2)) + \", R^2 = \" + str(round(r_value**2, 3)), color=color, ha=\"left\", va=\"bottom\", fontsize=ft)\n",
    "    # else:\n",
    "    #     ax.text(x, y, scn + \":\\nSlope = \" + str(round(slope, 2)) + \", R^2 = \" + str(round(r_value**2, 3)), color=color, ha=\"right\", va=\"top\", fontsize=ft)\n",
    "\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "# _ = ax.set_xlabel(\"log(number of cells)\")\n",
    "# _ = ax.set_ylabel(\"log(Pr(ncells > x))\")\n",
    "\n",
    "spatial_dir = out_dir + '/spatial_statistics'\n",
    "cl_size_dir = spatial_dir + '/cluster_size'\n",
    "cluster_slope_fmt = cl_size_dir + '/plots/{date}_{sn}_scinames_{scn0}_{scn1}_power_law_plot.pdf'\n",
    "out_fn = cluster_slope_fmt.format(date=date, sn=sn, scn0=scns[0], scn1=scns[1])\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot slope for each sciname in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smin = 1e10\n",
    "smax = -1e10\n",
    "\n",
    "\n",
    "dict_group_slopes = defaultdict(list)\n",
    "for sn, dict_scn_clsize in dict_sn_scn_clsize.items():\n",
    "    group = dict_sn_group[sn]\n",
    "    if 'implant' in group:\n",
    "        for scn, clsizes in dict_scn_clsize.items():\n",
    "            if len(clsizes) > 3:\n",
    "\n",
    "\n",
    "                # color = dict_sciname_color[scn]\n",
    "                counts_sort = np.sort(np.array(clsizes))\n",
    "                nclust = len(counts_sort)\n",
    "                Pr = np.array([r / nclust for r in range(nclust, 0, -1)])\n",
    "\n",
    "                bool_l = counts_sort > 20\n",
    "                bool_u = counts_sort < 1e4\n",
    "                lnc = np.log(counts_sort[bool_l * bool_u])\n",
    "                lnp = np.log(Pr[bool_l * bool_u])\n",
    "\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(lnc, lnp)\n",
    "                if not np.isnan(slope):\n",
    "                    dict_group_slopes[group].append(slope)\n",
    "            # x = dict_sciname_ind[scn] + np.random.rand()*0.5 - 0.25 + 1\n",
    "            # ax.scatter([x], [-slope], s=2, color=color)\n",
    "\n",
    "scns_sort = ['healthy_implant', 'mucositis_implant', 'peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(scns_sort)) + 1\n",
    "dict_sciname_ind = dict(zip(scns_sort, xticks))\n",
    "# dict_sciname_ind[\"Neisseria\"] = dict_sciname_ind[\"Neisseriaceae\"]\n",
    "# dict_sciname_ind[\"Saccharibacteria\"] = dict_sciname_ind[\"TM7\"]\n",
    "# dict_sciname_ind[\"TM\"] = dict_sciname_ind[\"TM7\"]\n",
    "\n",
    "s=5\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(2,2), ft=7)\n",
    "\n",
    "for scn in scns_sort:\n",
    "    x = dict_sciname_ind[scn]\n",
    "    slopes = dict_group_slopes[scn]\n",
    "    slopes = -np.array(slopes) \n",
    "    xs = [x] * len(slopes) + np.random.rand(len(slopes)) * 0.2 - 0.1\n",
    "    # color = dict_sciname_color[scn]\n",
    "    box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "    ax.scatter(xs, slopes, color='k', s=s)\n",
    "\n",
    "_ = ax.set_xticks(\n",
    "    xticks, scns_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    ")\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylim(0,2)\n",
    "# ax.set_ylabel('Power law eponent for each tilescan')\n",
    "\n",
    "out_fn = cluster_size_dir + \"/size_distribution_boxplot_bygroup.png\".format(\n",
    "    group\n",
    ")\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot slope for each tilescan in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smin = 1e10\n",
    "smax = -1e10\n",
    "\n",
    "\n",
    "dict_group_slopes = defaultdict(list)\n",
    "for sn, clsizes in dict_sn_clsizes.items():\n",
    "    group = dict_sn_group[sn]\n",
    "    if 'implant' in group:\n",
    "        if len(clsizes) > 3:\n",
    "\n",
    "\n",
    "            # color = dict_sciname_color[scn]\n",
    "            counts_sort = np.sort(np.array(clsizes))\n",
    "            nclust = len(counts_sort)\n",
    "            Pr = np.array([r / nclust for r in range(nclust, 0, -1)])\n",
    "\n",
    "            bool_l = counts_sort > 20\n",
    "            bool_u = counts_sort < 1e4\n",
    "            lnc = np.log(counts_sort[bool_l * bool_u])\n",
    "            lnp = np.log(Pr[bool_l * bool_u])\n",
    "\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(lnc, lnp)\n",
    "            if not np.isnan(slope):\n",
    "                dict_group_slopes[group].append(slope)\n",
    "        # x = dict_sciname_ind[scn] + np.random.rand()*0.5 - 0.25 + 1\n",
    "        # ax.scatter([x], [-slope], s=2, color=color)\n",
    "\n",
    "scns_sort = ['healthy_implant', 'mucositis_implant', 'peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(scns_sort)) + 1\n",
    "dict_sciname_ind = dict(zip(scns_sort, xticks))\n",
    "# dict_sciname_ind[\"Neisseria\"] = dict_sciname_ind[\"Neisseriaceae\"]\n",
    "# dict_sciname_ind[\"Saccharibacteria\"] = dict_sciname_ind[\"TM7\"]\n",
    "# dict_sciname_ind[\"TM\"] = dict_sciname_ind[\"TM7\"]\n",
    "\n",
    "s=5\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(2,2), ft=7)\n",
    "\n",
    "for scn in scns_sort:\n",
    "    x = dict_sciname_ind[scn]\n",
    "    slopes = dict_group_slopes[scn]\n",
    "    slopes = -np.array(slopes) \n",
    "    xs = [x] * len(slopes) + np.random.rand(len(slopes)) * 0.2 - 0.1\n",
    "    # color = dict_sciname_color[scn]\n",
    "    box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "    ax.scatter(xs, slopes, color='k', s=s)\n",
    "\n",
    "_ = ax.set_xticks(\n",
    "    xticks, scns_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    ")\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylim(0,2)\n",
    "# ax.set_ylabel('Power law eponent for each tilescan')\n",
    "\n",
    "out_fn = cluster_size_dir + \"/size_distribution_boxplot_tiles_bygroup.png\".format(\n",
    "    group\n",
    ")\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.log(36) - np.log(9)) / (np.log(4) - np.log(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scns_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Count things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../outputs/{date}/{date}_{sn}\"\n",
    "\n",
    "out_dir_seg = out_dir + '/segs'\n",
    "props_fmt = out_dir_seg + \"/{date}_{sn}_M_{m}_props.csv\"\n",
    "\n",
    "spatial_dir = out_dir + '/spatial_statistics'\n",
    "cl_size_dir = spatial_dir + '/cluster_size'\n",
    "cluster_size_fmt = cl_size_dir + '/{date}_{sn}_sciname_{scn}_cluster_size.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_group_counts = defaultdict(dict)\n",
    "# for group, sns in dict_group_sn.items():\n",
    "#     n_scans = 0\n",
    "#     n_tiles = 0\n",
    "#     n_cells = 0 \n",
    "#     n_clusters = 0\n",
    "#     for s in sns:\n",
    "#         n_scans += 1\n",
    "#         # date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", s)\n",
    "#         # props_glob = props_fmt.format(date=date, sn=sn, m='*')\n",
    "#         # props_fns = glob.glob(props_glob)\n",
    "#         # n_tiles += len(props_fns)\n",
    "#         # for pfn in props_fns:\n",
    "#         #     prop = pd.read_csv(pfn)\n",
    "#         #     n_cells += prop.shape[0]\n",
    "        \n",
    "#         # cl_glob = cluster_size_fmt.format(date=date, sn=sn, scn='*')\n",
    "#         # cl_fns = glob.glob(cl_glob)\n",
    "#         # for fn in cl_fns:\n",
    "#         #     clust = np.load(fn)\n",
    "#         #     n_clusters += len(np.unique(clust))\n",
    "#     dict_group_counts[group]['scans'] = n_scans\n",
    "#     # dict_group_counts[group]['tiles'] = n_tiles\n",
    "#     # dict_group_counts[group]['cells'] = n_cells\n",
    "#     # dict_group_counts[group]['clusters'] = n_clusters\n",
    "\n",
    "# dict_group_counts\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "np.zeros_like(a, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_counts = defaultdict(dict)\n",
    "for group, sns in dict_group_sn.items():\n",
    "    n_scans = 0\n",
    "    n_tiles = 0\n",
    "    n_cells = 0 \n",
    "    n_clusters = 0\n",
    "    for s in sns:\n",
    "        n_scans += 1\n",
    "        # date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", s)\n",
    "        # props_glob = props_fmt.format(date=date, sn=sn, m='*')\n",
    "        # props_fns = glob.glob(props_glob)\n",
    "        # n_tiles += len(props_fns)\n",
    "        # for pfn in props_fns:\n",
    "        #     prop = pd.read_csv(pfn)\n",
    "        #     n_cells += prop.shape[0]\n",
    "        \n",
    "        # cl_glob = cluster_size_fmt.format(date=date, sn=sn, scn='*')\n",
    "        # cl_fns = glob.glob(cl_glob)\n",
    "        # for fn in cl_fns:\n",
    "        #     clust = np.load(fn)\n",
    "        #     n_clusters += len(np.unique(clust))\n",
    "    dict_group_counts[group]['scans'] = n_scans\n",
    "    # dict_group_counts[group]['tiles'] = n_tiles\n",
    "    # dict_group_counts[group]['cells'] = n_cells\n",
    "    # dict_group_counts[group]['clusters'] = n_clusters\n",
    "\n",
    "dict_group_counts\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(dict_group_counts).T\n",
    "b = a[(a.index != 'healthy_tooth') & (a.index != 'periodontitis_tooth')]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.tiles.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.cells.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting post exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_counts = defaultdict(dict)\n",
    "for gr, ps_dict in dict_group_pat_sn.items():\n",
    "    n_pats = 0\n",
    "    n_scans = 0\n",
    "    n_tiles = 0\n",
    "    n_cells = 0 \n",
    "    for pat, sns in ps_dict.items():\n",
    "        n_unexcluded = 0\n",
    "        for bn in sns:\n",
    "            if bn not in exclude_sns:\n",
    "                n_unexcluded += 1\n",
    "        if n_unexcluded > 0:\n",
    "            n_pats += 1\n",
    "            for bn in sns:\n",
    "                if bn not in exclude_sns:\n",
    "                    n_scans += 1\n",
    "                    date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "                    props_glob = props_fmt.format(date=date, sn=sn, m='*')\n",
    "                    props_fns = glob.glob(props_glob)\n",
    "                    n_tiles += len(props_fns)\n",
    "                    for pfn in props_fns:\n",
    "                        prop = pd.read_csv(pfn)\n",
    "                        n_cells += prop.shape[0]\n",
    "    dict_group_counts[gr]['pats'] = n_pats     \n",
    "    dict_group_counts[gr]['scans'] = n_scans     \n",
    "    dict_group_counts[gr]['tiles'] = n_tiles    \n",
    "    dict_group_counts[gr]['cells'] = n_cells  \n",
    "\n",
    "                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict_group_counts).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict_group_counts).T.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box counting dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scn_unq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window.bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cells window\n",
    "convex_hull = ps.cg.convex_hull(coords.tolist())\n",
    "ch_arr = np.array(to_ccf(convex_hull))\n",
    "# plt.plot(ch_arr[:, 1], ch_arr[:, 0])\n",
    "# plt.gca().invert_yaxis()\n",
    "window = Window([convex_hull])\n",
    "\n",
    "# Get boxes initial\n",
    "bbox = window.bbox\n",
    "w_shp = [bbox[2] - bbox[0], bbox[3] - bbox[1]]\n",
    "dmin = np.min(w_shp)\n",
    "dmax = np.max(w_shp)\n",
    "ind_dmin = np.argmin(w_shp)\n",
    "ind_dmax = np.argmax(w_shp)\n",
    "dim_xy_init = np.array([0,0])\n",
    "dim_xy_init[ind_dmin] = 2\n",
    "ndmax = int(math.ceil(dmax / dmin))\n",
    "dim_xy_init[ind_dmax] = ndmax\n",
    "dmax_i_um_init = dmax / dim_xy_init[ind_dmax] * res_umpix\n",
    "\n",
    "# # Get hexagon length initial\n",
    "# lh_init = 100\n",
    "\n",
    "# minimum box size um\n",
    "dmiu_min = 5\n",
    "\n",
    "slopes = []\n",
    "for scn in scn_unq:\n",
    "    if scn != 'Prevotella':\n",
    "        fig, ax = ip.general_plot()\n",
    "        print(scn)\n",
    "        # Get point pattern\n",
    "        col_obs = dict_sciname_color[scn]\n",
    "        bool_scn = scinames == scn\n",
    "        coord_scn = coords[bool_scn]\n",
    "        pp = PointPattern(coord_scn, window=window)\n",
    "\n",
    "        # Get qstatistic\n",
    "        dxy = dim_xy_init.copy()\n",
    "        dmax_i_um = dmax_i_um_init.copy()\n",
    "        counts = []\n",
    "        box_size = []\n",
    "        while dmax_i_um > dmiu_min:\n",
    "            # q_r = qs.QStatistic(pp, shape=\"rectangle\", nx=dxy[1], ny=dxy[0])\n",
    "            # lh = lh_init\n",
    "            # q_r = qs.QStatistic(pp, shape=\"hexagon\", lh=lh)\n",
    "            # q_r.plot()\n",
    "            rect = RectangleM(pp, dxy[1], dxy[0]).point_location_sta()\n",
    "            c = np.array(list(rect.values()))\n",
    "            count = sum(c > 0)\n",
    "            counts.append(count)\n",
    "            box_size.append(dmax_i_um)\n",
    "\n",
    "            dxy *= 2\n",
    "            dmax_i_um = dmax / dxy[ind_dmax] * res_umpix\n",
    "\n",
    "        # Get regression\n",
    "        lnc = np.log(counts)\n",
    "        lns = np.log(box_size)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "        print(slope)\n",
    "        slopes.append(-slope)\n",
    "\n",
    "\n",
    "        ax.scatter(box_size, counts, color=col_obs, label=scn)\n",
    "\n",
    "    \n",
    "        x = np.array([min(box_size), max(box_size)])\n",
    "        y = math.exp(intercept) * x**slope\n",
    "        ax.plot(x, y, color=col_obs)\n",
    "        x = 40\n",
    "        y = math.exp(intercept) * x**slope\n",
    "        # ax.text(\n",
    "        #     x,\n",
    "        #     y,\n",
    "        #     \"Slope = \" + str(round(smean, 2)) + \", R^2 = \" + str(round(r_value**2, 3)),\n",
    "        #     color=\"r\",\n",
    "        #     ha=\"left\",\n",
    "        #     va=\"bottom\",\n",
    "        # )\n",
    "\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(np.array([3,4])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cells window\n",
    "convex_hull = ps.cg.convex_hull(coords.tolist())\n",
    "ch_arr = np.array(to_ccf(convex_hull))\n",
    "# plt.plot(ch_arr[:, 1], ch_arr[:, 0])\n",
    "# plt.gca().invert_yaxis()\n",
    "window = Window([convex_hull])\n",
    "\n",
    "# Get boxes initial\n",
    "bbox = window.bbox\n",
    "w_shp = np.array([bbox[2] - bbox[0], bbox[3] - bbox[1]])\n",
    "box_edge_init_um = 50\n",
    "box_edge_init = box_edge_init_um / res_umpix\n",
    "box_edge_min_um = 5\n",
    "box_edge_min = box_edge_min_um / res_umpix\n",
    "\n",
    "# dmin = np.min(w_shp)\n",
    "# dmax = np.max(w_shp)\n",
    "# ind_dmin = np.argmin(w_shp)\n",
    "# ind_dmax = np.argmax(w_shp)\n",
    "# dim_xy_init = np.array([0,0])\n",
    "# dim_xy_init[ind_dmin] = 2\n",
    "# ndmax = int(math.ceil(dmax / dmin))\n",
    "# dim_xy_init[ind_dmax] = ndmax\n",
    "# dmax_i_um_init = dmax / dim_xy_init[ind_dmax] * res_umpix\n",
    "\n",
    "# # Get hexagon length initial\n",
    "# lh_init = 100\n",
    "\n",
    "# minimum box size um\n",
    "# dmiu_min = 5\n",
    "\n",
    "slopes = []\n",
    "for scn in scn_unq:\n",
    "    # if scn != 'Prevotella':\n",
    "    fig, ax = ip.general_plot()\n",
    "    print(scn)\n",
    "    # Get point pattern\n",
    "    col_obs = dict_sciname_color[scn]\n",
    "    bool_scn = scinames == scn\n",
    "    coord_scn = coords[bool_scn]\n",
    "    pp = PointPattern(coord_scn, window=window)\n",
    "\n",
    "    # Get qstatistic\n",
    "    box_edge_um = box_edge_init_um\n",
    "    counts = []\n",
    "    box_size = []\n",
    "    while box_edge_um >= box_edge_min_um:\n",
    "        box_edge = box_edge_um / res_umpix\n",
    "        nxy = np.ceil(w_shp / box_edge).astype(int)\n",
    "        # q_r = qs.QStatistic(pp, shape=\"rectangle\", nx=dxy[1], ny=dxy[0])\n",
    "        # lh = lh_init\n",
    "        # q_r = qs.QStatistic(pp, shape=\"hexagon\", lh=lh)\n",
    "        # q_r.plot()\n",
    "        rect = RectangleM(pp, nxy[1], nxy[0]).point_location_sta()\n",
    "        c = np.array(list(rect.values()))\n",
    "        count = sum(c > 0)\n",
    "        counts.append(count)\n",
    "        dxy = w_shp / nxy\n",
    "        diag = np.sqrt(np.sum(dxy**2))\n",
    "        diag_um = diag * res_umpix\n",
    "        box_size.append(diag_um)\n",
    "\n",
    "        box_edge_um -= 5\n",
    "\n",
    "    # Get regression\n",
    "    lnc = np.log(counts)\n",
    "    lns = np.log(box_size)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    print(slope, r_value**2)\n",
    "    slopes.append(-slope)\n",
    "\n",
    "\n",
    "    ax.scatter(box_size, counts, color=col_obs, label=scn)\n",
    "\n",
    "\n",
    "    x = np.array([min(box_size), max(box_size)])\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.plot(x, y, color=col_obs)\n",
    "    x = 40\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    # ax.text(\n",
    "    #     x,\n",
    "    #     y,\n",
    "    #     \"Slope = \" + str(round(smean, 2)) + \", R^2 = \" + str(round(r_value**2, 3)),\n",
    "    #     color=\"r\",\n",
    "    #     ha=\"left\",\n",
    "    #     va=\"bottom\",\n",
    "    # )\n",
    "\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0]*len(slopes)) \n",
    "plt.scatter(x, slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of homogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define new function for Rectangle class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleM_new:\n",
    "    \"\"\"\n",
    "    Rectangle grid structure for quadrat-based method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pp                : :class:`.PointPattern`\n",
    "                        Point Pattern instance.\n",
    "    count_column      : integer\n",
    "                        Number of rectangles in the horizontal\n",
    "                        direction. Use in pair with count_row to\n",
    "                        fully specify a rectangle. Incompatible with\n",
    "                        rectangle_width and rectangle_height.\n",
    "    count_row         : integer\n",
    "                        Number of rectangles in the vertical\n",
    "                        direction. Use in pair with count_column to\n",
    "                        fully specify a rectangle. Incompatible with\n",
    "                        rectangle_width and rectangle_height.\n",
    "    rectangle_width   : float\n",
    "                        Rectangle width. Use in pair with\n",
    "                        rectangle_height to fully specify a rectangle.\n",
    "                        Incompatible with count_column & count_row.\n",
    "    rectangle_height  : float\n",
    "                        Rectangle height. Use in pair with\n",
    "                        rectangle_width to fully specify a rectangle.\n",
    "                        Incompatible with count_column & count_row.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    pp                : :class:`.PointPattern`\n",
    "                        Point Pattern instance.\n",
    "    mbb               : array\n",
    "                        Minimum bounding box for the point pattern.\n",
    "    points            : array\n",
    "                        x,y coordinates of the point points.\n",
    "    count_column      : integer\n",
    "                        Number of columns.\n",
    "    count_row         : integer\n",
    "                        Number of rows.\n",
    "    num               : integer\n",
    "                        Number of rectangular quadrats.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pp, labels, count_column = 3, count_row = 3,\n",
    "                 rectangle_width = 0, rectangle_height = 0):\n",
    "        self.mbb = pp.mbb\n",
    "        self.pp = pp\n",
    "        self.points = np.asarray(pp.points)\n",
    "        self.labels = np.array(labels)\n",
    "        x_range = self.mbb[2]-self.mbb[0]\n",
    "        y_range = self.mbb[3]-self.mbb[1]\n",
    "        if rectangle_width & rectangle_height:\n",
    "            self.rectangle_width = rectangle_width\n",
    "            self.rectangle_height = rectangle_height\n",
    "\n",
    "            # calculate column count and row count\n",
    "            self.count_column = int(math.ceil(x_range / rectangle_width))\n",
    "            self.count_row = int(math.ceil(y_range / rectangle_height))\n",
    "        else:\n",
    "            self.count_column = count_column\n",
    "            self.count_row = count_row\n",
    "\n",
    "            # calculate the actual width and height of cell\n",
    "            self.rectangle_width = x_range/float(count_column)\n",
    "            self.rectangle_height = y_range/float(count_row)\n",
    "        self.num = self.count_column * self.count_row\n",
    "\n",
    "\n",
    "    def point_location_sta(self):\n",
    "        \"\"\"\n",
    "        Count the point events in each cell.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict_id_count : dict\n",
    "                        keys: rectangle id, values: number of point\n",
    "                        events in each cell.\n",
    "        \"\"\"\n",
    "\n",
    "        dict_id_count = {}\n",
    "        for i in range(self.count_row):\n",
    "            for j in range(self.count_column):\n",
    "                dict_id_count[j+i*self.count_column] = 0\n",
    "\n",
    "        for point in self.points:\n",
    "            index_x = (point[0]-self.mbb[0]) // self.rectangle_width\n",
    "            index_y = (point[1]-self.mbb[1]) // self.rectangle_height\n",
    "            if index_x == self.count_column:\n",
    "                index_x -= 1\n",
    "            if index_y == self.count_row:\n",
    "                index_y -= 1\n",
    "            id = index_y * self.count_column + index_x\n",
    "            dict_id_count[id] += 1\n",
    "        return dict_id_count\n",
    "\n",
    "    def _get_dict_id_labels(self):\n",
    "        \"\"\"\n",
    "        Get a list of labels in each cell.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict_id_count : dict\n",
    "                        keys: rectangle id, values: number of point\n",
    "                        events in each cell.\n",
    "        \"\"\"\n",
    "\n",
    "        # dict_id_count = {}\n",
    "        # for i in range(self.count_row):\n",
    "        #     for j in range(self.count_column):\n",
    "        #         dict_id_points[j+i*self.count_column] = []\n",
    "        dict_id_labels = defaultdict(list)\n",
    "        for point, lab in zip(self.points, self.labels):\n",
    "            index_x = (point[0]-self.mbb[0]) // self.rectangle_width\n",
    "            index_y = (point[1]-self.mbb[1]) // self.rectangle_height\n",
    "            if index_x == self.count_column:\n",
    "                index_x -= 1\n",
    "            if index_y == self.count_row:\n",
    "                index_y -= 1\n",
    "            id = index_y * self.count_column + index_x\n",
    "            dict_id_labels[id].append(lab)\n",
    "        self.dict_id_labels = dict_id_labels\n",
    "\n",
    "    def get_shannon_diversities(self):\n",
    "        self._get_dict_id_labels()\n",
    "        dict_idx_shannon = {}\n",
    "        for idx, labels in self.dict_id_labels.items():\n",
    "            labels = np.array(labels)\n",
    "            nlab = len(labels)\n",
    "            Hs = []\n",
    "            for l in np.unique(labels):\n",
    "                nl = sum(labels==l)\n",
    "                p = nl / nlab\n",
    "                Hs.append(p * np.log(p))\n",
    "            H = -np.sum(Hs)\n",
    "            dict_idx_shannon[idx] = H\n",
    "        return dict_idx_shannon\n",
    "\n",
    "    def get_simpson_diversities(self):\n",
    "        self._get_dict_id_labels()\n",
    "        dict_idx_simpson = {}\n",
    "        for idx, labels in self.dict_id_labels.items():\n",
    "            labels = np.array(labels)\n",
    "            nlab = len(labels)\n",
    "            if nlab > 1:\n",
    "                etas = []\n",
    "                for l in np.unique(labels):\n",
    "                    nl = sum(labels==l)\n",
    "                    etas.append(nl*(nl-1))\n",
    "                D = 1 - np.sum(etas) / (nlab*(nlab-1))\n",
    "            else:\n",
    "                D = 0\n",
    "            dict_idx_simpson[idx] = D\n",
    "        return dict_idx_simpson\n",
    "\n",
    "    def get_multispecies_tiles(self):\n",
    "        self._get_dict_id_labels()\n",
    "        dict_idx_multi = {}\n",
    "        for idx, labels in self.dict_id_labels.items():\n",
    "            c = 0\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                c = 1\n",
    "            dict_idx_multi[idx] = c\n",
    "        return dict_idx_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([])\n",
    "nlab = len(labels)\n",
    "etas = []\n",
    "for l in np.unique(labels):\n",
    "    nl = sum(labels==l)\n",
    "    etas.append(nl*(nl-1))\n",
    "D = 1 - np.sum(etas) / (nlab*(nlab-1))\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do fuzzy box counting on shannon diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2023_02_08\"\n",
    "sn = \"hsdm_group_1_sample_12_fov_01\"\n",
    "\n",
    "centroid_sciname_fn = centroid_sciname_fmt.format(date=date, sn=sn)\n",
    "centroid_sciname = pd.read_csv(centroid_sciname_fn)\n",
    "coords = np.array([eval(c) for c in centroid_sciname[\"coord\"].values])\n",
    "scinames = centroid_sciname[\"sciname\"].values\n",
    "scn_unq = np.unique(scinames)\n",
    "\n",
    "# Get cells window\n",
    "convex_hull = ps.cg.convex_hull(coords.tolist())\n",
    "ch_arr = np.array(to_ccf(convex_hull))\n",
    "# plt.plot(ch_arr[:, 1], ch_arr[:, 0])\n",
    "# plt.gca().invert_yaxis()\n",
    "window = Window([convex_hull])\n",
    "\n",
    "# Get boxes initial\n",
    "bbox = window.bbox\n",
    "# w_shp = np.array([bbox[2] - bbox[0], bbox[3] - bbox[1]])\n",
    "box_edge_init_um = 50\n",
    "div_edgesize = 1.5\n",
    "box_edge_min_um = 5\n",
    "col='k'\n",
    "\n",
    "# if scn != 'Prevotella':\n",
    "fig, ax = ip.general_plot()\n",
    "# Get point pattern\n",
    "pp = PointPattern(coords, window=window)\n",
    "\n",
    "# Get qstatistic\n",
    "box_edge_um = box_edge_init_um\n",
    "counts = []\n",
    "box_size = []\n",
    "while box_edge_um >= box_edge_min_um:\n",
    "    print(box_edge_um)\n",
    "    box_edge = box_edge_um / res_umpix\n",
    "    nxy = np.ceil(w_shp / box_edge).astype(int)\n",
    "\n",
    "    rect = RectangleM_new(\n",
    "        pp, \n",
    "        count_column = nxy[1], \n",
    "        count_row = nxy[1],\n",
    "        labels=scinames\n",
    "    ).get_simpson_diversities()\n",
    "    Hs = np.array(list(rect.values()))\n",
    "    count = sum(Hs)\n",
    "    print(count)\n",
    "    counts.append(count)\n",
    "    dxy = w_shp / nxy\n",
    "    diag = np.sqrt(np.sum(dxy**2))\n",
    "    diag_um = diag * res_umpix\n",
    "    box_size.append(diag_um)\n",
    "\n",
    "    box_edge_um /= div_edgesize\n",
    "\n",
    "# Get regression\n",
    "lnc = np.log(counts)\n",
    "lns = np.log(box_size)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "print(slope, r_value**2)\n",
    "slopes.append(-slope)\n",
    "\n",
    "\n",
    "ax.scatter(box_size, counts, color=col, label=scn)\n",
    "\n",
    "\n",
    "x = np.array([min(box_size), max(box_size)])\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.plot(x, y, color=col)\n",
    "x = 40\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(box_edge_um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Hs == 0) / len(Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2023_10_18\"\n",
    "sn = \"hsdm_slide_IIL_fov_01\"\n",
    "\n",
    "centroid_sciname_fn = centroid_sciname_fmt.format(date=date, sn=sn)\n",
    "centroid_sciname = pd.read_csv(centroid_sciname_fn)\n",
    "coords = np.array([eval(c) for c in centroid_sciname[\"coord\"].values])\n",
    "scinames = centroid_sciname[\"sciname\"].values\n",
    "scn_unq = np.unique(scinames)\n",
    "\n",
    "# Get cells window\n",
    "convex_hull = ps.cg.convex_hull(coords.tolist())\n",
    "ch_arr = np.array(to_ccf(convex_hull))\n",
    "# plt.plot(ch_arr[:, 1], ch_arr[:, 0])\n",
    "# plt.gca().invert_yaxis()\n",
    "window = Window([convex_hull])\n",
    "\n",
    "# Get boxes initial\n",
    "bbox = window.bbox\n",
    "w_shp = np.array([bbox[2] - bbox[0], bbox[3] - bbox[1]])\n",
    "box_edge_init_um = 50\n",
    "div_edgesize = 1.5\n",
    "box_edge_min_um = 5\n",
    "col='k'\n",
    "\n",
    "# if scn != 'Prevotella':\n",
    "fig, ax = ip.general_plot()\n",
    "# Get point pattern\n",
    "pp = PointPattern(coords, window=window)\n",
    "\n",
    "# Get qstatistic\n",
    "box_edge_um = box_edge_init_um\n",
    "counts = []\n",
    "box_size = []\n",
    "while box_edge_um >= box_edge_min_um:\n",
    "    box_edge = box_edge_um / res_umpix\n",
    "    nxy = np.ceil(w_shp / box_edge).astype(int)\n",
    "\n",
    "    rect = RectangleM_new(\n",
    "        pp, \n",
    "        count_column = nxy[1], \n",
    "        count_row = nxy[1],\n",
    "        labels=scinames\n",
    "    ).get_simpson_diversities()\n",
    "    # ).get_shannon_diversities()\n",
    "    Hs = np.array(list(rect.values()))\n",
    "    count = sum(Hs)\n",
    "    counts.append(count)\n",
    "    dxy = w_shp / nxy\n",
    "    diag = np.sqrt(np.sum(dxy**2))\n",
    "    diag_um = diag * res_umpix\n",
    "    box_size.append(diag_um)\n",
    "\n",
    "    box_edge_um /= div_edgesize\n",
    "\n",
    "# Get regression\n",
    "lnc = np.log(counts)\n",
    "lns = np.log(box_size)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "print(slope, r_value**2)\n",
    "slopes.append(-slope)\n",
    "\n",
    "\n",
    "ax.scatter(box_size, counts, color=col, label=scn)\n",
    "\n",
    "\n",
    "x = np.array([min(box_size), max(box_size)])\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.plot(x, y, color=col)\n",
    "x = 40\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Hs == 0) / len(Hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After running box counting on all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzzy box counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_box_count_all_fn = sample_compare_dir + '/fuzzy_box_counting_table.csv'\n",
    "fuzzy_box_count_all = pd.read_csv(fuzzy_box_count_all_fn, index_col=0)\n",
    "fuzzy_box_count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_box_count_all2_fn = sample_compare_dir + '/20240506/fuzzy_box_counting_table.csv'\n",
    "fuzzy_box_count_all2 = pd.read_csv(fuzzy_box_count_all2_fn, index_col=0)\n",
    "fuzzy_box_count_all2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_sns = [\n",
    "    '2023_10_16_hsdm_slide_IB_fov_01', \n",
    "    '2023_10_16_hsdm_slide_IB_fov_03', \n",
    "    '2023_10_16_hsdm_slide_IB_fov_02', \n",
    "    '2022_12_16_harvardwelch_patient_18_tooth_2_aspect_MB_depth__fov_01',\n",
    "    '2022_12_16_harvardwelch_patient_19_tooth_30_aspect_MB_depth_sub_fov_01',\n",
    "    '2023_02_18_hsdm_group_II_patient_7_fov_02',\n",
    "    '2023_02_18_hsdm_group_II_patient_7_fov_01',\n",
    "    '2024_04_16_hsdmgel_group_I_pat_10_asp_DL_fov_01',\n",
    "    '2024_04_16_hsdmgel_group_I_pat_10_asp_DL_fov_02',\n",
    "    '2024_04_27_hsdm_group_II_patient_12_aspect_DL_fov_01',\n",
    "    '2024_04_27_hsdm_group_II_patient_12_aspect_DL_fov_02',\n",
    "    '2024_04_27_hsdm_group_II_patient_12_aspect_DL_fov_03',\n",
    "    '2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_01',\n",
    "    '2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_02',\n",
    "    '2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_03',\n",
    "    '2024_04_16_hsdmgel_group_II_pat_14_asp_DB_fov_04',\n",
    "    '2024_04_27_hsdm_group_II_patient_8_aspect_DL_fov_01',\n",
    "    '2024_04_27_hsdm_group_II_patient_8_aspect_DL_fov_02',\n",
    "    '2023_10_18_hsdm_slide_IIIB_fov_01',\n",
    "    '2024_04_16_hsdmgel_group_III_pat_6_asp_ML_fov_01',\n",
    "    '2024_05_03_hsdm_group_III_patient_3_aspect_DL_fov_01',\n",
    "    '2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_01',\n",
    "    '2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_03',\n",
    "    '2024_04_24_hsdm_group_III_patient_5_aspect_DB_fov_04',\n",
    "    '2024_04_24_hsdm_group_III_patient_8_aspect_DB_fov_01',\n",
    "    '2024_04_24_hsdm_group_III_patient_8_aspect_DB_fov_02',    \n",
    "    '2024_05_03_hsdm_group_IV_patient_3_aspect_DL_fov_01',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_bcvals = defaultdict(list)\n",
    "for group, sns in dict_group_sn.items():\n",
    "    print(group)\n",
    "    for sn in sns:\n",
    "        if not sn in exclude_sns:\n",
    "            try:\n",
    "                bcval = -fuzzy_box_count_all.loc[sn,'slope']\n",
    "            except:\n",
    "                bcval = -fuzzy_box_count_all2.loc[sn,'slope']\n",
    "\n",
    "            dict_group_bcvals[group].append(bcval)\n",
    "            # if bcval > 1.85:\n",
    "            #     print(sn, bcval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'moderate_peri_implantitis', 'severe_peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "for group in group_sort:\n",
    "    x = dict_group_xtick[group]\n",
    "    bcvals = dict_group_bcvals[group]\n",
    "    xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "    # color = dict_sciname_color[scn]\n",
    "    box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "    ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "# _ = ax.set_xticks(\n",
    "#     xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "# )\n",
    "_ = ax.set_xticks([])\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylim(0,2)\n",
    "# ax.set_ylabel('Homogeneity\\n(Fuzzy box counting fractal dimension)')\n",
    "ax.set_ylim(1.4,2)\n",
    "out_fn = sample_compare_dir + \"/box_counting/fuzzy_box_counting_bygroup.pdf\".format(\n",
    "    group\n",
    ")\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g0 in group_sort:\n",
    "    for g1 in group_sort:\n",
    "        if g0 != g1:\n",
    "            bc0 = dict_group_bcvals[g0]\n",
    "            bc1 = dict_group_bcvals[g1]\n",
    "            print(g0, 'vs.', g1)\n",
    "            print(stats.ttest_ind(bc0,bc1, equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multispecies box counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_box_count_all_fn = sample_compare_dir + '/multispecies_box_counting_table.csv'\n",
    "fuzzy_box_count_all = pd.read_csv(fuzzy_box_count_all_fn, index_col=0)\n",
    "fuzzy_box_count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_sns = [\n",
    "    '2023_10_16_hsdm_slide_IB_fov_01', \n",
    "    '2023_10_16_hsdm_slide_IB_fov_03', \n",
    "    '2023_10_16_hsdm_slide_IB_fov_02', \n",
    "    '2022_12_16_harvardwelch_patient_18_tooth_2_aspect_MB_depth__fov_01',\n",
    "    '2022_12_16_harvardwelch_patient_19_tooth_15_aspect_MF_depth_sub_fov_01',\n",
    "    '2022_12_16_harvardwelch_patient_19_tooth_30_aspect_MB_depth_sub_fov_01',\n",
    "    '2023_02_18_hsdm_group_II_patient_7_fov_02',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_bcvals = defaultdict(list)\n",
    "for group, sns in dict_group_sn.items():\n",
    "    print(group)\n",
    "    for sn in sns:\n",
    "        if not sn in exclude_sns:\n",
    "            bcval = -fuzzy_box_count_all.loc[sn,'slope']\n",
    "            dict_group_bcvals[group].append(bcval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(4,5), ft=12)\n",
    "\n",
    "for group in group_sort:\n",
    "    x = dict_group_xtick[group]\n",
    "    bcvals = dict_group_bcvals[group]\n",
    "    xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "    # color = dict_sciname_color[scn]\n",
    "    box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "    ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "_ = ax.set_xticks(\n",
    "    xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    ")\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylim(0,2)\n",
    "ax.set_ylabel('Homogeneity\\n(Box counting fractal dimension)')\n",
    "ax.set_ylim(1,2)\n",
    "# out_fn = cluster_size_dir + \"/size_distribution_boxplot_bygroup.png\".format(\n",
    "#     group\n",
    "# )\n",
    "# ip.check_dir(out_fn)\n",
    "# ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine patient data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load values into dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dir = out_dir + '/spatial_statistics'\n",
    "fuzzy_box_counting_fmt = spatial_dir + '/box_counting/{date}_{sn}_fuzzy_box_counting_regression.csv'\n",
    "dict_group_pat_slopes = defaultdict(lambda: defaultdict(list))\n",
    "for gr, ps_dict in dict_group_pat_sn.items():\n",
    "    for pat, sns in ps_dict.items():\n",
    "        for bn in sns:\n",
    "            if bn not in exclude_sns:\n",
    "                date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "                fn = fuzzy_box_counting_fmt.format(date=date, sn=sn)\n",
    "                box_counting = pd.read_csv(fn)\n",
    "                slope = box_counting['slope'].values[0]\n",
    "                dict_group_pat_slopes[gr][pat].append(slope)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_slmeans = defaultdict(list)\n",
    "for gr, ps_dict in dict_group_pat_slopes.items():\n",
    "    for pat, slopes in ps_dict.items():\n",
    "        val = -np.mean(slopes)\n",
    "        dict_group_slmeans[gr].append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'mild_peri_implantitis', 'moderate_severe_peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "for group in group_sort:\n",
    "    x = dict_group_xtick[group]\n",
    "    bcvals = dict_group_slmeans[group]\n",
    "    xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "    # color = dict_sciname_color[scn]\n",
    "    box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "    ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "# _ = ax.set_xticks(\n",
    "#     xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "# )\n",
    "_ = ax.set_xticks([])\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylim(0,2)\n",
    "# ax.set_ylabel('Homogeneity\\n(Fuzzy box counting fractal dimension)')\n",
    "ax.set_ylim(1.5,2)\n",
    "\n",
    "out_fn = sample_compare_dir + \"/box_counting/fuzzy_box_counting_bygroup_patient.pdf\".format(\n",
    "    group\n",
    ")\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g0 in group_sort:\n",
    "    for g1 in group_sort:\n",
    "        if g0 != g1:\n",
    "            bc0 = dict_group_slmeans[g0]\n",
    "            bc1 = dict_group_slmeans[g1]\n",
    "            print(g0, 'vs.', g1)\n",
    "            print(stats.ttest_ind(bc0,bc1, equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal wallis test for difference in median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats.kruskal(\n",
    "    dict_group_slmeans[group_sort[0]],\n",
    "    dict_group_slmeans[group_sort[1]],\n",
    "    dict_group_slmeans[group_sort[2]],\n",
    "    dict_group_slmeans[group_sort[3]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunn pairwise test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posthoc_dunn(list(dict_group_slmeans.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posthoc_dunn(list(dict_group_slmeans.values()), p_adjust='bonferroni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot simpson diversity curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_pat_slopes['healthy_implant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Xas dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns = [\n",
    "    '2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_02',\n",
    "    '2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01'\n",
    "]\n",
    "\n",
    "cols = plt.get_cmap('tab10').colors\n",
    "dict_bn_col = {\n",
    "    '2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_02': cols[0],\n",
    "    '2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01':cols[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '../outputs/{date}/{date}_{sn}'\n",
    "spatial_dir = out_dir + '/spatial_statistics'\n",
    "multifractal_dir = spatial_dir + '/multifractal'\n",
    "local_diversity_dict_fmt = multifractal_dir + '/{date}_{sn}_dict_area_q_partition_vals.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bn_areas_Xas = {}\n",
    "for bn in sns:\n",
    "    date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "    print(date,sn)\n",
    "    ldd_fn = local_diversity_dict_fmt.format(date=date, sn=sn)\n",
    "    with open(ldd_fn, 'r') as f:\n",
    "        dict_area_q_Xas = yaml.unsafe_load(f)\n",
    "    areas = []\n",
    "    Dsums = []\n",
    "    for area, dict_q_Xas in dict_area_q_Xas.items():\n",
    "        areas.append(area)\n",
    "        Xas = dict_q_Xas[2]\n",
    "        Ds = 1 - np.array(Xas)\n",
    "        Dsums.append(np.sum(Ds))\n",
    "    dict_bn_areas_Xas[bn] = [areas, Dsums]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_size = 2\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(1.9,2.5), ft=6)\n",
    "for bn in sns:\n",
    "    areas, Dsums = dict_bn_areas_Xas[bn]\n",
    "    edges = np.array(areas) ** (1/2)\n",
    "    \n",
    "    lnc = np.log(Dsums)\n",
    "    lns = np.log(edges)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    print('fit: ',slope, ', r^2: ', r_value**2, ', intercept: ', intercept)\n",
    "\n",
    "    col = dict_bn_col[bn]\n",
    "    ax.scatter(edges, Dsums, color=col, s=marker_size)\n",
    "\n",
    "    x = np.array([min(edges), max(edges)])\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.plot(x, y, color=col)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")   \n",
    "    # ax.set_xticks([], labels=[])\n",
    "    ax.xaxis.set_minor_formatter(tck.NullFormatter())\n",
    "\n",
    "# Plot idealized slopes\n",
    "color = (0.5,0.5,0.5)\n",
    "linestyle = ':'\n",
    "\n",
    "x = np.array([min(edges), max(edges)])\n",
    "intercept = 12.25\n",
    "slope = -2\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.plot(x,y, color=color, ls=linestyle)\n",
    "\n",
    "x = np.array([min(edges), max(edges)])\n",
    "intercept = 6\n",
    "slope = -1\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.plot(x,y, color=color, ls=linestyle)\n",
    "\n",
    "sample_compare_dir =  '../outputs/compare_samples'\n",
    "out_fn = sample_compare_dir + \"/box_counting/fuzzy_box_counting_curves.pdf\"\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(dict_area_q_Xas.keys()))**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot simpson diversity curves cosdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns = [\n",
    "    '2023_02_08_hsdm_group_1_sample_06_fov_01',\n",
    "    '2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01'\n",
    "]\n",
    "\n",
    "cols = plt.get_cmap('tab10').colors\n",
    "dict_bn_col = {\n",
    "    '2023_02_08_hsdm_group_1_sample_06_fov_01': cols[0],\n",
    "    '2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01':cols[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dir = out_dir + '/spatial_statistics'\n",
    "multifractal_dir = spatial_dir + '/multifractal'\n",
    "local_diversity_dict_fmt = multifractal_dir + '/{date}_{sn}_dict_area_q_partition_vals.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bn_areas_Xas = {}\n",
    "for bn in sns:\n",
    "    date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "    print(date,sn)\n",
    "    ldd_fn = local_diversity_dict_fmt.format(date=date, sn=sn)\n",
    "    with open(ldd_fn, 'r') as f:\n",
    "        dict_area_q_Xas = yaml.unsafe_load(f)\n",
    "    areas = []\n",
    "    Dsums = []\n",
    "    for area, dict_q_Xas in dict_area_q_Xas.items():\n",
    "        areas.append(area)\n",
    "        Xas = dict_q_Xas[2]\n",
    "        Ds = 1 - np.array(Xas)\n",
    "        Dsums.append(np.sum(Ds))\n",
    "    dict_bn_areas_Xas[bn] = [areas, Dsums]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_size = 2\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(1.9,2.5), ft=6)\n",
    "for bn in sns:\n",
    "    areas, Dsums = dict_bn_areas_Xas[bn]\n",
    "    edges = np.array(areas) ** (1/2)\n",
    "    \n",
    "    lnc = np.log(Dsums)\n",
    "    lns = np.log(edges)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    print('fit: ',slope, ', r^2: ', r_value**2, ', intercept: ', intercept)\n",
    "\n",
    "    col = dict_bn_col[bn]\n",
    "    ax.scatter(edges, Dsums, color=col, s=marker_size)\n",
    "\n",
    "    x = np.array([min(edges), max(edges)])\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.plot(x, y, color=col)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")   \n",
    "    # ax.set_xticks([], labels=[])\n",
    "    ax.xaxis.set_minor_formatter(tck.NullFormatter())\n",
    "\n",
    "# Plot idealized slopes\n",
    "color = (0.5,0.5,0.5)\n",
    "linestyle = ':'\n",
    "\n",
    "x = np.array([min(edges), max(edges)])\n",
    "intercept = 12.25\n",
    "slope = -2\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.plot(x,y, color=color, ls=linestyle)\n",
    "\n",
    "x = np.array([min(edges), max(edges)])\n",
    "intercept = 6.5\n",
    "slope = -1\n",
    "y = math.exp(intercept) * x**slope\n",
    "ax.plot(x,y, color=color, ls=linestyle)\n",
    "\n",
    "sample_compare_dir =  '../outputs/compare_samples'\n",
    "out_fn = sample_compare_dir + \"/box_counting/fuzzy_box_counting_curves_cosdist.pdf\"\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(dict_area_q_Xas.keys()))**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot abundance of each genus grouped by clinical diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fmt_classif = out_dir + \"/classif\"\n",
    "abundances_fmt = out_fmt_classif + '/{date}_{sn}_scinames.npy'\n",
    "\n",
    "sciname_list = [\n",
    "    'Pasteurellaceae',\n",
    "    'Corynebacterium',\n",
    "    'Veillonella',\n",
    "    'Actinomyces',\n",
    "    'Selenomonas',\n",
    "    'Rothia',\n",
    "    'Porphyromonas',\n",
    "    'Capnocytophaga',\n",
    "    'Prevotella',\n",
    "    'Streptococcus',\n",
    "    'Gemella',\n",
    "    'Campylobacter',\n",
    "    'Lautropia',\n",
    "    'Leptotrichia',\n",
    "    'Neisseriaceae',\n",
    "    'Treponema',\n",
    "    'Fusobacterium',\n",
    "    'Saccharibacteria'\n",
    "]\n",
    "\n",
    "dict_sci_rename = {\n",
    "    'TM7':'Saccharibacteria',\n",
    "    'Neisseria':'Neisseriaceae'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_group_sn = {\n",
    "#     'a':['2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01'],\n",
    "#     'b':['2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_02']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_scn_abund = defaultdict(lambda: defaultdict(list))\n",
    "for group, sns in dict_group_sn.items():\n",
    "    print(group)\n",
    "    for sn_ in sns:\n",
    "        # Get fns\n",
    "        date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", sn_)\n",
    "        abundances_fn = abundances_fmt.format(date=date, sn=sn)\n",
    "\n",
    "        # Load files\n",
    "        abundances = np.load(abundances_fn)\n",
    "\n",
    "        # add values\n",
    "        ncells = len(abundances)\n",
    "        scn_unq = np.unique(abundances)\n",
    "        scn_used = []\n",
    "        for sciname in scn_unq:\n",
    "            scn = dict_sci_rename[sciname] if sciname in dict_sci_rename else sciname\n",
    "            abund = sum(abundances == sciname) / ncells\n",
    "            dict_group_scn_abund[group][scn].append(abund)\n",
    "            scn_used.append(scn)\n",
    "\n",
    "        # Zeros for missed taxa\n",
    "        for sciname in sciname_list:\n",
    "            if sciname not in scn_used:\n",
    "                dict_group_scn_abund[group][sciname].append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'moderate_peri_implantitis', 'severe_peri_implantitis']\n",
    "# group_sort = ['a','b']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "for scn in sciname_list:\n",
    "    print(scn)\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "    for group in group_sort:\n",
    "        # Load classif\n",
    "        x = dict_group_xtick[group]\n",
    "        bcvals = dict_group_scn_abund[group][scn]\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        # color = dict_sciname_color[scn]\n",
    "        # box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "        # if scn == 'Veillonella': print(bcvals)\n",
    "        ax.scatter(xs, bcvals, color='k', s=s)\n",
    "    plt.show()\n",
    "    # _ = ax.set_xticks(\n",
    "    #     xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "    # )\n",
    "    # _ = ax.set_xticks([])\n",
    "    # ax.set_xlim(0,np.max(xticks) + 1)\n",
    "    # ax.set_ylim(-0.01,1.01)\n",
    "    # ax.set_ylabel('Homogeneity\\n(Fuzzy box counting fractal dimension)')\n",
    "    # ax.set_ylim(1.4,2)\n",
    "\n",
    "    # out_fn = sample_compare_dir + \"/box_counting/2024_05_06_fuzzy_box_counting_bygroup.pdf\".format(\n",
    "    #     group\n",
    "    # )\n",
    "    # ip.check_dir(out_fn)\n",
    "    # ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fmt_absabund = out_fmt_classif + '/absolute_abundance'\n",
    "volume_agg_fmt = out_fmt_absabund + '/{date}_{sn}_absolute_abundance_volume_aggregated.npy'\n",
    "scinames_agg_fmt = out_fmt_absabund + '/{date}_{sn}_absolute_abundance_scinames_aggregated.npy'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = '2022_12_16'\n",
    "# sn = 'harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_02'\n",
    "\n",
    "\n",
    "# volume_agg_fn = volume_agg_fmt.format(date=date, sn=sn)\n",
    "# volume_agg = np.load(volume_agg_fn)\n",
    "# scinames_agg_fn = scinames_agg_fmt.format(date=date, sn=sn)\n",
    "# scinames_agg = np.load(scinames_agg_fn)\n",
    "\n",
    "# print(volume_agg)\n",
    "# scinames_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciname_list = [\n",
    "    'Pasteurellaceae',\n",
    "    'Corynebacterium',\n",
    "    'Veillonella',\n",
    "    'Actinomyces',\n",
    "    'Selenomonas',\n",
    "    'Rothia',\n",
    "    'Porphyromonas',\n",
    "    'Capnocytophaga',\n",
    "    'Prevotella',\n",
    "    'Streptococcus',\n",
    "    'Gemella',\n",
    "    'Campylobacter',\n",
    "    'Lautropia',\n",
    "    'Leptotrichia',\n",
    "    'Neisseriaceae',\n",
    "    'Treponema',\n",
    "    'Fusobacterium',\n",
    "    'Saccharibacteria'\n",
    "]\n",
    "\n",
    "dict_sci_rename = {\n",
    "    'TM7':'Saccharibacteria',\n",
    "    'Neisseria':'Neisseriaceae'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_pat_volscis = defaultdict(lambda: defaultdict(dict))\n",
    "for gr, ps_dict in dict_group_pat_sn.items():\n",
    "    for pat, sns in ps_dict.items():\n",
    "        n_unexcluded = 0\n",
    "        for bn in sns:\n",
    "            if bn not in exclude_sns:\n",
    "                n_unexcluded += 1\n",
    "        if n_unexcluded > 0:\n",
    "            dict_group_pat_volscis[gr][pat]['vol'] = 0\n",
    "            dict_group_pat_volscis[gr][pat]['scinames'] = []\n",
    "            for bn in sns:\n",
    "                if bn not in exclude_sns:\n",
    "                    date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "\n",
    "                    volume_agg_fn = volume_agg_fmt.format(date=date, sn=sn)\n",
    "                    volume_agg = np.load(volume_agg_fn)\n",
    "\n",
    "                    dict_group_pat_volscis[gr][pat]['vol'] += volume_agg[0]\n",
    "\n",
    "                    scinames_agg_fn = scinames_agg_fmt.format(date=date, sn=sn)\n",
    "                    scinames_agg = np.load(scinames_agg_fn)\n",
    "\n",
    "                    dict_group_pat_volscis[gr][pat]['scinames'] += scinames_agg.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_sci_abunds = defaultdict(lambda: defaultdict(list))\n",
    "for gr, pvs_dict in dict_group_pat_volscis.items():\n",
    "    for pat, vs_dict in pvs_dict.items():\n",
    "        scinames_pat = vs_dict['scinames']\n",
    "        volume_pat = vs_dict['vol']\n",
    "        names, counts = np.unique(scinames_pat, return_counts=True)\n",
    "        for sci, c in zip(names, counts): \n",
    "            sci = dict_sci_rename[sci] if sci in dict_sci_rename else sci\n",
    "            dict_group_sci_abunds[gr][sci].append(c / volume_pat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'mild_peri_implantitis', 'moderate_severe_peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "for scn in sciname_list:\n",
    "    print(scn)\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "    for group in group_sort:\n",
    "        # Load classif\n",
    "        x = dict_group_xtick[group]\n",
    "        bcvals = dict_group_sci_abunds[group][scn]\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        color = dict_sciname_color[scn]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "        # if scn == 'Veillonella': print(bcvals)\n",
    "        ax.scatter(xs, bcvals, color=color, s=s)\n",
    "    \n",
    "    _ = ax.set_xticks([])\n",
    "\n",
    "    abund_dir_compare = sample_compare_dir + \"/absolute_abundances\"\n",
    "    out_fn = abund_dir_compare + \"/absolute_abundances_bygroup_sciname_{}.pdf\".format(\n",
    "        scn\n",
    "    )\n",
    "    if not os.path.exists(abund_dir_compare):\n",
    "        os.makedirs(abund_dir_compare)\n",
    "    ip.check_dir(out_fn)\n",
    "    ip.save_fig(out_fn)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal wallis test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_ps = []\n",
    "for sci in sciname_list:\n",
    "    \n",
    "    test = stats.kruskal(\n",
    "        dict_group_sci_abunds[group_sort[0]][sci],\n",
    "        dict_group_sci_abunds[group_sort[1]][sci],\n",
    "        dict_group_sci_abunds[group_sort[2]][sci],\n",
    "        dict_group_sci_abunds[group_sort[3]][sci],\n",
    "    )    \n",
    "    kruskal_ps.append(test.pvalue)\n",
    "kruskal_ps = np.array(kruskal_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(kruskal_ps <= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_ps[np.where(kruskal_ps <= 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sci, ps in zip(sciname_list, kruskal_ps):\n",
    "    print(sci, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_sci = [sciname_list[i] for i in np.where(kruskal_ps <= 0.05)[0]]\n",
    "kruskal_sci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunn pairwise test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sci in kruskal_sci + ['Actinomyces','Corynebacterium']:\n",
    "    vals = [dict_group_sci_abunds[gr][sci] for gr in group_sort]\n",
    "    print(sci)\n",
    "    print(posthoc_dunn(vals))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just look at largest clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get largest clusters for each sciname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn = 1\n",
    "# dict_sn_large_clusters = defaultdict(dict)\n",
    "# for sn, dict_scn_clsize in dict_sn_scn_clsize.items():\n",
    "#     for scn, clsizes in dict_scn_clsize.items():      \n",
    "#         cls_topn = np.sort(clsizes)[-topn:]\n",
    "#         cls_mean = np.mean(cls_topn)\n",
    "#         dict_sn_large_clusters[sn][scn] = cls_mean\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get largest clusters for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn = 1\n",
    "# dict_sn_topn = {}\n",
    "# for sn, dict_scn_clsize in dict_sn_large_clusters.items():\n",
    "#     group = dict_sn_group[sn]\n",
    "#     sizes = []\n",
    "#     for scn, size in dict_scn_clsize.items():\n",
    "#         sizes.append(size)\n",
    "#     sz_sort = np.sort(sizes)\n",
    "#     sz_topn = sz_sort[-topn:]\n",
    "#     sz_mean = np.mean(sz_topn)\n",
    "#     dict_sn_topn[sn] = sz_mean\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sn_top = {}\n",
    "for sn, dict_scn_clsize in dict_sn_scn_clsize.items():\n",
    "    sn_top = 0\n",
    "    for scn, clsizes in dict_scn_clsize.items():      \n",
    "        scn_top = np.sort(clsizes)[-1]\n",
    "        sn_top = scn_top if scn_top > sn_top else sn_top\n",
    "    dict_sn_top[sn] = sn_top\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 10\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(5,5), ft=12)\n",
    "\n",
    "group_list = ['healthy_implant', 'mucositis_implant', 'peri_implantitis']\n",
    "xticks = np.arange(len(group_list)) + 1\n",
    "dict_group_xtick = dict(zip(group_list, xticks))\n",
    "# col_list = \n",
    "# dict_group_color = dict(group_list, col_list)\n",
    "\n",
    "dict_group_sizes = defaultdict(list)\n",
    "for sn, size in dict_sn_top.items():\n",
    "    group = dict_sn_group[sn]\n",
    "    if 'implant' in group:\n",
    "        x = dict_group_xtick[group] + np.random.rand() * 0.2 - 0.1\n",
    "        dict_group_sizes[group].append(size)\n",
    "        ax.scatter(x, size, color='k', s=s)\n",
    "\n",
    "sizes = [dict_group_sizes[g] for g in group_list]\n",
    "# positions = [[xt]*len(s) for xt, s in zip(xticks, sizes)]\n",
    "\n",
    "box = ax.boxplot(sizes, positions=xticks, vert=True, widths=0.5)\n",
    "\n",
    "_ = ax.set_xticks(\n",
    "    xticks, group_list, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    ")\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylabel('Largest cluster in tilescan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([])\n",
    "a.append(pd.DataFrame({'a':[1,2,3], 'b':[4,5,6]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out multifractal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleM_new:\n",
    "    \"\"\"\n",
    "    Rectangle grid structure for quadrat-based method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pp                : :class:`.PointPattern`\n",
    "                        Point Pattern instance.\n",
    "    count_column      : integer\n",
    "                        Number of rectangles in the horizontal\n",
    "                        direction. Use in pair with count_row to\n",
    "                        fully specify a rectangle. Incompatible with\n",
    "                        rectangle_width and rectangle_height.\n",
    "    count_row         : integer\n",
    "                        Number of rectangles in the vertical\n",
    "                        direction. Use in pair with count_column to\n",
    "                        fully specify a rectangle. Incompatible with\n",
    "                        rectangle_width and rectangle_height.\n",
    "    rectangle_width   : float\n",
    "                        Rectangle width. Use in pair with\n",
    "                        rectangle_height to fully specify a rectangle.\n",
    "                        Incompatible with count_column & count_row.\n",
    "    rectangle_height  : float\n",
    "                        Rectangle height. Use in pair with\n",
    "                        rectangle_width to fully specify a rectangle.\n",
    "                        Incompatible with count_column & count_row.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    pp                : :class:`.PointPattern`\n",
    "                        Point Pattern instance.\n",
    "    mbb               : array\n",
    "                        Minimum bounding box for the point pattern.\n",
    "    points            : array\n",
    "                        x,y coordinates of the point points.\n",
    "    count_column      : integer\n",
    "                        Number of columns.\n",
    "    count_row         : integer\n",
    "                        Number of rows.\n",
    "    num               : integer\n",
    "                        Number of rectangular quadrats.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pp, labels, count_column = 3, count_row = 3,\n",
    "                 rectangle_width = 0, rectangle_height = 0):\n",
    "        self.mbb = pp.mbb\n",
    "        self.pp = pp\n",
    "        self.points = np.asarray(pp.points)\n",
    "        self.labels = np.array(labels)\n",
    "        x_range = self.mbb[2]-self.mbb[0]\n",
    "        y_range = self.mbb[3]-self.mbb[1]\n",
    "        if rectangle_width & rectangle_height:\n",
    "            self.rectangle_width = rectangle_width\n",
    "            self.rectangle_height = rectangle_height\n",
    "\n",
    "            # calculate column count and row count\n",
    "            self.count_column = int(math.ceil(x_range / rectangle_width))\n",
    "            self.count_row = int(math.ceil(y_range / rectangle_height))\n",
    "        else:\n",
    "            self.count_column = count_column\n",
    "            self.count_row = count_row\n",
    "\n",
    "            # calculate the actual width and height of cell\n",
    "            self.rectangle_width = x_range/float(count_column)\n",
    "            self.rectangle_height = y_range/float(count_row)\n",
    "        self.num = self.count_column * self.count_row\n",
    "\n",
    "\n",
    "    def point_location_sta(self):\n",
    "        \"\"\"\n",
    "        Count the point events in each cell.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict_id_count : dict\n",
    "                        keys: rectangle id, values: number of point\n",
    "                        events in each cell.\n",
    "        \"\"\"\n",
    "\n",
    "        dict_id_count = {}\n",
    "        for i in range(self.count_row):\n",
    "            for j in range(self.count_column):\n",
    "                dict_id_count[j+i*self.count_column] = 0\n",
    "\n",
    "        for point in self.points:\n",
    "            index_x = (point[0]-self.mbb[0]) // self.rectangle_width\n",
    "            index_y = (point[1]-self.mbb[1]) // self.rectangle_height\n",
    "            if index_x == self.count_column:\n",
    "                index_x -= 1\n",
    "            if index_y == self.count_row:\n",
    "                index_y -= 1\n",
    "            id = index_y * self.count_column + index_x\n",
    "            dict_id_count[id] += 1\n",
    "        return dict_id_count\n",
    "\n",
    "    def _get_dict_id_labels(self):\n",
    "        \"\"\"\n",
    "        Get a list of labels in each cell.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict_id_count : dict\n",
    "                        keys: rectangle id, values: number of point\n",
    "                        events in each cell.\n",
    "        \"\"\"\n",
    "\n",
    "        # dict_id_count = {}\n",
    "        # for i in range(self.count_row):\n",
    "        #     for j in range(self.count_column):\n",
    "        #         dict_id_points[j+i*self.count_column] = []\n",
    "        dict_id_labels = defaultdict(list)\n",
    "        for point, lab in zip(self.points, self.labels):\n",
    "            index_x = (point[0]-self.mbb[0]) // self.rectangle_width\n",
    "            index_y = (point[1]-self.mbb[1]) // self.rectangle_height\n",
    "            if index_x == self.count_column:\n",
    "                index_x -= 1\n",
    "            if index_y == self.count_row:\n",
    "                index_y -= 1\n",
    "            id = index_y * self.count_column + index_x\n",
    "            dict_id_labels[id].append(lab)\n",
    "        self.dict_id_labels = dict_id_labels\n",
    "\n",
    "    def get_shannon_diversities(self):\n",
    "        self._get_dict_id_labels()\n",
    "        dict_idx_shannon = {}\n",
    "        for idx, labels in self.dict_id_labels.items():\n",
    "            labels = np.array(labels)\n",
    "            nlab = len(labels)\n",
    "            Hs = []\n",
    "            for l in np.unique(labels):\n",
    "                nl = sum(labels==l)\n",
    "                p = nl / nlab\n",
    "                Hs.append(p * np.log(p))\n",
    "            H = -np.sum(Hs)\n",
    "            dict_idx_shannon[idx] = H\n",
    "        return dict_idx_shannon\n",
    "\n",
    "    def get_simpson_diversities(self):\n",
    "        self._get_dict_id_labels()\n",
    "        dict_idx_simpson = {}\n",
    "        for idx, labels in self.dict_id_labels.items():\n",
    "            labels = np.array(labels)\n",
    "            nlab = len(labels)\n",
    "            if nlab > 1:\n",
    "                etas = []\n",
    "                for l in np.unique(labels):\n",
    "                    nl = sum(labels==l)\n",
    "                    etas.append(nl*(nl-1))\n",
    "                D = 1 - np.sum(etas) / (nlab*(nlab-1))\n",
    "            else:\n",
    "                D = 0\n",
    "            dict_idx_simpson[idx] = D\n",
    "        return dict_idx_simpson\n",
    "\n",
    "    def get_multispecies_tiles(self):\n",
    "        self._get_dict_id_labels()\n",
    "        dict_idx_multi = {}\n",
    "        for idx, labels in self.dict_id_labels.items():\n",
    "            c = 0\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                c = 1\n",
    "            dict_idx_multi[idx] = c\n",
    "        return dict_idx_multi\n",
    "\n",
    "\n",
    "    def get_partition_values(self, q):\n",
    "        self._get_dict_id_labels()\n",
    "        dict_idx = {}\n",
    "        for idx, labels in self.dict_id_labels.items():\n",
    "            labels = np.array(labels)\n",
    "            nlab = len(labels)\n",
    "            Xs = []\n",
    "            for l in np.unique(labels):\n",
    "                nl = sum(labels==l)\n",
    "                p = nl / nlab\n",
    "                if q == 1:\n",
    "                    Xs.append(-p * np.log(p))\n",
    "                else:\n",
    "                    Xs.append(p**q)\n",
    "            Xa = np.sum(Xs)\n",
    "            dict_idx[idx] = Xa\n",
    "        return dict_idx\n",
    "\n",
    "    def get_partition_values_noreplace(self, q):\n",
    "        self._get_dict_id_labels()\n",
    "        dict_idx = {}\n",
    "        for idx, labels in self.dict_id_labels.items():\n",
    "            labels = np.array(labels)\n",
    "            nlab = len(labels)\n",
    "            Xs = []\n",
    "            if nlab >= abs(q):\n",
    "                for l in np.unique(labels):\n",
    "                    nl = sum(labels==l)\n",
    "                    p = nl / nlab\n",
    "                    if q == 1:\n",
    "                        Xs.append(-p * np.log(p))\n",
    "                    else:\n",
    "                        if nl >= abs(q):\n",
    "                            minus = 0\n",
    "                            ns = []\n",
    "                            Ns = []\n",
    "                            while minus < abs(q):\n",
    "                                ns.append(nl - minus)\n",
    "                                Ns.append(nlab - minus)\n",
    "                                minus += 1\n",
    "                            p_ = (np.prod(ns)/np.prod(Ns)) ** np.sign(q)\n",
    "                            Xs.append(p_)\n",
    "                        else:\n",
    "                            Xs.append(0)\n",
    "            else:\n",
    "                Xs.append(0)\n",
    "            Xa = np.sum(Xs)\n",
    "            dict_idx[idx] = Xa\n",
    "        return dict_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0)**-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get partition values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2023_02_08\"\n",
    "sn = \"hsdm_group_1_sample_12_fov_01\"\n",
    "\n",
    "centroid_sciname_fn = centroid_sciname_fmt.format(date=date, sn=sn)\n",
    "centroid_sciname = pd.read_csv(centroid_sciname_fn)\n",
    "coords = np.array([eval(c) for c in centroid_sciname[\"coord\"].values])\n",
    "scinames = centroid_sciname[\"sciname\"].values\n",
    "scn_unq = np.unique(scinames)\n",
    "\n",
    "# Get cells window\n",
    "convex_hull = ps.cg.convex_hull(coords.tolist())\n",
    "ch_arr = np.array(to_ccf(convex_hull))\n",
    "# plt.plot(ch_arr[:, 1], ch_arr[:, 0])\n",
    "# plt.gca().invert_yaxis()\n",
    "window = Window([convex_hull])\n",
    "\n",
    "# Get boxes initial\n",
    "bbox = window.bbox\n",
    "# w_shp = np.array([bbox[2] - bbox[0], bbox[3] - bbox[1]])\n",
    "box_edge_init_um = 50\n",
    "div_edgesize = 1.5\n",
    "box_edge_min_um = 5\n",
    "col='k'\n",
    "# range of moments\n",
    "qrange = np.arange(-5,5)\n",
    "\n",
    "# Get point pattern\n",
    "pp = PointPattern(coords, window=window)\n",
    "# Get qstatistic\n",
    "box_edge_um = box_edge_init_um\n",
    "box_size = []\n",
    "dict_q_Xams = defaultdict(list)\n",
    "while box_edge_um >= box_edge_min_um:\n",
    "    print(box_edge_um)\n",
    "    box_edge = box_edge_um / res_umpix\n",
    "    nxy = np.ceil(w_shp / box_edge).astype(int)\n",
    "    for q in qrange:\n",
    "        rect = RectangleM_new(\n",
    "            pp, \n",
    "            count_column = nxy[1], \n",
    "            count_row = nxy[1],\n",
    "            labels=scinames\n",
    "        ).get_partition_values(q)\n",
    "        Xas = np.array(list(rect.values()))\n",
    "        Xam = np.mean(Xas)\n",
    "        dict_q_Xams[q].append(Xam)\n",
    "    dxy = w_shp / nxy\n",
    "    diag = np.sqrt(np.sum(dxy**2))\n",
    "    diag_um = diag * res_umpix\n",
    "    box_size.append(diag_um)\n",
    "\n",
    "    box_edge_um /= div_edgesize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnc = dict_q_Xams[1]\n",
    "stats.linregress(lns, lnc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at positive q values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zqs = []\n",
    "dict_q_col = dict(zip(qrange, plt.get_cmap('tab10').colors))\n",
    "fig, ax = ip.general_plot(dims=(10,5))\n",
    "for q in range(5):\n",
    "    # Get regression\n",
    "    Xams = dict_q_Xams[q]\n",
    "    lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "    lns = np.log(box_size)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    zq = slope/(1-q) if q != 1 else slope\n",
    "    print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "    zqs.append(zq)\n",
    "\n",
    "    Xams = np.exp(Xams) if q == 1 else Xams\n",
    "    col = dict_q_col[q]\n",
    "    ax.scatter(box_size, Xams, label=q, color=col)\n",
    "\n",
    "    x = np.array([min(box_size), max(box_size)])\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.plot(x, y, color=col, label=q)\n",
    "\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(box_edge_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at negative q values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zqs = []\n",
    "dict_q_col = dict(zip(qrange, plt.get_cmap('tab10').colors))\n",
    "fig, ax = ip.general_plot(dims=(10,5))\n",
    "for q in range(-5,1):\n",
    "    # Get regression\n",
    "    Xams = dict_q_Xams[q]\n",
    "    lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "    lns = np.log(areas)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    zq = slope/(1-q) if q != 1 else slope\n",
    "    print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "    zqs.append(zq)\n",
    "\n",
    "    Xams = np.exp(Xams) if q == 1 else Xams\n",
    "    col = dict_q_col[q]\n",
    "    ax.scatter(areas, Xams, label=q, color=col)\n",
    "\n",
    "    x = np.array([min(areas), max(areas)])\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.plot(x, y, color=col)\n",
    "    x = 1e3\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.text(\n",
    "        x,y, \n",
    "        (\n",
    "            \"Slope = \" + str(round(slope, 2)) \n",
    "            + \",\\nR^2 = \" + str(round(r_value**2, 4))\n",
    "        ),\n",
    "        ha=\"right\",\n",
    "        va=\"bottom\",\n",
    "        color=col\n",
    "    )\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(box_edge_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at fractal dimension as a function of q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zqs = []\n",
    "for q in qrange:\n",
    "    # Get regression\n",
    "    Xams = dict_q_Xams[q]\n",
    "    lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "    lns = np.log(areas)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    zq = slope/(1-q) if q != 1 else slope\n",
    "    print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "    zqs.append(zq)\n",
    "fig, ax = ip.general_plot(dims=(10,5))\n",
    "ax.scatter(qrange, zqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([np.array([1,2,3]) for i in range(4)])\n",
    "a.columns = np.array(['a','b','c'])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with a different sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get partion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2023_10_18\"\n",
    "sn = \"hsdm_slide_IIL_fov_01\"\n",
    "\n",
    "centroid_sciname_fn = centroid_sciname_fmt.format(date=date, sn=sn)\n",
    "centroid_sciname = pd.read_csv(centroid_sciname_fn)\n",
    "coords = np.array([eval(c) for c in centroid_sciname[\"coord\"].values])\n",
    "scinames = centroid_sciname[\"sciname\"].values\n",
    "scn_unq = np.unique(scinames)\n",
    "\n",
    "# Get cells window\n",
    "convex_hull = ps.cg.convex_hull(coords.tolist())\n",
    "ch_arr = np.array(to_ccf(convex_hull))\n",
    "# plt.plot(ch_arr[:, 1], ch_arr[:, 0])\n",
    "# plt.gca().invert_yaxis()\n",
    "window = Window([convex_hull])\n",
    "\n",
    "# Get boxes initial\n",
    "bbox = window.bbox\n",
    "# w_shp = np.array([bbox[2] - bbox[0], bbox[3] - bbox[1]])\n",
    "box_edge_init_um = 50\n",
    "div_edgesize = 1.5\n",
    "box_edge_min_um = 5\n",
    "col='k'\n",
    "# range of moments\n",
    "qrange = np.arange(-5,5)\n",
    "\n",
    "# Get point pattern\n",
    "pp = PointPattern(coords, window=window)\n",
    "# Get qstatistic\n",
    "box_edge_um = box_edge_init_um\n",
    "box_size = []\n",
    "areas = []\n",
    "dict_sn_q_Xams = defaultdict(lambda: defaultdict(list))\n",
    "while box_edge_um >= box_edge_min_um:\n",
    "    print(box_edge_um)\n",
    "    box_edge = box_edge_um / res_umpix\n",
    "    nxy = np.ceil(w_shp / box_edge).astype(int)\n",
    "    for q in qrange:\n",
    "        rect = RectangleM_new(\n",
    "            pp, \n",
    "            count_column = nxy[1], \n",
    "            count_row = nxy[1],\n",
    "            labels=scinames\n",
    "        ).get_partition_values(q)\n",
    "        Xas = np.array(list(rect.values()))\n",
    "        Xam = np.mean(Xas)\n",
    "        dict_sn_q_Xams[sn][q].append(Xam)\n",
    "    dxy = w_shp / nxy\n",
    "    diag = np.sqrt(np.sum(dxy**2))\n",
    "    diag_um = diag * res_umpix\n",
    "    box_size.append(diag_um)\n",
    "    areas.append(np.prod(dxy * res_umpix))\n",
    "\n",
    "    box_edge_um /= div_edgesize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_q_col = dict(zip(qrange, plt.get_cmap('tab10').colors))\n",
    "fig, ax = ip.general_plot(dims=(10,5))\n",
    "for q in range(5):\n",
    "    # Get regression\n",
    "    Xams = dict_sn_q_Xams[sn][q]\n",
    "    lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "    lns = np.log(box_size)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    zq = slope/(1-q) if q != 1 else slope\n",
    "    print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "\n",
    "    Xams = np.exp(Xams) if q == 1 else Xams\n",
    "    col = dict_q_col[q]\n",
    "    ax.scatter(box_size, Xams, label=q, color=col)\n",
    "\n",
    "    x = np.array([min(box_size), max(box_size)])\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.plot(x, y, color=col, label=q)\n",
    "\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(box_edge_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "negative q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_q_col = dict(zip(qrange, plt.get_cmap('tab10').colors))\n",
    "fig, ax = ip.general_plot(dims=(10,5))\n",
    "for q in range(-5,1):\n",
    "    # Get regression\n",
    "    Xams = dict_sn_q_Xams[sn][q]\n",
    "    lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "    lns = np.log(box_size)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    zq = slope/(1-q) if q != 1 else slope\n",
    "    print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "\n",
    "    Xams = np.exp(Xams) if q == 1 else Xams\n",
    "    col = dict_q_col[q]\n",
    "    ax.scatter(box_size, Xams, label=q, color=col)\n",
    "\n",
    "    x = np.array([min(box_size), max(box_size)])\n",
    "    y = math.exp(intercept) * x**slope\n",
    "    ax.plot(x, y, color=col)\n",
    "\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(box_edge_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between fractal dimensino values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zqs = []\n",
    "for q in qrange:\n",
    "    # Get regression\n",
    "    Xams = dict_q_Xams[q]\n",
    "    lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "    lns = np.log(areas)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    zq = slope/(1-q) if q != 1 else slope\n",
    "    print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "    zqs.append(zq)\n",
    "\n",
    "zqs1 = []\n",
    "for q in qrange:\n",
    "    # Get regression\n",
    "    Xams = dict_sn_q_Xams[sn][q]\n",
    "    lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "    lns = np.log(areas)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "    zq = slope/(1-q) if q != 1 else slope\n",
    "    print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "    zqs1.append(zq)\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(10,5))\n",
    "ax.plot(qrange, zqs, '-o')\n",
    "ax.plot(qrange, zqs1, '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do sum instead of mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"2023_02_08\", \"2023_10_18\"]\n",
    "sns = [\"hsdm_group_1_sample_12_fov_01\", \"hsdm_slide_IIL_fov_01\"]\n",
    "\n",
    "dict_sn_q_Xass = defaultdict(lambda: defaultdict(list))\n",
    "for date, sn in zip(dates, sns):\n",
    "    centroid_sciname_fn = centroid_sciname_fmt.format(date=date, sn=sn)\n",
    "    centroid_sciname = pd.read_csv(centroid_sciname_fn)\n",
    "    coords = np.array([eval(c) for c in centroid_sciname[\"coord\"].values])\n",
    "    scinames = centroid_sciname[\"sciname\"].values\n",
    "    scn_unq = np.unique(scinames)\n",
    "\n",
    "    # Get cells window\n",
    "    convex_hull = ps.cg.convex_hull(coords.tolist())\n",
    "    ch_arr = np.array(to_ccf(convex_hull))\n",
    "    # plt.plot(ch_arr[:, 1], ch_arr[:, 0])\n",
    "    # plt.gca().invert_yaxis()\n",
    "    window = Window([convex_hull])\n",
    "\n",
    "    # Get boxes initial\n",
    "    bbox = window.bbox\n",
    "    # w_shp = np.array([bbox[2] - bbox[0], bbox[3] - bbox[1]])\n",
    "    box_edge_init_um = 50\n",
    "    div_edgesize = 1.5\n",
    "    box_edge_min_um = 5\n",
    "    col='k'\n",
    "    # range of moments\n",
    "    qrange = np.arange(-4,6)\n",
    "\n",
    "    # Get point pattern\n",
    "    pp = PointPattern(coords, window=window)\n",
    "    # Get qstatistic\n",
    "    box_edge_um = box_edge_init_um\n",
    "    box_size = []\n",
    "    areas = []\n",
    "    while box_edge_um >= box_edge_min_um:\n",
    "        print(box_edge_um)\n",
    "        box_edge = box_edge_um / res_umpix\n",
    "        nxy = np.ceil(w_shp / box_edge).astype(int)\n",
    "        for q in qrange:\n",
    "            rect = RectangleM_new(\n",
    "                pp, \n",
    "                count_column = nxy[1], \n",
    "                count_row = nxy[1],\n",
    "                labels=scinames\n",
    "            ).get_partition_values_new(q)\n",
    "            Xas = np.array(list(rect.values()))\n",
    "            Xam = np.mean(Xas)\n",
    "            dict_sn_q_Xass[sn][q].append(Xam)\n",
    "        dxy = w_shp / nxy\n",
    "        diag = np.sqrt(np.sum(dxy**2))\n",
    "        diag_um = diag * res_umpix\n",
    "        box_size.append(diag_um)\n",
    "        area = np.prod(dxy * res_umpix)\n",
    "        areas.append(area)\n",
    "\n",
    "        box_edge_um /= div_edgesize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot positive q values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, sn in zip(dates, sns):\n",
    "    print(sn)\n",
    "    dict_q_col = dict(zip(qrange, plt.get_cmap('tab10').colors))\n",
    "    fig, ax = ip.general_plot(dims=(10,5))\n",
    "    for q in range(5):\n",
    "        # Get regression\n",
    "        Xams = dict_sn_q_Xass[sn][q]\n",
    "        lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "        lns = np.log(areas)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "        zq = slope/(1-q) if q != 1 else slope\n",
    "        print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "\n",
    "        Xams = np.exp(Xams) if q == 1 else Xams\n",
    "        col = dict_q_col[q]\n",
    "        ax.scatter(areas, Xams, label=q, color=col)\n",
    "\n",
    "        x = np.array([min(areas), max(areas)])\n",
    "        y = math.exp(intercept) * x**slope\n",
    "        ax.plot(x, y, color=col, label=q)\n",
    "\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"log(edge length (Î¼m))\")\n",
    "    ax.set_ylabel(\"log(partition function)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(box_edge_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative q values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, sn in zip(dates, sns):\n",
    "    print(sn)\n",
    "    dict_q_col = dict(zip(qrange, plt.get_cmap('tab10').colors))\n",
    "    fig, ax = ip.general_plot(dims=(10,5))\n",
    "    for q in range(-4,1):\n",
    "        # Get regression\n",
    "        Xams = dict_sn_q_Xass[sn][q]\n",
    "        lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "        lns = np.log(areas)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "        zq = slope/(1-q) if q != 1 else slope\n",
    "        print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "\n",
    "        Xams = np.exp(Xams) if q == 1 else Xams\n",
    "        col = dict_q_col[q]\n",
    "        ax.scatter(areas, Xams, label=q, color=col)\n",
    "\n",
    "        x = np.array([min(areas), max(areas)])\n",
    "        y = math.exp(intercept) * x**slope\n",
    "        ax.plot(x, y, color=col, label=q)\n",
    "\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"log(edge length (Î¼m))\")\n",
    "    ax.set_ylabel(\"log(partition function)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(box_edge_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare z values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ip.general_plot(dims=(10,5))\n",
    "for sn in sns:\n",
    "    print(sn)\n",
    "    zqs = []\n",
    "    for q in qrange:\n",
    "        # Get regression\n",
    "        Xams = dict_sn_q_Xass[sn][q]\n",
    "        lnc = np.log(Xams) if q != 1 else np.array(Xams)\n",
    "        lns = np.log(areas)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(lns, lnc)\n",
    "        zq = slope/(1-q) if q != 1 else slope\n",
    "        print('q:', q,', fit: ',slope, ', r^2: ', r_value**2, ', zq: ',zq)\n",
    "        zqs.append(zq)\n",
    "    ax.plot(qrange, zqs, '-o', label=sn)\n",
    "plt.legend()\n",
    "ax.set_xlabel(\"q\")\n",
    "ax.set_ylabel(\"z_q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After running multifractal pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multifractal_all_fn = sample_compare_dir + '/multifractal_zq_values.csv'\n",
    "multifractal_all = pd.read_csv(multifractal_all_fn, index_col=0)\n",
    "multifractal_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multifractal_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_sns = [\n",
    "    '2023_10_16_hsdm_slide_IB_fov_01', \n",
    "    '2023_10_16_hsdm_slide_IB_fov_03', \n",
    "    '2023_10_16_hsdm_slide_IB_fov_02', \n",
    "    '2022_12_16_harvardwelch_patient_18_tooth_2_aspect_MB_depth__fov_01',\n",
    "    '2022_12_16_harvardwelch_patient_19_tooth_15_aspect_MF_depth_sub_fov_01',\n",
    "    '2022_12_16_harvardwelch_patient_19_tooth_30_aspect_MB_depth_sub_fov_01',\n",
    "    '2023_02_18_hsdm_group_II_patient_7_fov_02',\n",
    "    '2023_02_18_hsdm_group_II_patient_7_fov_01',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrange = multifractal_all.columns.values\n",
    "qrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_q_zqs = defaultdict(lambda: defaultdict(list))\n",
    "for group, sns in dict_group_sn.items():\n",
    "    print(group)\n",
    "    for q in qrange:\n",
    "        for sn in sns:\n",
    "            if not sn in exclude_sns:\n",
    "                bcval = multifractal_all.loc[sn,q]\n",
    "                dict_group_q_zqs[group][q].append(bcval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "for q in qrange:\n",
    "    fig, ax = ip.general_plot(dims=(4,4), ft=12)\n",
    "\n",
    "    for group in group_sort:\n",
    "        x = dict_group_xtick[group]\n",
    "        bcvals = dict_group_q_zqs[group][q]\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        # color = dict_sciname_color[scn]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "        ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "    _ = ax.set_xticks(\n",
    "        xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "    )\n",
    "    ax.set_xlim(0,np.max(xticks) + 1)\n",
    "    ax.set_ylabel('$Z_{}$'.format('{' + q + '}'))\n",
    "    plt.show(plt.close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ip.general_plot(dims=(3,2), ft=7)\n",
    "sns = [\n",
    "    \"2023_02_08_hsdm_group_1_sample_11_fov_01\", \n",
    "    \"2023_10_18_hsdm_slide_IIL_fov_01\", \n",
    "    \"2023_02_18_hsdm_group_IV_patient_1_fov_01\"\n",
    "]\n",
    "colors = [\n",
    "    'tab:blue',\n",
    "    'tab:green',\n",
    "    'tab:red',\n",
    "]\n",
    "for sn, c in zip(sns, colors):\n",
    "    zqs = multifractal_all.loc[sn, :].values\n",
    "    ax.plot(qrange.astype(int)[4:8], zqs[4:8], '-o', label=sn, color=c)\n",
    "# plt.legend()\n",
    "# ax.set_xlabel(\"q\")\n",
    "# ax.set_ylabel(\"z_q\")\n",
    "ax.set_xticks([0,1,2,3])\n",
    "\n",
    "multifractal_dir = sample_compare_dir + '/multifractal'\n",
    "out_fn = multifractal_dir + '/zq_curves_three_images.pdf'\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn, transp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_col = {\n",
    "    'healthy_implant':'tab:blue',\n",
    "    'mucositis_implant':'tab:green',\n",
    "    'peri_implantitis':'tab:red',\n",
    "}\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(10,10), ft=20)\n",
    "for group, sns in dict_group_sn.items():\n",
    "    if group in group_sort:\n",
    "        col = dict_group_col[group]\n",
    "        for sn in sns:\n",
    "            if not sn in exclude_sns:\n",
    "                zqs = multifractal_all.loc[sn, :].values\n",
    "                ax.plot(qrange.astype(int), zqs, '-o', color=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot values from power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../outputs/{date}/{date}_{sn}\"\n",
    "\n",
    "spatial_dir = out_dir + '/spatial_statistics'\n",
    "\n",
    "power_spectrum_dir = spatial_dir + '/power_spectrum'\n",
    "power_spectrum_fmt = power_spectrum_dir + '/{date}_{sn}_power_spectrum_fit.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sn_scn_psloper = defaultdict(dict)\n",
    "for date, dict_sn_fns in dict_date_sn_fns.items():\n",
    "    for sn, _ in dict_sn_fns.items():\n",
    "        if os.path.exists(power_spectrum_fmt.format(date=date, sn=sn)):\n",
    "            power_spectrums = pd.read_csv(power_spectrum_fmt.format(date=date, sn=sn))\n",
    "            for i, row in power_spectrums.iterrows():\n",
    "                scn, slope, rsquared = row[['sciname','slope','r_squared']]\n",
    "                dsn = '{}_{}'.format(date,sn)\n",
    "                dict_sn_scn_psloper[dsn][scn] = [slope, rsquared]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smin = 1e10\n",
    "smax = -1e10\n",
    "\n",
    "dict_scn_slopes = defaultdict(list)\n",
    "dict_scn_rsquared = defaultdict(list)\n",
    "dict_scn_groups = defaultdict(list)\n",
    "for sn, dict_scn_psloper in dict_sn_scn_psloper.items():\n",
    "    try:\n",
    "        group = dict_sn_group[sn]\n",
    "    except:\n",
    "        group = \"none\"\n",
    "        print(sn)\n",
    "    if 'implant' in group:\n",
    "        for scn, (slope, rsquared) in dict_scn_psloper.items():\n",
    "            if scn == \"Neisseria\":\n",
    "                scn = \"Neisseriaceae\"\n",
    "            elif scn == \"TM7\":\n",
    "                scn = \"Saccharibacteria\"\n",
    "            elif scn == \"TM\":\n",
    "                scn = \"Saccharibacteria\"\n",
    "\n",
    "            if not np.isnan(slope):\n",
    "                dict_scn_slopes[scn].append(slope)\n",
    "                dict_scn_rsquared[scn].append(rsquared)\n",
    "                dict_scn_groups[scn].append(group)\n",
    "\n",
    "\n",
    "means = [np.median(s) for s in dict_scn_slopes.values()]\n",
    "scns = [s for s in dict_scn_slopes.keys()]\n",
    "scns_sort = [x for _, x in sorted(zip(means, scns))]\n",
    "\n",
    "\n",
    "xticks = np.arange(len(scns_sort)) + 1\n",
    "dict_sciname_ind = dict(zip(scns_sort, xticks))\n",
    "# dict_sciname_ind[\"Neisseria\"] = dict_sciname_ind[\"Neisseriaceae\"]\n",
    "# dict_sciname_ind[\"Saccharibacteria\"] = dict_sciname_ind[\"TM7\"]\n",
    "# dict_sciname_ind[\"TM\"] = dict_sciname_ind[\"TM7\"]\n",
    "\n",
    "s=100\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(20,10), ft=20)\n",
    "x = 1\n",
    "# scn_list = []\n",
    "# xticks = []\n",
    "dict_group_col = {\n",
    "    'healthy_implant':'tab:blue',\n",
    "    'mucositis_implant':'tab:purple',\n",
    "    'mild_peri_implantitis':'tab:orange',\n",
    "    'moderate_severe_peri_implantitis':'tab:red',\n",
    "}\n",
    "for scn in scns_sort:\n",
    "    x = dict_sciname_ind[scn]\n",
    "    slopes = dict_scn_slopes[scn]\n",
    "    slopes = -np.array(slopes) \n",
    "    xs = [x] * len(slopes) + np.random.rand(len(slopes)) * 0.2 - 0.1\n",
    "    # color = dict_sciname_color[scn]\n",
    "    # box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5)\n",
    "    box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5, patch_artist=True)\n",
    "    for k, vs in box.items():\n",
    "        for v in vs:\n",
    "            v.set_color('k')\n",
    "            v.set_alpha(0.25)\n",
    "            # if k == 'boxes':\n",
    "            # v.set_facecolor(\"k\")\n",
    "\n",
    "    groups = np.array(dict_scn_groups[scn])\n",
    "    sizes = s*np.array(dict_scn_rsquared[scn])\n",
    "    for g in ['healthy_implant','mucositis_implant','mild_peri_implantitis','moderate_severe_peri_implantitis']:\n",
    "        boolg = groups == g\n",
    "        col = dict_group_col[g]\n",
    "        ax.scatter(\n",
    "            xs[boolg], slopes[boolg],  s=sizes[boolg], color=col)\n",
    "\n",
    "\n",
    "    # ax.scatter(xs[groups == \"healthy_implant\"], slopes[groups == \"healthy_implant\"], color=\"tab:blue\", s=s)\n",
    "    # ax.scatter(xs[groups == \"mucositis_implant\"], slopes[groups == \"mucositis_implant\"], color=\"tab:green\", s=s)\n",
    "    # ax.scatter(xs[groups == \"peri_implantitis\"], slopes[groups == \"peri_implantitis\"], color=\"tab:red\", s=s)\n",
    "\n",
    "\n",
    "    \n",
    "    x += 1\n",
    "\n",
    "_ = ax.set_xticks(\n",
    "    xticks, scns_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    ")\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "ax.set_ylabel(\"Power spectrum slope for each tilescan\")\n",
    "\n",
    "\n",
    "# out_fn = cluster_size_dir + \"/size_distribution_by_sample_group_{}.png\".format(\n",
    "#     group\n",
    "# )\n",
    "# ip.check_dir(out_fn)\n",
    "# ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toplot = ['Porphyromonas','Streptococcus','Selenomonas','Pasteurellaceae', 'Veillonella', 'Lautropia','Prevotella']\n",
    "\n",
    "s=5\n",
    "\n",
    "# fig, ax = ip.general_plot(dims=(4,4), ft=7)\n",
    "fig, ax = ip.general_plot(dims=(2,2), ft=7)\n",
    "x = 1\n",
    "scn_list = []\n",
    "xticks = []\n",
    "for scn in toplot:\n",
    "    # if scn in toplot:\n",
    "    # x = dict_sciname_ind[scn]\n",
    "    slopes = dict_scn_slopes[scn]\n",
    "    slopes = -np.array(slopes) \n",
    "    xs = [x] * len(slopes) + np.random.rand(len(slopes)) * 0.2 - 0.1\n",
    "    # color = dict_sciname_color[scn]\n",
    "    # box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5)\n",
    "    box = ax.boxplot([slopes], positions=[x], vert=True, widths=0.5, patch_artist=True)\n",
    "    for k, vs in box.items():\n",
    "        for v in vs:\n",
    "            v.set_color('k')\n",
    "            v.set_alpha(0.25)\n",
    "            # if k == 'boxes':\n",
    "            # v.set_facecolor(\"k\")\n",
    "\n",
    "    groups = np.array(dict_scn_groups[scn])\n",
    "\n",
    "    ax.scatter(xs[groups == \"healthy_implant\"], slopes[groups == \"healthy_implant\"], color=\"tab:blue\", s=s)\n",
    "    ax.scatter(xs[groups == \"mucositis_implant\"], slopes[groups == \"mucositis_implant\"], color=\"tab:cyan\", s=s)\n",
    "    ax.scatter(xs[groups == \"mild_peri_implantitis\"], slopes[groups == \"mild_peri_implantitis\"], color=\"tab:pink\", s=s)\n",
    "    ax.scatter(xs[groups == \"moderate_severe_peri_implantitis\"], slopes[groups == \"moderate_severe_peri_implantitis\"], color=\"tab:red\", s=s)\n",
    "\n",
    "    scn_list.append(scn)\n",
    "    xticks.append(x)\n",
    "    \n",
    "    x += 1\n",
    "\n",
    "_ = ax.set_xticks(\n",
    "    xticks, scn_list, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    ")\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "# ax.set_ylim(0,2)\n",
    "# ax.set_ylabel(\"Power law eponent for each tilescan\")\n",
    "\n",
    "power_spectrum_compare_dir = sample_compare_dir + '/power_spectrum'\n",
    "out_fn = power_spectrum_compare_dir + \"/slopes_boxplot_select_genera.pdf\"\n",
    "ip.check_dir(out_fn)\n",
    "ip.save_fig(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bray curtis vs distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns = [\n",
    "    '2023_02_08_hsdm_group_1_sample_06_fov_01',\n",
    "    '2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01'\n",
    "]\n",
    "\n",
    "\n",
    "cols = plt.get_cmap('tab10').colors\n",
    "dict_bn_col = {\n",
    "    '2023_02_08_hsdm_group_1_sample_06_fov_01': cols[0],\n",
    "    '2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01':cols[1]\n",
    "}\n",
    "\n",
    "out_fmt_classif = out_dir + \"/classif\"\n",
    "out_dir_coords = out_fmt_classif + \"/coords_240705_cosdist\"\n",
    "centroid_sciname_fmt = out_dir_coords + '/{date}_{sn}_centroid_sciname.csv'\n",
    "\n",
    "cent_scis = []\n",
    "for bn in sns:\n",
    "    date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "    cs = pd.read_csv(centroid_sciname_fmt.format(date=date, sn=sn))\n",
    "    cent_scis.append(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_scis[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "czi_fn = \"../data/2022_12_16_harvardwelch_patient_14_tooth_14_aspect_MB_depth_sub_fov_02tile_las_488.czi\"\n",
    "resolution = fsi.get_resolution(czi_fn)\n",
    "res_umpix = resolution * 1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scinames_sort = [\n",
    "    'Pasteurellaceae',\n",
    "    'Corynebacterium',\n",
    "    'Veillonella',\n",
    "    'Actinomyces',\n",
    "    'Selenomonas',\n",
    "    'Rothia',\n",
    "    'Porphyromonas',\n",
    "    'Capnocytophaga',\n",
    "    'Prevotella',\n",
    "    'Streptococcus',\n",
    "    'Gemella',\n",
    "    'Campylobacter',\n",
    "    'Lautropia',\n",
    "    'Leptotrichia',\n",
    "    'Neisseriaceae',\n",
    "    'Treponema',\n",
    "    'Fusobacterium',\n",
    "    'Saccharibacteria'\n",
    "]\n",
    "\n",
    "dict_sci_rename = {\n",
    "    'TM7':'Saccharibacteria',\n",
    "    'Neisseria':'Neisseriaceae'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_um = 5\n",
    "n_compare = 10000\n",
    "\n",
    "radius_pix = radius_um / res_umpix\n",
    "euc_bc_list = []\n",
    "for cent_sci in cent_scis:\n",
    "    euc_bc = []\n",
    "    coords = np.array([eval(c) for c in cent_sci.coord.values])\n",
    "    scinames_cosdist = cent_sci.sciname.values\n",
    "    nbrs = NearestNeighbors(radius=radius_pix)\n",
    "    nbrs.fit(coords)\n",
    "    nn = nbrs.radius_neighbors(coords, return_distance=False)\n",
    "    choice = np.arange(coords.shape[0])\n",
    "    rand_lst = [\n",
    "        np.random.choice(choice, size=(1,2), replace=False) \n",
    "        for _ in range(n_compare)\n",
    "    ]\n",
    "    # iterate through random pairs of cells\n",
    "    for r in tqdm(rand_lst):\n",
    "        r = np.squeeze(r)\n",
    "        euclid = distance.euclidean(coords[r[0]], coords[r[1]])\n",
    "        # get nearest neighbors for both indices\n",
    "        nns = [nn[r_] for r_ in r]\n",
    "        # get scinames for nearest neighbors\n",
    "        nn_mats = []\n",
    "        for ns in nns:\n",
    "            scis = []\n",
    "            for i in ns:\n",
    "                sci = scinames_cosdist[i]\n",
    "                sci = dict_sci_rename[sci] if sci in dict_sci_rename else sci\n",
    "                scis.append(sci)\n",
    "            # Build feature matrices\n",
    "            scis = np.array(scis)\n",
    "            mat = []\n",
    "            for sci in scinames_sort:\n",
    "                count = sum(scis == sci)\n",
    "                mat.append(count)\n",
    "            nn_mats.append(mat)\n",
    "\n",
    "        # Get distance\n",
    "        bc = distance.braycurtis(nn_mats[0], nn_mats[1])\n",
    "        euc_bc.append([euclid, bc])\n",
    "    euc_bc_list.append(euc_bc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_um = [10,20,30,40,50,60,70,80,90,100,110,120,140]\n",
    "d = [dp / res_umpix for dp in d_um]\n",
    "ddb_list = []\n",
    "for euc_bc in euc_bc_list:\n",
    "    dict_dist_bcvals = defaultdict(list)\n",
    "    for euc, bc in euc_bc:\n",
    "        for i in range(len(d) - 1):\n",
    "            if (euc >= d[i]) and (euc < d[i+1]):\n",
    "                dict_dist_bcvals[i].append(bc)\n",
    "    ddb_list.append(dict_dist_bcvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_dist_bcvals in ddb_list:\n",
    "    for dist, bcvals in dict_dist_bcvals.items():\n",
    "        print(dist, len(bcvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = np.arange(len(ddb_list)) + 1\n",
    "dict_group_xtick = dict(zip(np.arange(len(ddb_list)), xticks))\n",
    "\n",
    "s = 1\n",
    "alpha = 0.1\n",
    "\n",
    "for di in range(len(d)-1):\n",
    "    print(di)\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "    bcvalist = []\n",
    "    for i, dict_dist_bcvals in enumerate(ddb_list):\n",
    "        # Load classif\n",
    "        x = dict_group_xtick[i]\n",
    "        bcvals = dict_dist_bcvals[di]\n",
    "        bcvalist.append(bcvals)\n",
    "        print(len(bcvals))\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        color = dict_bn_col[sns[i]]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "        # if scn == 'Veillonella': print(bcvals)\n",
    "        ax.scatter(xs, bcvals, color=color, s=s, alpha=alpha)\n",
    "    plt.show()\n",
    "    print(stats.ttest_ind(bcvalist[0], bcvalist[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limited radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_um = 5\n",
    "n_compare = 100000\n",
    "rlimu_um = 20\n",
    "rliml_um = 10\n",
    "\n",
    "rlimu = rlimu_um / res_umpix\n",
    "rliml = rliml_um / res_umpix\n",
    "radius_pix = radius_um / res_umpix\n",
    "euc_bc_list = []\n",
    "for cent_sci in cent_scis:\n",
    "    euc_bc = []\n",
    "    coords = np.array([eval(c) for c in cent_sci.coord.values])\n",
    "    scinames_cosdist = cent_sci.sciname.values\n",
    "    nbrs = NearestNeighbors(radius=radius_pix)\n",
    "    nbrs.fit(coords)\n",
    "    nn = nbrs.radius_neighbors(coords, return_distance=False)\n",
    "    choice = np.arange(coords.shape[0])\n",
    "    rand_lst = [\n",
    "        np.random.choice(choice, size=(1,2), replace=False) \n",
    "        for _ in range(n_compare)\n",
    "    ]\n",
    "    # iterate through random pairs of cells\n",
    "    for r in tqdm(rand_lst):\n",
    "        r = np.squeeze(r)\n",
    "        euclid = distance.euclidean(coords[r[0]], coords[r[1]])\n",
    "        if (euclid > rliml) and (euclid < rlimu):\n",
    "            # get nearest neighbors for both indices\n",
    "            nns = [nn[r_] for r_ in r]\n",
    "            # get scinames for nearest neighbors\n",
    "            nn_mats = []\n",
    "            for ns in nns:\n",
    "                scis = []\n",
    "                for i in ns:\n",
    "                    sci = scinames_cosdist[i]\n",
    "                    sci = dict_sci_rename[sci] if sci in dict_sci_rename else sci\n",
    "                    scis.append(sci)\n",
    "                # Build feature matrices\n",
    "                scis = np.array(scis)\n",
    "                mat = []\n",
    "                for sci in scinames_sort:\n",
    "                    count = sum(scis == sci)\n",
    "                    mat.append(count)\n",
    "                nn_mats.append(mat)\n",
    "\n",
    "            # Get distance\n",
    "            bc = distance.braycurtis(nn_mats[0], nn_mats[1])\n",
    "            euc_bc.append([euclid, bc])\n",
    "    euc_bc_list.append(euc_bc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_um = [10,20]\n",
    "d = [dp / res_umpix for dp in d_um]\n",
    "ddb_list = []\n",
    "for euc_bc in euc_bc_list:\n",
    "    dict_dist_bcvals = defaultdict(list)\n",
    "    for euc, bc in euc_bc:\n",
    "        for i in range(len(d) - 1):\n",
    "            if (euc >= d[i]) and (euc < d[i+1]):\n",
    "                dict_dist_bcvals[i].append(bc)\n",
    "    ddb_list.append(dict_dist_bcvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_dist_bcvals in ddb_list:\n",
    "    for dist, bcvals in dict_dist_bcvals.items():\n",
    "        print(dist, len(bcvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = np.arange(len(ddb_list)) + 1\n",
    "dict_group_xtick = dict(zip(np.arange(len(ddb_list)), xticks))\n",
    "\n",
    "s = 1\n",
    "alpha = 0.1\n",
    "\n",
    "for di in range(len(d)-1):\n",
    "    print(di)\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "    for i, dict_dist_bcvals in enumerate(ddb_list):\n",
    "        # Load classif\n",
    "        x = dict_group_xtick[i]\n",
    "        bcvals = dict_dist_bcvals[di]\n",
    "        print(len(bcvals))\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        color = dict_bn_col[sns[i]]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "        # if scn == 'Veillonella': print(bcvals)\n",
    "        ax.scatter(xs, bcvals, color=color, s=s, alpha=alpha)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([[3,4],[2,254],[1,21]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = np.arange(len(ddb_list)) + 1\n",
    "dict_group_xtick = dict(zip(np.arange(len(ddb_list)), xticks))\n",
    "\n",
    "s = 1\n",
    "alpha = 0.01\n",
    "\n",
    "\n",
    "\n",
    "for i, euc_bc in enumerate(euc_bc_list):\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "    # Load classif\n",
    "    # x = dict_group_xtick[i]\n",
    "    x = np.arange(len(euc_bc))\n",
    "    bcvals_sort = [x for _, x in sorted(euc_bc)]\n",
    "    # print(len(bcvals))\n",
    "    # xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "    color = dict_bn_col[sns[i]]\n",
    "    # box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "    # if scn == 'Veillonella': print(bcvals)\n",
    "    ax.scatter(x, bcvals_sort, color=color, s=s)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limited radius heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_um = np.array([5,10])\n",
    "n_compare = 100000\n",
    "rlimu_um = np.array([20,30,40])\n",
    "rliml_um = 10\n",
    "\n",
    "rlimu = rlimu_um / res_umpix\n",
    "rliml = rliml_um / res_umpix\n",
    "radius_pix = radius_um / res_umpix\n",
    "euc_bc_list = []\n",
    "for cent_sci in cent_scis:\n",
    "    euc_bc = []\n",
    "    coords = np.array([eval(c) for c in cent_sci.coord.values])\n",
    "    scinames_cosdist = cent_sci.sciname.values\n",
    "\n",
    "    nbrs = NearestNeighbors(radius=radius_pix)\n",
    "    nbrs.fit(coords)\n",
    "    nn = nbrs.radius_neighbors(coords, return_distance=False)\n",
    "    choice = np.arange(coords.shape[0])\n",
    "    rand_lst = [\n",
    "        np.random.choice(choice, size=(1,2), replace=False) \n",
    "        for _ in range(n_compare)\n",
    "    ]\n",
    "    # iterate through random pairs of cells\n",
    "    for r in tqdm(rand_lst):\n",
    "        r = np.squeeze(r)\n",
    "        euclid = distance.euclidean(coords[r[0]], coords[r[1]])\n",
    "        if (euclid > rliml) and (euclid < rlimu):\n",
    "            # get nearest neighbors for both indices\n",
    "            nns = [nn[r_] for r_ in r]\n",
    "            # get scinames for nearest neighbors\n",
    "            nn_mats = []\n",
    "            for ns in nns:\n",
    "                scis = []\n",
    "                for i in ns:\n",
    "                    sci = scinames_cosdist[i]\n",
    "                    sci = dict_sci_rename[sci] if sci in dict_sci_rename else sci\n",
    "                    scis.append(sci)\n",
    "                # Build feature matrices\n",
    "                scis = np.array(scis)\n",
    "                mat = []\n",
    "                for sci in scinames_sort:\n",
    "                    count = sum(scis == sci)\n",
    "                    mat.append(count)\n",
    "                nn_mats.append(mat)\n",
    "\n",
    "            # Get distance\n",
    "            bc = distance.braycurtis(nn_mats[0], nn_mats[1])\n",
    "            euc_bc.append([euclid, bc])\n",
    "    euc_bc_list.append(euc_bc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_um = [10,20]\n",
    "d = [dp / res_umpix for dp in d_um]\n",
    "ddb_list = []\n",
    "for euc_bc in euc_bc_list:\n",
    "    dict_dist_bcvals = defaultdict(list)\n",
    "    for euc, bc in euc_bc:\n",
    "        for i in range(len(d) - 1):\n",
    "            if (euc >= d[i]) and (euc < d[i+1]):\n",
    "                dict_dist_bcvals[i].append(bc)\n",
    "    ddb_list.append(dict_dist_bcvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_dist_bcvals in ddb_list:\n",
    "    for dist, bcvals in dict_dist_bcvals.items():\n",
    "        print(dist, len(bcvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = np.arange(len(ddb_list)) + 1\n",
    "dict_group_xtick = dict(zip(np.arange(len(ddb_list)), xticks))\n",
    "\n",
    "s = 1\n",
    "alpha = 0.1\n",
    "\n",
    "for di in range(len(d)-1):\n",
    "    print(di)\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "    for i, dict_dist_bcvals in enumerate(ddb_list):\n",
    "        # Load classif\n",
    "        x = dict_group_xtick[i]\n",
    "        bcvals = dict_dist_bcvals[di]\n",
    "        print(len(bcvals))\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        color = dict_bn_col[sns[i]]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "        # if scn == 'Veillonella': print(bcvals)\n",
    "        ax.scatter(xs, bcvals, color=color, s=s, alpha=alpha)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped bray curtis analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_diversity_fmt = out_dir + '/beta_diversity/{date}_{sn}_dict_radius_distance_bray_curtis_mean.yaml'\n",
    "\n",
    "dict_group_pat_bcs = defaultdict(lambda: defaultdict(list))\n",
    "for gr, ps_dict in dict_group_pat_sn.items():\n",
    "    for pat, sns in ps_dict.items():\n",
    "        for bn in sns:\n",
    "            if bn not in exclude_sns:\n",
    "                date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "                fn = beta_diversity_fmt.format(date=date, sn=sn)\n",
    "                with open(fn, 'r') as f:\n",
    "                    dict_radius_distance_bc = yaml.unsafe_load(f)\n",
    "                dict_group_pat_bcs[gr][pat].append(dict_radius_distance_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot bray curtis vs distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ip.general_plot()\n",
    "for dist, bc in dict_group_pat_bcs['healthy_implant']['patient_6'][0][10].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.k')\n",
    "for dist, bc in dict_group_pat_bcs['healthy_implant']['patient_6'][1][10].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.k')\n",
    "for dist, bc in dict_group_pat_bcs['mild_peri_implantitis']['patient_11'][0][10].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.r')\n",
    "for dist, bc in dict_group_pat_bcs['mild_peri_implantitis']['patient_11'][1][10].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ip.general_plot()\n",
    "for dist, bc in dict_group_pat_bcs['healthy_implant']['patient_6'][0][20].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.k')\n",
    "for dist, bc in dict_group_pat_bcs['healthy_implant']['patient_6'][1][20].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.k')\n",
    "for dist, bc in dict_group_pat_bcs['mild_peri_implantitis']['patient_11'][0][20].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.r')\n",
    "for dist, bc in dict_group_pat_bcs['mild_peri_implantitis']['patient_11'][1][20].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ip.general_plot()\n",
    "for dist, bc in dict_group_pat_bcs['healthy_implant']['patient_6'][0][5].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.k')\n",
    "for dist, bc in dict_group_pat_bcs['healthy_implant']['patient_11'][0][5].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.k')\n",
    "for dist, bc in dict_group_pat_bcs['mild_peri_implantitis']['patient_11'][0][5].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.r')\n",
    "for dist, bc in dict_group_pat_bcs['mild_peri_implantitis']['patient_2'][0][5].items():\n",
    "    ax.plot(dist * res_umpix, bc, '.r')\n",
    "\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax.set_yscale(\"log\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = 5\n",
    "s = 1\n",
    "for rad in [5,10,20]:\n",
    "    dict_group_color = dict(zip(group_sort, plt.get_cmap('tab10').colors))\n",
    "\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "    for gr, ps_dict in dict_group_pat_bcs.items():\n",
    "        col = dict_group_color[gr]\n",
    "        for pat, dcts in ps_dict.items():\n",
    "            for dict_radius_distance_bc in dcts:\n",
    "                dict_dist_bc = dict_radius_distance_bc[rad]\n",
    "                for d, bc in dict_dist_bc.items():\n",
    "                    ax.plot(d * res_umpix, bc, '.', color=col, ms=s, mec=col)\n",
    "    out_fn = sample_compare_dir + \"/bray_curtis/bray_curtis_mean_patch_radius_{}.pdf\".format(\n",
    "        rad\n",
    "    )\n",
    "    ip.check_dir(out_fn)\n",
    "    ip.save_fig(out_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean beta diversity at 100um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_radius_distance_bc[rad].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 / res_umpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = 10\n",
    "dst = 3\n",
    "\n",
    "dict_group_bcs = defaultdict(list)\n",
    "for gr, ps_dict in dict_group_pat_bcs.items():\n",
    "    for pat, dcts in ps_dict.items():\n",
    "        bcs = []\n",
    "        for dict_radius_distance_bc in dcts:\n",
    "            dists = list(dict_radius_distance_bc[rad].keys())\n",
    "            print(dists[dst])\n",
    "            bc = dict_radius_distance_bc[rad][dists[dst]]\n",
    "            bcs.append(bc)\n",
    "        dict_group_bcs[gr].append(np.mean(bcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists[dst] * res_umpix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'mild_peri_implantitis', 'moderate_severe_peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "\n",
    "for group in group_sort:\n",
    "    x = dict_group_xtick[group]\n",
    "    bcvals = dict_group_bcs[group]\n",
    "    xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "    # color = dict_sciname_color[scn]\n",
    "    box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "    ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "# _ = ax.set_xticks(\n",
    "#     xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "# )\n",
    "_ = ax.set_xticks([])\n",
    "ax.set_xlim(0,np.max(xticks) + 1)\n",
    "# ax.set_ylim(0,2)\n",
    "# ax.set_ylabel('Homogeneity\\n(Fuzzy box counting fractal dimension)')\n",
    "# ax.set_ylim(1.5,2)\n",
    "\n",
    "# out_fn = sample_compare_dir + \"/box_counting/2024_07_08_fuzzy_box_counting_bygroup_patient.pdf\".format(\n",
    "#     group\n",
    "# )\n",
    "# ip.check_dir(out_fn)\n",
    "# ip.save_fig(out_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal wallis test for difference in median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats.kruskal(\n",
    "    dict_group_bcs[group_sort[0]],\n",
    "    dict_group_bcs[group_sort[1]],\n",
    "    dict_group_bcs[group_sort[2]],\n",
    "    dict_group_bcs[group_sort[3]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunn pairwise test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posthoc_dunn(list(dict_group_bcs.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average diversity nocell-> nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns = [\n",
    "    '2023_02_08_hsdm_group_1_sample_06_fov_01',\n",
    "    '2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01'\n",
    "]\n",
    "\n",
    "cols = plt.get_cmap('tab10').colors\n",
    "dict_bn_col = {\n",
    "    '2023_02_08_hsdm_group_1_sample_06_fov_01': cols[0],\n",
    "    '2024_04_27_hsdm_group_III_patient_11_aspect_DL_fov_01':cols[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dir = out_dir + '/spatial_statistics'\n",
    "multifractal_dir = spatial_dir + '/multifractal'\n",
    "local_diversity_nocell_nan_dict_fmt = multifractal_dir + '/{date}_{sn}_dict_area_q_partition_vals_nocell_nan.yaml'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shannon diversities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_i = 0\n",
    "q_i = 1\n",
    "\n",
    "dict_bn_shan = defaultdict(dict)\n",
    "for bn in sns:\n",
    "    date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "    print(date,sn)\n",
    "    ldd_fn = local_diversity_nocell_nan_dict_fmt.format(date=date, sn=sn)\n",
    "    with open(ldd_fn, 'r') as f:\n",
    "        dict_area_q_Xas = yaml.unsafe_load(f)\n",
    "    areas = sorted(list(dict_area_q_Xas.keys()))\n",
    "    for a in range(len(areas)):\n",
    "        Xas = np.array(dict_area_q_Xas[areas[a]][q_i])\n",
    "        print(sum(np.isnan(Xas)))\n",
    "        Xas = Xas[~np.isnan(Xas)]\n",
    "        dict_bn_shan[bn][a] = Xas\n",
    "\n",
    "    # Dsums = []\n",
    "    # for area, dict_q_Xas in dict_area_q_Xas.items():\n",
    "    #     areas.append(area)\n",
    "    #     Xas = dict_q_Xas[2]\n",
    "    #     Ds = 1 - np.array(Xas)\n",
    "    #     Dsums.append(np.sum(Ds))\n",
    "    # dict_bn_areas_Xas[bn] = [areas, Dsums]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = np.arange(len(sns)) + 1\n",
    "dict_group_xtick = dict(zip(np.arange(len(sns)), xticks))\n",
    "\n",
    "s = 1\n",
    "alpha = 0.1\n",
    "for area_i in range(5):\n",
    "    print(area_i)\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "    for i, bn in enumerate(sns):\n",
    "        x = dict_group_xtick[i]\n",
    "        vals = dict_bn_shan[bn][area_i]\n",
    "        # areas = sorted(list(dict_bn_shan[bn].keys()))\n",
    "        xs = [x] * len(vals) + np.random.rand(len(vals)) * 0.2 - 0.1\n",
    "\n",
    "        color = dict_bn_col[bn]\n",
    "        ax.scatter(xs, vals, color=color, s=s, alpha=alpha)\n",
    "\n",
    "        box = ax.boxplot([vals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot simpson diversities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_i = 2\n",
    "\n",
    "dict_bn_simp = defaultdict(dict)\n",
    "for bn in sns:\n",
    "    date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "    print(date,sn)\n",
    "    ldd_fn = local_diversity_nocell_nan_dict_fmt.format(date=date, sn=sn)\n",
    "    with open(ldd_fn, 'r') as f:\n",
    "        dict_area_q_Xas = yaml.unsafe_load(f)\n",
    "    areas = sorted(list(dict_area_q_Xas.keys()))\n",
    "    for a in range(len(areas)):\n",
    "        Xas = np.array(dict_area_q_Xas[areas[a]][q_i])\n",
    "        Xas = Xas[~np.isnan(Xas)]\n",
    "        Ds = 1 - np.array(Xas)\n",
    "        dict_bn_simp[bn][a] = Ds\n",
    "\n",
    "    # Dsums = []\n",
    "    # for area, dict_q_Xas in dict_area_q_Xas.items():\n",
    "    #     areas.append(area)\n",
    "    #     Xas = dict_q_Xas[2]\n",
    "    #     Ds = 1 - np.array(Xas)\n",
    "    #     Dsums.append(np.sum(Ds))\n",
    "    # dict_bn_areas_Xas[bn] = [areas, Dsums]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = np.arange(len(sns)) + 1\n",
    "dict_group_xtick = dict(zip(np.arange(len(sns)), xticks))\n",
    "\n",
    "s = 1\n",
    "alpha = 0.1\n",
    "for area_i in range(5):\n",
    "    print(area_i)\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "    for i, bn in enumerate(sns):\n",
    "        x = dict_group_xtick[i]\n",
    "        vals = dict_bn_simp[bn][area_i]\n",
    "        # areas = sorted(list(dict_bn_shan[bn].keys()))\n",
    "        xs = [x] * len(vals) + np.random.rand(len(vals)) * 0.2 - 0.1\n",
    "\n",
    "        color = dict_bn_col[bn]\n",
    "        ax.scatter(xs, vals, color=color, s=s, alpha=alpha)\n",
    "\n",
    "        box = ax.boxplot([vals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,1,2,3,np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(a)[np.isnan(a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped alpha diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shannon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mean and std dev for each tile and group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 1\n",
    "\n",
    "dict_group_pat_area_shan = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "for gr, ps_dict in dict_group_pat_sn.items():\n",
    "    for pat, sns in tqdm(ps_dict.items()):\n",
    "        for bn in sns:\n",
    "            if bn not in exclude_sns:\n",
    "                date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "                ldd_fn = local_diversity_nocell_nan_dict_fmt.format(date=date, sn=sn)\n",
    "                with open(ldd_fn, 'r') as f:\n",
    "                    dict_area_q_Xas = yaml.unsafe_load(f)\n",
    "                areas = sorted(list(dict_area_q_Xas.keys()))\n",
    "                for i, a in enumerate(areas):\n",
    "                    Xas = np.array(dict_area_q_Xas[a][q])\n",
    "                    Xas = Xas[~np.isnan(Xas)]\n",
    "                    mean = np.mean(Xas)\n",
    "                    std = np.std(Xas)\n",
    "                    dict_group_pat_area_shan[gr][pat][i].append([mean, std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average by patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_area_patmeans = defaultdict(lambda: defaultdict(list))\n",
    "for gr, psa_dict in dict_group_pat_area_shan.items():\n",
    "    for pat, as_dict in psa_dict.items():\n",
    "        for area, vals in as_dict.items():\n",
    "            vals = np.array(vals)\n",
    "            patmean = np.mean(vals, axis=0)\n",
    "            dict_group_area_patmeans[gr][area].append(patmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean for varying area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'mild_peri_implantitis', 'moderate_severe_peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "for ai in range(5):\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "    for group in group_sort:\n",
    "        x = dict_group_xtick[group]\n",
    "        bcvals = dict_group_area_patmeans[group][ai]\n",
    "        bcvals = [v[0] for v in bcvals]\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        # color = dict_sciname_color[scn]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "        ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "    # _ = ax.set_xticks(\n",
    "    #     xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "    # )\n",
    "    _ = ax.set_xticks([])\n",
    "    ax.set_xlim(0,np.max(xticks) + 1)\n",
    "    plt.show()\n",
    "    # ax.set_ylim(0,2)\n",
    "    # ax.set_ylabel('Homogeneity\\n(Fuzzy box counting fractal dimension)')\n",
    "    # ax.set_ylim(1.5,2)\n",
    "\n",
    "    print(stats.kruskal(\n",
    "        [v[0] for v in dict_group_area_patmeans[group_sort[0]][ai]],\n",
    "        [v[0] for v in dict_group_area_patmeans[group_sort[1]][ai]],\n",
    "        [v[0] for v in dict_group_area_patmeans[group_sort[2]][ai]],\n",
    "        [v[0] for v in dict_group_area_patmeans[group_sort[3]][ai]],\n",
    "    ))\n",
    "\n",
    "    # out_fn = sample_compare_dir + \"/alpha_diversity/2024_07_12_shannon_mean_bygroup_patient.pdf\".format(\n",
    "    #     group\n",
    "    # )\n",
    "    # ip.check_dir(out_fn)\n",
    "    # ip.save_fig(out_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot stddev for varying area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'mild_peri_implantitis', 'moderate_severe_peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "for ai in range(5):\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "    for group in group_sort:\n",
    "        x = dict_group_xtick[group]\n",
    "        bcvals = dict_group_area_patmeans[group][ai]\n",
    "        bcvals = [v[1] for v in bcvals]\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        # color = dict_sciname_color[scn]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "        ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "    # _ = ax.set_xticks(\n",
    "    #     xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "    # )\n",
    "    _ = ax.set_xticks([])\n",
    "    ax.set_xlim(0,np.max(xticks) + 1)\n",
    "    # ax.set_ylim(0,2)\n",
    "    # ax.set_ylabel('Homogeneity\\n(Fuzzy box counting fractal dimension)')\n",
    "    # ax.set_ylim(1.5,2)\n",
    "\n",
    "\n",
    "    # out_fn = sample_compare_dir + \"/alpha_diversity/2024_07_12_shannon_mean_bygroup_patient.pdf\".format(\n",
    "    #     group\n",
    "    # )\n",
    "    # ip.check_dir(out_fn)\n",
    "    # ip.save_fig(out_fn)\n",
    "    plt.show()\n",
    "    print(stats.kruskal(\n",
    "        [v[1] for v in dict_group_area_patmeans[group_sort[0]][ai]],\n",
    "        [v[1] for v in dict_group_area_patmeans[group_sort[1]][ai]],\n",
    "        [v[1] for v in dict_group_area_patmeans[group_sort[2]][ai]],\n",
    "        [v[1] for v in dict_group_area_patmeans[group_sort[3]][ai]],\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simpson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mean and std dev for each tile and group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 2\n",
    "\n",
    "dict_group_pat_area_simp = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "dict_ai_area = defaultdict(list)\n",
    "for gr, ps_dict in dict_group_pat_sn.items():\n",
    "    for pat, sns in tqdm(ps_dict.items()):\n",
    "        for bn in sns:\n",
    "            if bn not in exclude_sns:\n",
    "                date, sn = re.split(\"(?<=^\\d{4}_\\d{2}_\\d{2})_\", bn)\n",
    "                ldd_fn = local_diversity_nocell_nan_dict_fmt.format(date=date, sn=sn)\n",
    "                with open(ldd_fn, 'r') as f:\n",
    "                    dict_area_q_Xas = yaml.unsafe_load(f)\n",
    "                areas = sorted(list(dict_area_q_Xas.keys()))\n",
    "                for i, a in enumerate(areas):\n",
    "                    Xas = np.array(dict_area_q_Xas[a][q])\n",
    "                    Xas = Xas[~np.isnan(Xas)]\n",
    "                    Xas = 1 - Xas\n",
    "                    mean = np.mean(Xas)\n",
    "                    std = np.std(Xas)\n",
    "                    dict_group_pat_area_simp[gr][pat][i].append([mean, std])\n",
    "                    dict_ai_area[i].append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average by patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_area_patmeans = defaultdict(lambda: defaultdict(list))\n",
    "for gr, psa_dict in dict_group_pat_area_simp.items():\n",
    "    for pat, as_dict in psa_dict.items():\n",
    "        for area, vals in as_dict.items():\n",
    "            vals = np.array(vals)\n",
    "            patmean = np.mean(vals, axis=0)\n",
    "            dict_group_area_patmeans[gr][area].append(patmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean for varying area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'mild_peri_implantitis', 'moderate_severe_peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "for ai in range(9):\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "    for group in group_sort:\n",
    "        x = dict_group_xtick[group]\n",
    "        bcvals = dict_group_area_patmeans[group][ai]\n",
    "        bcvals = [v[0] for v in bcvals]\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        # color = dict_sciname_color[scn]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "        ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "    # _ = ax.set_xticks(\n",
    "    #     xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "    # )\n",
    "    _ = ax.set_xticks([])\n",
    "    ax.set_xlim(0,np.max(xticks) + 1)\n",
    "    # ax.set_ylim(0,2)\n",
    "    # ax.set_ylabel('Homogeneity\\n(Fuzzy box counting fractal dimension)')\n",
    "    # ax.set_ylim(1.5,2)\n",
    "\n",
    "    print(stats.kruskal(\n",
    "        [v[0] for v in dict_group_area_patmeans[group_sort[0]][ai]],\n",
    "        [v[0] for v in dict_group_area_patmeans[group_sort[1]][ai]],\n",
    "        [v[0] for v in dict_group_area_patmeans[group_sort[2]][ai]],\n",
    "        [v[0] for v in dict_group_area_patmeans[group_sort[3]][ai]],\n",
    "    ))\n",
    "\n",
    "    out_fn = sample_compare_dir + \"/alpha_diversity/simpson_mean_bygroup_patient_area_{}.pdf\".format(\n",
    "        ai\n",
    "    )\n",
    "    ip.check_dir(out_fn)\n",
    "    ip.save_fig(out_fn)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, areas in dict_ai_area.items():\n",
    "    print(i, np.mean(areas), np.mean(areas)**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot stddev for varying area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sort = ['healthy_implant', 'mucositis_implant', 'mild_peri_implantitis', 'moderate_severe_peri_implantitis']\n",
    "\n",
    "xticks = np.arange(len(group_sort)) + 1\n",
    "dict_group_xtick = dict(zip(group_sort, xticks))\n",
    "\n",
    "s=5\n",
    "\n",
    "for ai in range(5):\n",
    "    fig, ax = ip.general_plot(dims=(1.9,1.75), ft=7)\n",
    "    for group in group_sort:\n",
    "        x = dict_group_xtick[group]\n",
    "        bcvals = dict_group_area_patmeans[group][ai]\n",
    "        bcvals = [v[1] for v in bcvals]\n",
    "        xs = [x] * len(bcvals) + np.random.rand(len(bcvals)) * 0.2 - 0.1\n",
    "\n",
    "        # color = dict_sciname_color[scn]\n",
    "        box = ax.boxplot([bcvals], positions=[x], vert=True, widths=0.5)\n",
    "\n",
    "        ax.scatter(xs, bcvals, color='k', s=s)\n",
    "\n",
    "    # _ = ax.set_xticks(\n",
    "    #     xticks, group_sort, rotation=45, ha=\"right\", va=\"top\", rotation_mode=\"anchor\"\n",
    "    # )\n",
    "    _ = ax.set_xticks([])\n",
    "    ax.set_xlim(0,np.max(xticks) + 1)\n",
    "    # ax.set_ylim(0,2)\n",
    "    # ax.set_ylabel('Homogeneity\\n(Fuzzy box counting fractal dimension)')\n",
    "    # ax.set_ylim(1.5,2)\n",
    "\n",
    "\n",
    "    # out_fn = sample_compare_dir + \"/alpha_diversity/2024_07_12_shannon_mean_bygroup_patient.pdf\".format(\n",
    "    #     group\n",
    "    # )\n",
    "    # ip.check_dir(out_fn)\n",
    "    # ip.save_fig(out_fn)\n",
    "    plt.show()\n",
    "    print(stats.kruskal(\n",
    "        [v[1] for v in dict_group_area_patmeans[group_sort[0]][ai]],\n",
    "        [v[1] for v in dict_group_area_patmeans[group_sort[1]][ai]],\n",
    "        [v[1] for v in dict_group_area_patmeans[group_sort[2]][ai]],\n",
    "        [v[1] for v in dict_group_area_patmeans[group_sort[3]][ai]],\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
