# Snakefile

"""
Pipeline to segment hiprfish images for hsdm project

"""

# =============================================================================
# Imports
# =============================================================================
import pandas as pd
import numpy as np
import os
import sys
import glob
from collections import defaultdict
import matplotlib.pyplot as plt
import re
import yaml
from scipy.spatial.distance import squareform, pdist
from sklearn.cluster import AgglomerativeClustering
import umap
from scipy.spatial.distance import squareform, pdist, cdist
from sklearn.neighbors import NearestNeighbors

sys.path.append(config['functions_path'])
import fn_spectral_images as fsi
import image_plots as ip
import fn_hiprfish_classifier as fhc
import segmentation_func as sf
import math


# =============================================================================
# Functions
# =============================================================================

def get_input_table():
    input_table = pd.read_csv(config['input_table'])
    # input_table.columns = config['input_table_cols']
    return input_table


def get_seg_fns(date, sn, fmt):
    fns = dict_date_sn_fns[date][sn]
    M, mtype = fsi.get_ntiles(fns[0])
    seg_fns = []
    for m in range(M):
        seg_fns.append(fmt.format(date=date, sn=sn, m=m))
    return seg_fns

def get_fns(fmt):
    fns = []
    for date, dict_sn_fns in dict_date_sn_fns.items():
        for sn in dict_sn_fns.keys():
            fns.append(fmt.format(date=date, sn=sn))
    return fns

def get_czi_fns(date, sn):
    return dict_date_sn_fns[date][sn]

# =============================================================================
# Setup
# =============================================================================

# args = sys.argv
# config_fn = args[args.index("--configfile") + 1]

input_table = get_input_table()
filenames = input_table['filenames']

dict_date_sn_fns = defaultdict(lambda: defaultdict(list))
for fn in filenames:
    bn = os.path.split(fn)[1]
    date, bn = re.split('(?<=^\d{4}_\d{2}_\d{2})_', bn)
    sn, ext = re.split("(?<=fov_\d{2})", bn)
    dict_date_sn_fns[date][sn].append(fn)

out_dir = config['output_dir'] + "/{date}/{date}_{sn}"

# Segment
out_dir_seg = out_dir + "/segs"
out_dir_plot = out_dir + "/plots"
ofmt = '/{date}_{sn}_M_{m}'
seg_fmt = out_dir_seg + ofmt + "_seg.npy"
props_fmt = out_dir_seg + ofmt + "_props.csv"
plot_fmt = out_dir_plot + ofmt + "_seg_plot.png"
rgb_fmt = out_dir_plot + ofmt + "_rgb_plot.png"
segs_done_fmt = out_dir + "/snakemake_segment_done.txt"

# Cluster
out_fmt_clust = out_dir + "/cluster/{date}_{sn}"
umap_fmt = out_fmt_clust + "_umap.png"
spec_fmt = out_fmt_clust + "_spec_clust_{cl}.png"
clust_fmt = out_fmt_clust + "_clusters.npy"
mlab_fmt = out_fmt_clust + "_dict_index_mlab.yaml"

# Classif
bmg224_dir = '../../..'
dict_date_pdfn = {
    '2022_12_16': [
        bmg224_dir 
        + '/manuscripts/mgefish/data/HiPRFISH_probe_design' 
        + '/welch2016_5b_no_633_channel.csv',
        '5bit_no633'
    ],
    '2023_02_08': [
        bmg224_dir 
        + '/manuscripts/mgefish/data/HiPRFISH_probe_design' 
        + '/welch2016_5b_no_633_channel.csv',
        '5bit_no633'
    ],
    '2023_02_18': [
        bmg224_dir 
        + '/manuscripts/mgefish/data/HiPRFISH_probe_design'
        + '/welch2016_5b_no_633_channel.csv',
        '5bit_no633'
    ],
    '2023_10_16': [
        bmg224_dir 
        + '/harvard_dental/pick_distant_barcodes/2023_08_01_order'
        + '/welch2016_7b_distant_v2.csv',
        '7bit_no405'
    ],
    '2023_10_18': [
        bmg224_dir 
        + '/harvard_dental/pick_distant_barcodes/2023_08_01_order'
        + '/welch2016_7b_distant_v2.csv',
        '7bit_no405'
    ],
}
out_fmt_classif = out_dir + "/classif"
spec_classif_fmt = out_fmt_classif + "/spectra_plots/{date}_{sn}_spec_clust_{cl}.png"
classif_fmt = out_fmt_classif + "/{date}_{sn}_dict_cluster_barcode.yaml"

# get coords
sciname_list = [
    'Pasteurellaceae',
    'Corynebacterium',
    'Veillonella',
    'Actinomyces',
    'Selenomonas',
    'Rothia',
    'Porphyromonas',
    'Capnocytophaga',
    'Prevotella',
    'Streptococcus',
    'Gemella',
    'Campylobacter',
    'Lautropia',
    'Leptotrichia',
    'Neisseriaceae',
    'Treponema',
    'Fusobacterium',
    'TM7'
]
cmap = plt.get_cmap('gist_rainbow')
colors = [cmap(i)[:3] for i in np.linspace(0,1,len(sciname_list))]
# colors = [c + (1,) for c in colors]
dict_sciname_color = dict(zip(sciname_list, colors))
dict_sciname_color['Neisseria'] = dict_sciname_color['Neisseriaceae']
dict_sciname_color['Saccharibacteria'] = dict_sciname_color['TM7']

out_dir_plot_classif = out_dir_plot + '/color_240416'
out_dir_coords = out_dir + "/coords"
classif_plot_fmt = out_dir_plot_classif + '/{date}_{sn}_M_{m}_classif.png'
centroid_sciname_fmt = out_dir_coords + '/{date}_{sn}_centroid_sciname.csv'
sample_compare_dir = config['output_dir'] + '/compare_samples'
classif_plot_all_fmt = sample_compare_dir + '/alltiles/color_240416/{date}_{sn}_classif_alltiles_white.png'

# recolor
out_dir_recolor = out_dir_plot + '/recolor_240418'
plot_recolor_fmt = out_dir_recolor + '/{date}_{sn}_M_{m}_classif.png'
plot_recolor_all_fmt = sample_compare_dir + '/alltiles/recolor_240418/{date}_{sn}_classif_alltiles.png'
recolor_done_fmt = out_dir + '/snakemake_recolor_done.txt'

# color_legend
color_legend_fn = sample_compare_dir + '/alltiles/recolor_240418/taxon_legend.pdf'

# # global_autocorr
# spatial_dir = out_dir + '/spatial_statistics'
# moran_dir = spatial_dir + '/morans_i'
# adjacency_hist_fmt = moran_dir + '/{date}_{sn}_adjacency_histogram.png'
# moran_plot_fmt = moran_dir + "/{date}_{sn}_sciname_{scn}_moran_plot.png"
# scatter_plot_fmt = moran_dir + "/{date}_{sn}_sciname_{scn}_scatter_plot.png"
# moran_table_fmt = moran_dir + "/{date}_{sn}_moran_values.csv"
# moran_bv_dir = spatial_dir + '/morans_bv'
# scatter_plot_bv_fmt = moran_bv_dir + "/{date}_{sn}_scinames_{scn0}_{scn1}_scatter_plot.png"
# moran_plot_bv_fmt = moran_bv_dir + "/{date}_{sn}_scinames_{scn0}_{scn1}_moran_plot.png"
# moran_bv_table_fmt = moran_bv_dir + "/{date}_{sn}_moran_bv_values.csv"


# =============================================================================
# Rule all output
# =============================================================================

segs_done = get_fns(segs_done_fmt)
clust_done = get_fns(clust_fmt)
classif_done = get_fns(classif_fmt)
coords_done = get_fns(centroid_sciname_fmt)
recolor_done = get_fns(recolor_done_fmt)
# global_autocorr_done = get_fns(moran_bv_table_fmt)

# seg_fns_all = get_fns(seg_fmt)
# props_fns_all = get_fns(props_fmt)
# plot_fns_all = get_fns(plot_fmt)
# rgb_fns_all = get_fns(rgb_fmt)


# =============================================================================
# Snake rules
# =============================================================================

rule all:
    input:
        color_legend_fn


rule segment:
    input:
        lambda wildcards: get_czi_fns(f'{wildcards.date}',f'{wildcards.sn}')
    output:
        segs_done_fmt,
    run:
        # Get number of tiles or scenes
        M, mtype = fsi.get_ntiles(input[0])
        # Get the resolutions
        resolutions = [fsi.get_resolution(fn) for fn in input]
        # Get the lasers
        lasers = [fsi.get_laser(fn) for fn in input]
        # remove 405 channel
        czi_fns = [fn for fn, l in zip(input, lasers) if l != 405]
        resolutions = [r for r, l in zip(resolutions, lasers) if l != 405]
        lasers = [l for l in lasers if l != 405]
        czi_fns = [x for _, x in sorted(zip(lasers, czi_fns))]
        resolutions = [x for _, x in sorted(zip(lasers, resolutions))]
        lasers = sorted(lasers)
        # Get shifts
        shifts = []
        for m in range(M):
            raws = [fsi.load_raw(fn, m, mtype) for fn in czi_fns]
            raws = [fsi.reshape_aics_image(r) for r in raws]
            # some images have different pixel resolution, correct that
            raws = fsi.match_resolutions_and_size(raws, resolutions)
            image_max_norm = [fsi.max_norm(r) for r in raws]
            sh = fsi._get_shift_vectors(image_max_norm)
            # print(sh)
            shifts.append(sh)
        # Some of the shifts are clearly wrong, fix those
        sh_arr = np.array(shifts)
        for k in range(1, len(lasers)):
            sh_i = sh_arr[:, k, :]
            # print("Shifts", lasers[k], ":")
            # print(sh_i)
            # address large deviatinos from typical
            sh_arr[:, k, :] = fsi.replace_outlier_shifts(sh_i)
        # Now shift the raw images
        for m in range(M):
            rgb_fn = rgb_fmt.format(date=wildcards.date, sn=wildcards.sn, m=m)
            raws = [fsi.load_raw(fn, m, mtype) for fn in czi_fns]
            raws = [fsi.reshape_aics_image(r) for r in raws]
            # some images have different pixel resolution, correct that
            raws = fsi.match_resolutions_and_size(raws, resolutions)
            raws_shift = fsi._shift_images(
                raws, sh_arr[m, :, :], max_shift=config['max_shift']
            )
            stack = np.dstack(raws_shift)
            stack_sum = np.sum(stack, axis=2)
            pre = sf.pre_process(
                stack_sum, 
                gauss=config['gauss'], 
                diff_gauss=eval(config['diff_gauss'])
                )
            mask = sf.get_background_mask(
                stack_sum,
                bg_smoothing=config['bg_smoothing'],
                n_clust_bg=config['n_clust_bg'],
                top_n_clust_bg=config['top_n_clust_bg'],
            )
            seg = sf.segment(pre, mask)
            props = sf.measure_regionprops(seg, stack_sum)
            spec = fsi.get_cell_average_spectra(seg, stack)
            props = props.merge(
                pd.DataFrame(spec), left_index=True, right_index=True
            )
            ncells += props.shape[0]

            seg_fn = seg_fmt.format(date=wildcards.date, sn=wildcards.sn, m=m)
            props_fn = props_fmt.format(date=wildcards.date, sn=wildcards.sn, m=m)
            plot_fn = plot_fmt.format(date=wildcards.date, sn=wildcards.sn, m=m)
            rgb_fn = rgb_fmt.format(date=wildcards.date, sn=wildcards.sn, m=m)

            for f in [seg_fn, props_fn, plot_fn, rgb_fn]:
                odir = os.path.split(f)[0]
                if not os.path.exists(odir):
                    os.makedirs(odir)
                    print("Made dir:", odir)

            np.save(seg_fn, seg)
            print("Wrote:", seg_fn)
            props.to_csv(props_fn, index=False)
            print("Wrote:", props_fn)
            
            # ip.plot_image(stack_sum, cmap="inferno", im_inches=10)
            fig, ax, _ = ip.plot_image(ip.seg2rgb(seg), im_inches=config['im_inches'])
            plt.figure(fig)
            ip.save_fig(plot_fn, dpi=config['dpi'], bbox_inches=0)
            plt.close()
            print("Wrote:", plot_fn)

            rgb = np.dstack([fsi.max_norm(r, type='sum') for r in raws_shift])
            rgb = rgb[:,:,:3]
            fig, ax, _ = ip.plot_image(rgb, im_inches=config['im_inches'])
            plt.figure(fig)
            ip.save_fig(rgb_fn, dpi=config['dpi'], bbox_inches=0)
            plt.close()
            print("Wrote:", rgb_fn)
        
        with open(output, 'w') as f:
            f.write('snakemake seg rule file')


        # seg_fns = lambda wildcards: get_seg_fns(
        #     f'{wildcards.date}', f'{wildcards.sn}', seg_fmt
        # ),
        # props_fns = lambda wildcards: get_seg_fns(
        #     f'{wildcards.date}', f'{wildcards.sn}', props_fmt
        # ),
        # plot_fns = lambda wildcards: get_seg_fns(
        #     f'{wildcards.date}', f'{wildcards.sn}', plot_fmt
        # ),
        # rgb_fns = lambda wildcards: get_seg_fns(
        #     f'{wildcards.date}', f'{wildcards.sn}', rgb_fmt
        # ),



rule cluster:
    input:
        lambda wildcards: get_seg_fns(
            f'{wildcards.date}', f'{wildcards.sn}', props_fmt
        )
    output:
        umap_fn = umap_fmt,
        clust_fn = clust_fmt,
        mlab_fn = mlab_fmt
    run:
        # Get props filenames
        props_fns = sorted(input)
        # Load props
        spec_arr = []
        ind_plus = 0
        dict_m_lab_ind = defaultdict(dict)
        for fn in props_fns:
            m = int(re.search('(?<=_M_)\d+',fn)[0])
            p = pd.read_csv(fn)
            # construct spectra array
            _, bc_type = dict_date_pdfn[wildcards.date]
            n_chan_spec = fhc.get_n_spec_channels(bc_type)
            cols_spec = np.arange(n_chan_spec).astype(str).tolist()
            spec_arr.append(p[cols_spec].values)
            # make a dictionary to map spec array index to tile and cell label
            for ind, mlab in enumerate(p.label):
                dict_m_lab_ind[m][mlab] = ind+ind_plus
            ind_plus += p.shape[0]
        with open(output.mlab_fn, 'w') as f:
            yaml.dump(dict_m_lab_ind, f, default_flow_style=False)
        print('Loaded cells')

        # Get spectra distances
        spec_arr = np.vstack(spec_arr)
        dist_mat_cond = pdist(spec_arr, fhc.channel_cosine_intensity_allonev2)
        print('Got pdist')
        # Make squareform
        dist_mat = squareform(dist_mat_cond)
        print('Got square matrix')
        # Agglomerative cluster
        agg = AgglomerativeClustering(
            n_clusters=config['n_clust'], 
            affinity='precomputed', 
            linkage='complete'
        )
        agg.fit(dist_mat)
        clust_agg = agg.labels_
        np.save(output.clust_fn, clust_agg)
        print('Got clustering')

        # Plot umap
        fig, ax = ip.general_plot(dims=eval(config['umap_dims']), col='w')
        fit = umap.UMAP(
            metric='precomputed', 
            n_neighbors=100, 
            min_dist=0.1
        ).fit(dist_mat)
        u = fit.embedding_
        ax.scatter(
            u[:,0], u[:,1], 
            c=clust_agg, 
            s=config['s_u'], 
            alpha=config['alpha_u'], 
            cmap=config['cmap_u']
        )
        ax.set_aspect('equal')
        ip.save_fig(output.umap_fn)
        plt.close()
        print('Got umap')

        colors = plt.get_cmap(config['cmap_u'])(np.linspace(0,1,config['n_clust']))
        dict_clust_col = dict(zip(np.arange(config['n_clust']), colors))
        # Plot spectra 
        for c in np.unique(clust_agg):
            # print('Cluster:', c)
            bool_c = clust_agg == c
            spec_sub = spec_arr[bool_c,:]

            # spec_sub_meansub = spec_sub - specs_med
            # spec_sub_meansub[spec_sub_meansub < 0] = 0

            fig, ax = ip.general_plot(dims=eval(config['spec_dims']), col='w')
            color = dict_clust_col[c]
            # fsi.plot_cell_spectra(ax, spec_sub, {'lw':2,'alpha':0.2,'color':'r'})
            fsi.plot_cell_spectra(ax, spec_sub, {'lw':2,'alpha':0.2,'color':color})

            ylim = ax.get_ylim()

            xs = [3, 7, 10, 24, 27, 29, 31, 33, 43, 47]
            for x in xs:
                ax.plot([x,x], ylim, color=(0.5,0.5,0.5), lw=0.5)
            
            spec_fn = spec_fmt.format(date=wildcards.date, sn=wildcards.sn, cl=c)
            ip.save_fig(spec_fn)
            plt.close()
        print('Got spectra')

rule classif:
    input:
        clust_fn = clust_fmt,
    output:
        classif_fn = classif_fmt
    run:
        # Load reference spectra
        pdfn, bc_type = dict_date_pdfn[wildcards.date]
        probe_design = pd.read_csv(pdfn)
        barcodes = probe_design['code']
        sci_names = probe_design['sci_name']
        dict_bc_sciname = dict(zip(barcodes, sci_names))
        barcodes = np.unique(barcodes)
        sci_names = [dict_bc_sciname[bc] for bc in barcodes]
        ref_spec = fhc.get_reference_spectra(
            barcodes, bc_type, config['ref_dir']
            )

        # Get classifier
        ref_spec_med = [np.median(r, axis=0) for r in ref_spec]
        ref_spec_arr = np.vstack(ref_spec_med)
        ref_spec_dist_mat_cond = pdist(
            ref_spec_arr, fhc.channel_cosine_intensity_allonev2
        )
        ref_spec_dist_mat = squareform(ref_spec_dist_mat_cond)
        nbrs = NearestNeighbors(n_neighbors=1, metric='precomputed')
        nn_ref = nbrs.fit(ref_spec_dist_mat)

        # Get props filenames
        props_glob = props_fmt.format(date=wildcards.date, sn=wildcards.sn, m='*')
        props_fns = sorted(glob.glob(props_glob))
        # Load props
        spec_arr = []
        for fn in props_fns:
            p = pd.read_csv(fn)
            # construct spectra array
            n_chan_spec = fhc.get_n_spec_channels(bc_type)
            cols_spec = np.arange(n_chan_spec).astype(str).tolist()
            spec_arr.append(p[cols_spec].values)
        spec_arr = np.vstack(spec_arr)

        # Load clustering
        clust_agg = np.load(input.clust_fn)
        cl_unq = np.unique(clust_agg)

        # Iterate through clusters and classify
        dict_cl_bc = {}
        for cl in cl_unq:
            spec = spec_arr[clust_agg == cl]
            spec_mean = np.median(spec, axis=0)[None, :]

            # Get distances
            try:
                cl_dist_matrix = cdist(
                    spec_mean, 
                    ref_spec_arr, 
                    metric=fhc.channel_cosine_intensity_allonev2
                )
            except:
                print('\n\n\n\nLOOK HERE',spec_mean.shape, ref_spec_arr.shape)
                raise ValueError("cdist not working")
            # Classify each spectrum
            nn_dists, nn_inds = nn_ref.kneighbors(cl_dist_matrix)
            rs_ind = nn_inds[0][0]
            bc = barcodes[rs_ind]
            sciname = sci_names[rs_ind]
            dict_cl_bc[cl] = bc

            # print('Cluster:',cl, 'Barcode:', bc, 'Sciname:', sciname)
            # bc = dict_refind_bc[nn_inds[0]]

            # Plot classif vs mean cluster spec
            fig, ax = ip.general_plot(dims=eval(config['spec_dims']), col='w')
            rs = ref_spec_med[rs_ind][None,:]
            rs = rs / np.sum(rs)
            sm = (spec_mean / np.sum(spec_mean))
            fsi.plot_cell_spectra(ax, rs, {"lw": 1, "alpha": 1, "color": "w"})                    
            fsi.plot_cell_spectra(ax, sm, {"lw": 1, "alpha": 1, "color": "r"})                    
            ylim = ax.get_ylim()
            xs = [3, 7, 10, 24, 27, 29, 31, 33, 43, 47]
            for x in xs:
                ax.plot([x, x], ylim, color=(0.5, 0.5, 0.5), lw=0.5)
            ax.set_title(sciname + ': ' + str(bc), color='w')
            spec_classif_fn = spec_classif_fmt.format(
                date=wildcards.date, sn=wildcards.sn, cl=cl
            )
            d = os.path.split(spec_classif_fn)[0]
            if not os.path.exists(d):
                os.makedirs(d)
                print('Made dir:', d)
            ip.save_fig(spec_classif_fn)
            plt.close()

        # Write classif dict
        with open(output.classif_fn, 'w') as f:
            yaml.dump(dict_cl_bc, f, default_flow_style=False)


rule get_coords:
    input:
        czi_fns = lambda wildcards: get_czi_fns(f'{wildcards.date}',f'{wildcards.sn}'),
        classif_fn = classif_fmt
    output:
        coords_fn = centroid_sciname_fmt
    run:
        czi_fns = input.czi_fns
        # print(czi_fns)
        # Get bc sciname dict
        pdfn, bc_type = dict_date_pdfn[wildcards.date]
        probe_design = pd.read_csv(pdfn)
        barcodes = probe_design['code']
        sci_names = probe_design['sci_name']
        dict_bc_sciname = dict(zip(barcodes, sci_names))
        # filenames
        mlab_fn = mlab_fmt.format(
            date=wildcards.date, sn=wildcards.sn
        )
        clust_fn = clust_fmt.format(
            date=wildcards.date, sn=wildcards.sn
        )
        classif_fn = classif_fmt.format(
            date=wildcards.date, sn=wildcards.sn
        )

        # props
        prop_glob = props_fmt.format(
            date=wildcards.date, sn=wildcards.sn, m='*'
        )
        prop_fns = glob.glob(prop_glob)
        Ms = [int(re.search('(?<=_M_)\d+',fn)[0]) for fn in prop_fns]
        prop_fns = [x for _, x in sorted(zip(Ms, prop_fns))]

        # # registered images
        # reg_glob = reg_fmt.format(
        #     date=wildcards.date, sn=wildcards.sn, m='*'
        # )
        # reg_fns = glob.glob(reg_glob)
        # Ms = [int(re.search('(?<=_registered_)\d+',fn)[0]) for fn in reg_fns]
        # reg_fns = [x for _, x in sorted(zip(Ms, reg_fns))]

        # segs
        seg_glob = seg_fmt.format(date=wildcards.date, sn=wildcards.sn, m='*')
        seg_fns = glob.glob(seg_glob)
        Ms = [int(re.search('(?<=_M_)\d+',fn)[0]) for fn in seg_fns]
        seg_fns = [x for _, x in sorted(zip(Ms, seg_fns))]

        # Load mlab dict
        with open(mlab_fn, 'r') as f:
            dict_m_lab_ind = yaml.unsafe_load(f)
        # Load clusters
        clust_agg = np.load(clust_fn)
        cl_unq = np.unique(clust_agg)
        # Load classif
        with open(classif_fn, 'r') as f:
            dict_cl_bc = yaml.unsafe_load(f)

        # Get upper left corners for each tile
        M, mtype = fsi.get_ntiles(czi_fns[0])
        res_umpix = fsi.get_resolution(czi_fns[0]) * 1e6
        if mtype == 'M':
            ncols = int(fsi.get_metadata_value(czi_fns[0], 'TilesX')[0])
            nrows = int(fsi.get_metadata_value(czi_fns[0], 'TilesY')[0])
            overl = float(fsi.get_metadata_value(
                czi_fns[0], 'TileAcquisitionOverlap'
            )[0])
            cols = np.tile(np.arange(ncols), nrows)
            rows = np.repeat(np.arange(nrows), ncols)
            seg = np.load(seg_fns[0])
            shp = np.array(seg.shape[:2])
            im_r, im_c = shp - shp * overl
            ul_corners = []
            for m in range(M):
                c, r = cols[m], rows[m]
                ulc = np.array([r * im_r, c * im_c])
                ul_corners.append(ulc)

            # Plot classified tiled image
            tile_shp = (
                (nrows - 1)*int(math.ceil(im_r)) + shp[0], 
                (ncols - 1)*int(math.ceil(im_c)) + shp[1]
            )
            classif_tile = np.zeros((
                tile_shp[0], tile_shp[1],len(colors[0])
            ))
            sum_tile = np.zeros((tile_shp[0], tile_shp[1]))
            # Get cell absolute locations
            dict_ind_centroid_sciname = {}
            ul_corners = np.array(ul_corners)
            r_lims = np.unique(ul_corners[:,0])
            c_lims = np.unique(ul_corners[:,1])
            for m in range(M):
                # Get image corner values
                c, r = cols[m], rows[m]
                ulc = ul_corners[m]
                # Get limits to remove cells from overlap
                r_lim, c_lim = [1e15]*2
                if r < np.max(rows):
                    r_lim = r_lims[r+1]
                if c < np.max(cols):
                    c_lim = c_lims[c+1]

                # Adjust cell locations 
                prop = pd.read_csv(prop_fns[m])
                # Centroid
                centroids = np.array([eval(c) for c in prop['centroid']])
                centroids += ulc
                bool_clim = centroids[:,1] < c_lim
                bool_rlim = centroids[:,0] < r_lim
                prop['centroid_adj'] = centroids.tolist()
                # Bbox
                bboxes = np.array([eval(b) for b in prop['bbox']])
                bboxes += np.tile(ulc, 2).astype(int)
                prop['bbox_adj'] = bboxes.tolist()

                # Filter based on location
                prop_filt = prop[bool_rlim*bool_clim]

                # Plot classif
                seg = np.load(seg_fns[m])
                dict_lab_col = {}
                dict_lab_bbox = {}
                for i, row in prop_filt.iterrows():
                    lab = row['label']
                    bbox = row['bbox']
                    centroid = row['centroid_adj']
                    ind = dict_m_lab_ind[m][lab]
                    cl = clust_agg[ind]
                    bc = dict_cl_bc[cl]
                    sciname = dict_bc_sciname[bc]
                    color = dict_sciname_color[sciname]
                    dict_lab_col[lab] = color
                    dict_ind_centroid_sciname[ind] = [centroid, sciname, m]
                    dict_lab_bbox[lab] = bbox
                classif_rgb = sf.seg_2_rgb(
                    seg, dict_lab_col, dict_lab_bbox
                )
                # Save plot
                fig, ax, cbar = ip.plot_image(
                    classif_rgb, 
                    im_inches=config['im_inches'], 
                    scalebar_resolution=res_umpix,
                    cb_col=config['cb_col']
                )
                classif_plot_fn = classif_plot_fmt.format(
                    date=wildcards.date, sn=wildcards.sn, m=m
                )
                d = os.path.split(classif_plot_fn)[0]
                if not os.path.exists(d):
                    os.makedirs(d)
                    print('Made dir:', d)
                plt.figure(fig)
                ip.save_fig(classif_plot_fn, dpi=config['dpi'], bbox_inches=0)   
                plt.close()

                # Write to all tiles image
                cr_shp = classif_rgb.shape[:2]
                ulc = [int(c) for c in ulc]
                # print(ulc, cr_shp)
                classif_tile[ulc[0]:ulc[0] + cr_shp[0], ulc[1]:ulc[1] + cr_shp[1], :] = classif_rgb

                # # Plot sum 
                # reg = np.load(reg_fns[m])
                # reg_sum = np.sum(reg, axis=2)
                # sum_tile[ulc[0]:ulc[0] + cr_shp[0], ulc[1]:ulc[1] + cr_shp[1]] = reg_sum
            # Plot all tiles together
            fig, ax, cbar = ip.plot_image(
                classif_tile, 
                im_inches=config['im_inches']*np.max(rows), 
                scalebar_resolution=res_umpix,
                cb_col=config['cb_col']
            )
            classif_plot_all_fn = classif_plot_all_fmt.format(date=wildcards.date, sn=wildcards.sn)
            d = os.path.split(classif_plot_all_fn)[0]
            if not os.path.exists(d):
                os.makedirs(d)
                print('Made dir:', d)
            plt.figure(fig)
            ip.save_fig(classif_plot_all_fn, dpi=config['dpi'], bbox_inches=0)
            plt.close()

            # Save overall coords
            cent_sci = list(dict_ind_centroid_sciname.values())
            clust_inds = list(dict_ind_centroid_sciname.keys())
            coords = [cs[0] for cs in cent_sci]
            scinames = [cs[1] for cs in cent_sci]
            tiles = [cs[2] for cs in cent_sci]
            # radius_pix = radius_um / res_umpix
            # neigh = NearestNeighbors(radius=radius_pix)
            # nbrs = neigh.fit(coords)
            # nn_inds, nn_dists = nbrs.radius_neighbors(coords)
            centroid_sciname_fn = centroid_sciname_fmt.format(date=wildcards.date, sn=wildcards.sn)
            d = os.path.split(centroid_sciname_fn)[0]
            if not os.path.exists(d):
                os.makedirs(d)
                print('Made dir:', d)
            pd.DataFrame({
                'clust_ind': clust_inds,
                'coord': coords,
                'sciname': scinames,
                'tile': tiles,
            }).to_csv(centroid_sciname_fn)
        else:
            dict_ind_centroid_sciname = {}
            for m in range(M):
                # Adjust cell locations 
                prop = pd.read_csv(prop_fns[m])
                # Centroid
                centroids = np.array([eval(c) for c in prop['centroid']])
                # Bbox
                bboxes = np.array([eval(b) for b in prop['bbox']])

                # Plot classif
                seg = np.load(seg_fns[m])
                dict_lab_col = {}
                dict_lab_bbox = {}
                for i, row in prop.iterrows():
                    lab = row['label']
                    bbox = row['bbox']
                    centroid = row['centroid']
                    ind = dict_m_lab_ind[m][lab]
                    cl = clust_agg[ind]
                    bc = dict_cl_bc[cl]
                    sciname = dict_bc_sciname[bc]
                    color = dict_sciname_color[sciname]
                    dict_lab_col[lab] = color
                    dict_ind_centroid_sciname[ind] = [centroid, sciname, m]
                    dict_lab_bbox[lab] = bbox
                classif_rgb = sf.seg_2_rgb(
                    seg, dict_lab_col, dict_lab_bbox
                )
                # Save plot
                fig, ax, cbar = ip.plot_image(
                    classif_rgb, 
                    im_inches=config['im_inches'], 
                    scalebar_resolution=res_umpix,
                    cb_col=config['cb_col']
                )
                classif_plot_fn = classif_plot_fmt.format(
                    date=wildcards.date, sn=wildcards.sn, m=m
                )
                d = os.path.split(classif_plot_fn)[0]
                if not os.path.exists(d):
                    os.makedirs(d)
                    print('Made dir:', d)
                plt.figure(fig)
                ip.save_fig(classif_plot_fn, dpi=config['dpi'], bbox_inches=0)   
                plt.close()

            # Save overall coords
            cent_sci = list(dict_ind_centroid_sciname.values())
            clust_inds = list(dict_ind_centroid_sciname.keys())
            coords = [cs[0] for cs in cent_sci]
            scinames = [cs[1] for cs in cent_sci]
            tiles = [cs[2] for cs in cent_sci]
            # radius_pix = radius_um / res_umpix
            # neigh = NearestNeighbors(radius=radius_pix)
            # nbrs = neigh.fit(coords)
            # nn_inds, nn_dists = nbrs.radius_neighbors(coords)
            centroid_sciname_fn = centroid_sciname_fmt.format(date=wildcards.date, sn=wildcards.sn)
            d = os.path.split(centroid_sciname_fn)[0]
            if not os.path.exists(d):
                os.makedirs(d)
                print('Made dir:', d)
            pd.DataFrame({
                'clust_ind': clust_inds,
                'coord': coords,
                'sciname': scinames,
                'tile': tiles,
            }).to_csv(centroid_sciname_fn)

rule recolor:
    input:
        czi_fns = lambda wildcards: get_czi_fns(f'{wildcards.date}',f'{wildcards.sn}'),
        classif_fn = classif_fmt
    output:
        recolor_done_fn = recolor_done_fmt
    run:
        czi_fns = input.czi_fns
        # print(czi_fns)
        # Get bc sciname dict
        pdfn, bc_type = dict_date_pdfn[wildcards.date]
        probe_design = pd.read_csv(pdfn)
        barcodes = probe_design['code']
        sci_names = probe_design['sci_name']
        dict_bc_sciname = dict(zip(barcodes, sci_names))
        # filenames
        mlab_fn = mlab_fmt.format(
            date=wildcards.date, sn=wildcards.sn
        )
        clust_fn = clust_fmt.format(
            date=wildcards.date, sn=wildcards.sn
        )
        classif_fn = classif_fmt.format(
            date=wildcards.date, sn=wildcards.sn
        )

        # props
        prop_glob = props_fmt.format(
            date=wildcards.date, sn=wildcards.sn, m='*'
        )
        prop_fns = glob.glob(prop_glob)
        Ms = [int(re.search('(?<=_M_)\d+',fn)[0]) for fn in prop_fns]
        prop_fns = [x for _, x in sorted(zip(Ms, prop_fns))]

        # segs
        seg_glob = seg_fmt.format(date=wildcards.date, sn=wildcards.sn, m='*')
        seg_fns = glob.glob(seg_glob)
        Ms = [int(re.search('(?<=_M_)\d+',fn)[0]) for fn in seg_fns]
        seg_fns = [x for _, x in sorted(zip(Ms, seg_fns))]

        # Get number of tiles or scenes
        M, mtype = fsi.get_ntiles(input.czi_fns[0])
        # Get the resolutions
        resolutions = [fsi.get_resolution(fn) for fn in input.czi_fns]
        # Get the lasers
        lasers = [fsi.get_laser(fn) for fn in input.czi_fns]
        # remove 405 channel
        czi_fns = [fn for fn, l in zip(input.czi_fns, lasers) if l != 405]
        resolutions = [r for r, l in zip(resolutions, lasers) if l != 405]
        lasers = [l for l in lasers if l != 405]
        czi_fns = [x for _, x in sorted(zip(lasers, czi_fns))]
        resolutions = [x for _, x in sorted(zip(lasers, resolutions))]
        lasers = sorted(lasers)

        # Load mlab dict
        with open(mlab_fn, 'r') as f:
            dict_m_lab_ind = yaml.unsafe_load(f)
        # Load clusters
        clust_agg = np.load(clust_fn)
        cl_unq = np.unique(clust_agg)
        # Load classif
        with open(classif_fn, 'r') as f:
            dict_cl_bc = yaml.unsafe_load(f)

        # Get upper left corners of tiles if it is a tilescan
        # M, mtype = fsi.get_ntiles(czi_fns[0])
        # res_umpix = fsi.get_resolution(czi_fns[0]) * 1e6
        res_umpix = resolutions[0] * 1e6
        if mtype == 'M':
            ncols = int(fsi.get_metadata_value(czi_fns[0], 'TilesX')[0])
            nrows = int(fsi.get_metadata_value(czi_fns[0], 'TilesY')[0])
            overl = float(fsi.get_metadata_value(
                czi_fns[0], 'TileAcquisitionOverlap'
            )[0])
            cols = np.tile(np.arange(ncols), nrows)
            rows = np.repeat(np.arange(nrows), ncols)
            seg = np.load(seg_fns[0])
            shp = np.array(seg.shape[:2])
            im_r, im_c = shp - shp * overl
            ul_corners = []
            for m in range(M):
                c, r = cols[m], rows[m]
                ulc = np.array([r * im_r, c * im_c])
                ul_corners.append(ulc)

            # Plot classified tiled image
            tile_shp = (
                (nrows - 1)*int(math.ceil(im_r)) + shp[0], 
                (ncols - 1)*int(math.ceil(im_c)) + shp[1]
            )
            classif_tile = np.zeros((
                tile_shp[0], tile_shp[1],len(colors[0])
            ))
            sum_tile = np.zeros((tile_shp[0], tile_shp[1]))
            # Get cell absolute locations
            dict_ind_centroid_sciname = {}
            ul_corners = np.array(ul_corners)
            r_lims = np.unique(ul_corners[:,0])
            c_lims = np.unique(ul_corners[:,1])

        # Plot each FOV
        for m in range(M):
            # Get shifts
            raws = [fsi.load_raw(fn, m, mtype) for fn in czi_fns]
            raws = [fsi.reshape_aics_image(r) for r in raws]
            # some images have different pixel resolution, correct that
            raws = fsi.match_resolutions_and_size(raws, resolutions)
            image_max_norm = [fsi.max_norm(r) for r in raws]
            sh = fsi._get_shift_vectors(image_max_norm)
            raws_shift = fsi._shift_images(
                raws, sh, max_shift=config['max_shift']
            )

            # Segment with no edge correction
            stack = np.dstack(raws_shift)
            stack_sum = np.sum(stack, axis=2)
            pre = sf.pre_process(
                stack_sum, 
                gauss=config['gauss'], 
                diff_gauss=eval(config['diff_gauss'])
                )
            mask = sf.get_background_mask(
                stack_sum,
                bg_smoothing=config['bg_smoothing'],
                n_clust_bg=config['n_clust_bg'],
                top_n_clust_bg=config['top_n_clust_bg'],
            )
            seg = sf.segment_02(pre, mask)
            props = sf.measure_regionprops(seg, stack_sum)

            # load old props 
            props_old = pd.read_csv(prop_fns[m])

            # map new seg to old
            dict_nlab_color = {}
            for i, row in props_old.iterrows():
                c = eval(row.centroid)
                c = [int(c_) for c_ in c]
                lab = row.label
                ind = dict_m_lab_ind[m][lab]
                cl = clust_agg[ind]
                bc = dict_cl_bc[cl]
                sciname = dict_bc_sciname[bc]
                color = dict_sciname_color[sciname]
                lnew = seg[c[0],c[1]]
                if lnew:
                    dict_nlab_color[lnew] = color

            # Adjust raw image
            stack_sum_norm = fsi.max_norm(stack, type='sum')
            # stack_sum_norm = fsi.max_norm(stack, type='sum', c=eval(config['clips']))

            # Plot classif
            dict_lab_bbox = dict(zip(props.label.values,props.bbox.values))
            dict_nlab_bbox = {l: dict_lab_bbox[l] for l in dict_nlab_color.keys()}
            seg_classif = sf.seg_2_rgb_dict(
                seg, 
                dict_nlab_color, 
                dict_nlab_bbox, 
                raw=stack_sum_norm
            )
            # Save plot
            fig, ax, cbar = ip.plot_image(
                seg_classif, 
                im_inches=config['im_inches'], 
                scalebar_resolution=res_umpix,
                cb_col=config['cb_col'],
                ft=config['im_ft']
            )
            classif_plot_fn = plot_recolor_fmt.format(
                date=wildcards.date, sn=wildcards.sn, m=m
            )
            d = os.path.split(classif_plot_fn)[0]
            if not os.path.exists(d):
                os.makedirs(d)
                print('Made dir:', d)
            plt.figure(fig)
            ip.save_fig(classif_plot_fn, dpi=config['dpi'], bbox_inches=0)   
            plt.close()

            # overlap tiles if it is a tilescan
            if mtype == 'M':
                # Get image corner values
                c, r = cols[m], rows[m]
                ulc = ul_corners[m]
                # Get limits to remove cells from overlap
                r_lim, c_lim = [1e15]*2
                if r < np.max(rows):
                    r_lim = r_lims[r+1]
                if c < np.max(cols):
                    c_lim = c_lims[c+1]
                    
                # Write to all tiles image
                cr_shp = seg_classif.shape[:2]
                ulc = [int(c) for c in ulc]
                # print(ulc, cr_shp)
                classif_tile[ulc[0]:ulc[0] + cr_shp[0], ulc[1]:ulc[1] + cr_shp[1], :] = seg_classif


        # Plot all tiles together if it is a tilescan
        if mtype == 'M':
            fig, ax, cbar = ip.plot_image(
                classif_tile, 
                im_inches=config['im_inches']*np.max(rows), 
                scalebar_resolution=res_umpix,
                cb_col=config['cb_col'],
                ft=config['im_ft']
            )
            plot_recolor_all_fn = plot_recolor_all_fmt.format(
                date=wildcards.date, sn=wildcards.sn
            )
            d = os.path.split(plot_recolor_all_fn)[0]
            if not os.path.exists(d):
                os.makedirs(d)
                print('Made dir:', d)
            plt.figure(fig)
            ip.save_fig(plot_recolor_all_fn, dpi=config['dpi'], bbox_inches=0)
            plt.close()
        
        with open(output.recolor_done_fn, 'w') as f:
            f.write('Snakemake rule recolor done')



rule color_legend:
    input:
        recolor_done
    output:
        color_legend_fn = color_legend_fn
    run:
        fig, ax = ip.taxon_legend(
            sciname_list, 
            colors, 
            label_color=config['color_legend']['label_color'],
            ft=config['color_legend']['ft'],
            dims=eval(config['color_legend']['dims']),
        )
        ip.save_fig(output.color_legend_fn)

# # rule global_autocorr:
#     input:
#         czi_fns = lambda wildcards: get_czi_fns(f'{wildcards.date}',f'{wildcards.sn}'),
#         centroid_sciname_fn = centroid_sciname_fmt
#     output:
#         adjacency_hist_fn = adjacency_hist_fmt,
#         moran_table_fn = moran_table_fmt,
#         moran_bv_table_fn = moran_bv_table_fmt,
#     conda:
#         'hiprfish_pysal'
#     run:
#         from esda.moran import Moran, Moran_BV
#         from libpysal.weights import W
#         pdict = config['moran']

#         # Get coords 
#         centroid_sciname = pd.read_csv(input.centroid_sciname_fn)
#         coords = np.array([eval(c) for c in centroid_sciname["coord"].values])
#         scinames = centroid_sciname["sciname"].values
#         scn_unq = np.unique(scinames)

#         # Get adjacency
#         res_mpix = fsi.get_resolution(input.czi_fns[0])
#         res_umpix = res_mpix * 1e6
#         radius_pix = pdict['radius_um'] / res_umpix
#         neigh = NearestNeighbors(radius=radius_pix)
#         nbrs = neigh.fit(coords)
#         nn_dists, nn_inds = nbrs.radius_neighbors(coords)

#         # Plot adjacency
#         _ = plt.hist([len(ni) for ni in nn_inds])
#         _ = plt.xlabel(
#             'Number of cells within ' 
#             + str(pdict['radius_um']) 
#             + 'Î¼m (' + str(int(radius_pix)) + ' pixels)'
#         )
#         ip.save_fig(output.adjacency_hist_fn)

#         # Build weights matrix
#         neighbors = {}
#         for i, (nn_i) in enumerate(nn_inds):
#             neighbors[i] = [ni for ni in nn_i if ni != i]
#         w = W(neighbors)

#         # Get morans I
#         xlim = (0, np.max(coords[:, 1]))
#         ylim = (0, np.max(coords[:, 0]))
#         moran_table = defaultdict(list)
#         for scn in scn_unq:
#             # calculate morans i
#             col = dict_sciname_color[scn]
#             bool_scn = scinames == scn
#             y = bool_scn * 1
#             mi = Moran(y, w)
#             # print(scn, mi.I, mi.p_sim)
#             moran_table["sciname"].append(scn)
#             moran_table["I_expected"].append(mi.EI)
#             moran_table["I_measured"].append(mi.I)
#             moran_table["p_simulation"].append(mi.p_sim)
#             # PLot the simluation vs observed
#             fig, ax = apl.general_plot(
#                 col=pdict['l_col'], 
#                 dims=eval(pdict['dims']), 
#                 lw=pdict['lw'], 
#                 ft=pdict['ft'], 
#                 pad=pdict['pad']
#             )
#             apl.plot_morans_i_sim_obj(
#                 ax, mi, lw=pdict['lw'], ft=pdict['ft'], col=col, l_col=pdict['l_col']
#             )
#             moran_fn = moran_plot_fmt.format(
#                 date=wildcards.date, sn=wildcards.sn, scn=scn
#             )
#             ip.check_dir(moran_fn)
#             ip.save_fig(moran_fn)
#             plt.close()
#             # Plot the scatter locations
#             coord_scn = coords[bool_scn]
#             fig, ax = ip.general_plot(
#                 col='w', dims=eval(pdict['dims_im']), lw=pdict['lw'], ft=pdict['ft']
#             )
#             ax.scatter(coord_scn[:,1], coord_scn[:,0], s=pdict['spot_size'], color=col)
#             ax.set_xlim(xlim[0], xlim[1])
#             ax.set_ylim(ylim[0], ylim[1])
#             ax.invert_yaxis()
#             ax.set_aspect('equal')
#             scatter_fn = scatter_plot_fmt.format(
#                 date=wildcards.date, sn=wildcards.sn, scn=scn
#             )
#             ip.check_dir(scatter_fn)
#             ip.save_fig(scatter_fn, dpi=pdict['dpi'])
#             plt.close()
#         pd.DataFrame(moran_table).to_csv(output.moran_table_fn, index=False)

#         # Morans bivariate corrrelation
#         moran_bv_table = defaultdict(list)
#         for i, scn0 in enumerate(scn_unq):
#             for j, scn1 in enumerate(scn_unq):
#                 if i != j:
#                     # calculate morans bivariate
#                     col0 = dict_sciname_color[scn0]
#                     col1 = dict_sciname_color[scn1]
#                     bool_scn0 = scinames == scn0
#                     bool_scn1 = scinames == scn1
#                     y0 = bool_scn0 * 1
#                     y1 = bool_scn1 * 1
#                     mbv = Moran_BV(y0, y1, w)
#                     moran_bv_table["sciname0"].append(scn0)
#                     moran_bv_table["sciname1"].append(scn0)
#                     moran_bv_table["I_expected"].append(mbv.EI_sim)
#                     moran_bv_table["I_measured"].append(mbv.I)
#                     moran_bv_table["p_simulation"].append(mbv.p_sim)
#                     # PLot the simluation vs observed
#                     fig, ax = apl.general_plot(
#                         col=pdict['l_col'], 
#                         dims=eval(pdict['dims']), 
#                         lw=pdict['lw'], 
#                         ft=pdict['ft'], 
#                         pad=pdict['pad']
#                     )
#                     apl.plot_morans_i_sim_obj(
#                         ax, mbv, 
#                         lw=pdict['lw'], 
#                         ft=pdict['ft'], 
#                         col=col0, 
#                         l_col=pdict['l_col']
#                     )
#                     moran_bv_fn = moran_plot_bv_fmt.format(
#                         date=wildcards.date, sn=wildcards.sn, scn0=scn1, scn1=scn1
#                     )
#                     ip.check_dir(moran_bv_fn)
#                     ip.save_fig(moran_bv_fn)
#                     plt.close()
#                     # Plot the scatter locations
#                     coord_scn0 = coords[bool_scn0]
#                     coord_scn1 = coords[bool_scn1]
#                     fig, ax = ip.general_plot(
#                         col='w', 
#                         dims=eval(pdict['dims_im']), 
#                         lw=pdict['lw'], 
#                         ft=pdict['ft']
#                     )
#                     ax.scatter(
#                         coord_scn0[:,1], 
#                         coord_scn0[:,0], 
#                         s=pdict['spot_size'], 
#                         color=col0
#                     )
#                     ax.scatter(
#                         coord_scn[:,1], 
#                         coord_scn[:,0], 
#                         s=pdict['spot_size'], 
#                         color=col1
#                         )
#                     ax.set_xlim(xlim[0], xlim[1])
#                     ax.set_ylim(ylim[0], ylim[1])
#                     ax.invert_yaxis()
#                     ax.set_aspect('equal')
#                     scatter_bv_fn = scatter_plot_bv_fmt.format(
#                         date=wildcards.date, sn=wildcards.sn,scn0=scn1, scn1=scn1
#                     )
#                     ip.check_dir(scatter_bv_fn)
#                     ip.save_fig(scatter_bv_fn, dpi=pdict['dpi'])
#                     plt.close()
#         pd.DataFrame(moran_bv_table).to_csv(output.moran_bv_table_fn, index=False)
