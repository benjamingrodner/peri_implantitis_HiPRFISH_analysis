{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import re\n",
    "import aicspylibczi as aplc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import javabridge\n",
    "import bioformats\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import aicspylibczi as aplc\n",
    "from scipy import stats\n",
    "from cv2 import resize, INTER_CUBIC, INTER_NEAREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = \"\"\n",
    "workdir = \"/workdir/bmg224/harvard_dental/manuscript/code\"\n",
    "os.chdir(cluster + workdir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "functions_path = '/workdir/bmg224/manuscripts/mgefish/code/functions'\n",
    "\n",
    "sys.path.append(cluster + functions_path)\n",
    "\n",
    "import fn_general_use as fgu\n",
    "import image_plots as ip\n",
    "import segmentation_func as sf\n",
    "import fn_hiprfish_classifier as fhc\n",
    "import fn_spectral_images as fsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\n",
    "    \"../../imaging/2022_12_16_harvardwelch/data\",\n",
    "    \"../../imaging/2023_02_08_hsdm/data\",\n",
    "    \"../../imaging/2023_02_18_hsdm/data\",\n",
    "    \"/fs/cbsuvlaminck2/workdir/Data/bmg224/2023/brc_imaging/2023_10_16_hsdm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dir_group_czi = {}\n",
    "for d in dirs:\n",
    "    fns = glob.glob(d + \"/*.czi\")\n",
    "    fns_base = [os.path.split(f)[1] for f in fns]\n",
    "    group_names = [\n",
    "        re.sub(\"(?<=fov_\\d{2})[a-zA-Z0-9\\-\\_]+.czi\", \"\", s) for s in fns_base\n",
    "    ]\n",
    "    # print('HERE-->', shifts_fns)\n",
    "    group_names = np.sort(np.unique(group_names))\n",
    "    m_size = group_names.shape[0]\n",
    "    dict_group_czifns_all = defaultdict(list)\n",
    "    for g in group_names:\n",
    "        for s in fns:\n",
    "            if g in s:\n",
    "                dict_group_czifns_all[g].append(s)\n",
    "    dict_dir_group_czi[d] = {g: sorted(s) for g, s in dict_group_czifns_all.items()}\n",
    "    print(dict_dir_group_czi[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 0\n",
    "for d, dict_group_czi in dict_dir_group_czi.items():\n",
    "    for gr, _ in dict_group_czi.items():\n",
    "        n_images += 1\n",
    "n_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dir_group_czi_filt = defaultdict(dict)\n",
    "for d, dict_group_czi in dict_dir_group_czi.items():\n",
    "    for gr, czi_fns in dict_group_czi.items():\n",
    "        czi_fns_filt = []\n",
    "        for fn in czi_fns:\n",
    "            if (\"stitch\" not in fn) and (\"Stitch\" not in fn):\n",
    "                czi_fns_filt.append(fn)\n",
    "        dict_dir_group_czi_filt[d][gr] = czi_fns_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outlier_shifts(sh_i):\n",
    "    q = np.quantile(sh_i, [0.25, 0.5, 0.75], axis=0)\n",
    "    iqr = q[2] - q[0]\n",
    "    ol_plus = q[2] + 1.5 * iqr\n",
    "    ol_minus = q[0] - 1.5 * iqr\n",
    "    shifts_red = []\n",
    "    inds_replace = []\n",
    "    for k, s in enumerate(sh_i):\n",
    "        bool_std = any(s > ol_plus) or (any(s < ol_minus))\n",
    "        bool_z = all(s == np.array([0, 0]))\n",
    "        if bool_std or bool_z:\n",
    "            inds_replace.append(k)\n",
    "        else:\n",
    "            shifts_red.append(s)\n",
    "    if inds_replace:\n",
    "        sh_mean = np.median(shifts_red, axis=0).astype(int)\n",
    "        for k in inds_replace:\n",
    "            # print('Replaced', sh_i[k,:], 'with', sh_mean)\n",
    "            sh_i[k, :] = sh_mean\n",
    "    return sh_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dir_date = {\n",
    "    \"../../imaging/2022_12_16_harvardwelch/data\": \"2022_12_16\",\n",
    "    \"../../imaging/2023_02_08_hsdm/data\": \"2023_02_08\",\n",
    "    \"../../imaging/2023_02_18_hsdm/data\": \"2023_02_18\",\n",
    "    \"/workdir/Data/bmg224/2023/brc_imaging/2023_10_16_hsdm\": \"2023_10_16\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01\n",
      "0 0 0\n",
      "1 4 -7\n",
      "2 4 -7\n",
      "Wrote: ../outputs/segmentation_2024_03_07/2022_12_16/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01/segs/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01_M_1_seg.npy\n",
      "Wrote: ../outputs/segmentation_2024_03_07/2022_12_16/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01/segs/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01_M_1_props.csv\n",
      "Wrote: ../outputs/segmentation_2024_03_07/2022_12_16/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01/plots/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01_M_1_seg_plot.png\n",
      "Wrote: ../outputs/segmentation_2024_03_07/2022_12_16/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01/plots/2022_12_16_harvardwelch_patient_10_tooth_8_aspect_MB_depth_supra_fov_01_M_1_rgb_plot.png\n"
     ]
    }
   ],
   "source": [
    "max_shift = 500\n",
    "gauss = 3\n",
    "diff_gauss = (2, 3)\n",
    "bg_smoothing = 5\n",
    "n_clust_bg = 4\n",
    "top_n_clust_bg = 3\n",
    "imin=2\n",
    "dpi=500\n",
    "\n",
    "out_dir = \"../outputs/segmentation_2024_03_07\"\n",
    "out_fmt_seg = out_dir + \"/{d}/{sn}/segs/{sn}_M_{m}\"\n",
    "out_fmt_plot = out_dir + \"/{d}/{sn}/plots/{sn}_M_{m}\"\n",
    "seg_fmt = out_fmt_seg + \"_seg.npy\"\n",
    "props_fmt = out_fmt_seg + \"_props.csv\"\n",
    "plot_fmt = out_fmt_plot + \"_seg_plot.png\"\n",
    "rgb_fmt = out_fmt_plot + \"_rgb_plot.png\"\n",
    "\n",
    "for i, (d, dict_group_czi) in enumerate(dict_dir_group_czi_filt.items()):\n",
    "    date = dict_dir_date[d]\n",
    "    for j, (sn, czi_fns) in enumerate(dict_group_czi.items()):\n",
    "        # if (i == 0) and (j == 0):\n",
    "        # if i == n:\n",
    "        print(sn)\n",
    "        # Get number of tiles or scenes\n",
    "        M, mtype = fsi.get_ntiles(czi_fns[0])\n",
    "        # Get the resolutions\n",
    "        resolutions = [fsi.get_resolution(fn) for fn in czi_fns]\n",
    "        # Get the lasers\n",
    "        lasers = [fsi.get_laser(fn) for fn in czi_fns]\n",
    "        # Get shifts\n",
    "        shifts = []\n",
    "        for m in range(M):\n",
    "            raws = [fsi.load_raw(fn, m, mtype) for fn in czi_fns]\n",
    "            raws = [fsi.reshape_aics_image(r) for r in raws]\n",
    "            # some images have different pixel resolution, correct that\n",
    "            raws = fsi.match_resolutions_and_size(raws, resolutions)\n",
    "            image_max_norm = [fsi.max_norm(r) for r in raws]\n",
    "            sh = fsi._get_shift_vectors(image_max_norm)\n",
    "            # print(sh)\n",
    "            shifts.append(sh)\n",
    "        # Some of the shifts are clearly wrong, fix those\n",
    "        sh_arr = np.array(shifts)\n",
    "        for k in range(1, len(lasers)):\n",
    "            sh_i = sh_arr[:, k, :]\n",
    "            print(\"Shifts\", lasers[k], \":\")\n",
    "            print(sh_i)\n",
    "            # address large deviatinos from typical\n",
    "            sh_arr[:, k, :] = replace_outlier_shifts(sh_i)\n",
    "        # Now shift the raw images\n",
    "        for m in range(M):\n",
    "            # if m == 1:\n",
    "            raws = [fsi.load_raw(fn, m, mtype) for fn in czi_fns]\n",
    "            raws = [fsi.reshape_aics_image(r) for r in raws]\n",
    "            # some images have different pixel resolution, correct that\n",
    "            raws = fsi.match_resolutions_and_size(raws, resolutions)\n",
    "            raws_shift = fsi._shift_images(\n",
    "                raws, sh_arr[m, :, :], max_shift=max_shift\n",
    "            )\n",
    "            stack = np.dstack(raws_shift)\n",
    "            stack_sum = np.sum(stack, axis=2)\n",
    "            pre = sf.pre_process(stack_sum, gauss=gauss, diff_gauss=diff_gauss)\n",
    "            mask = sf.get_background_mask(\n",
    "                stack_sum,\n",
    "                bg_smoothing=bg_smoothing,\n",
    "                n_clust_bg=n_clust_bg,\n",
    "                top_n_clust_bg=top_n_clust_bg,\n",
    "            )\n",
    "            seg = sf.segment(pre, mask)\n",
    "            props = sf.measure_regionprops(seg, stack_sum)\n",
    "            spec = fsi.get_cell_average_spectra(seg, stack)\n",
    "            props = props.merge(\n",
    "                pd.DataFrame(spec), left_index=True, right_index=True\n",
    "            )\n",
    "\n",
    "            seg_fn = seg_fmt.format(d=date, sn=sn, m=m)\n",
    "            props_fn = props_fmt.format(d=date, sn=sn, m=m)\n",
    "            plot_fn = plot_fmt.format(d=date, sn=sn, m=m)\n",
    "            rgb_fn = rgb_fmt.format(d=date, sn=sn, m=m)\n",
    "\n",
    "            for f in [seg_fn, props_fn, plot_fn, rgb_fn]:\n",
    "                odir = os.path.split(f)[0]\n",
    "                if not os.path.exists(odir):\n",
    "                    os.makedirs(odir)\n",
    "                    print(\"Made dir:\", odir)\n",
    "\n",
    "            np.save(seg_fn, seg)\n",
    "            print(\"Wrote:\", seg_fn)\n",
    "            props.to_csv(props_fn, index=False)\n",
    "            print(\"Wrote:\", props_fn)\n",
    "\n",
    "            # ip.plot_image(stack_sum, cmap=\"inferno\", im_inches=10)\n",
    "            fig, ax, _ = ip.plot_image(ip.seg2rgb(seg), im_inches=imin)\n",
    "            plt.figure(fig)\n",
    "            ip.save_fig(plot_fn, dpi=dpi, bbox_inches=0)\n",
    "            plt.close()\n",
    "            print(\"Wrote:\", plot_fn)\n",
    "\n",
    "            rgb = np.dstack([fsi.max_norm(r, type='sum') for r in raws_shift])\n",
    "            rgb = rgb[:,:,:3]\n",
    "            fig, ax, _ = ip.plot_image(rgb, im_inches=imin)\n",
    "            plt.figure(fig)\n",
    "            ip.save_fig(rgb_fn, dpi=dpi, bbox_inches=0)\n",
    "            plt.close()\n",
    "            print(\"Wrote:\", rgb_fn)\n",
    "\n",
    "            # ip.plot_image(\n",
    "            #     stack_sum[900:1100, 900:1100], cmap=\"inferno\", im_inches=10\n",
    "            # )\n",
    "            # ip.plot_image(ip.seg2rgb(seg)[900:1100, 900:1100, :], im_inches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
